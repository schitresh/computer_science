{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Computer Science Database System Computer Networks Object Oriented Programming Operating System","title":"Computer Science"},{"location":"#computer-science","text":"Database System Computer Networks Object Oriented Programming Operating System","title":"Computer Science"},{"location":"computer_networks/index","text":"Computer Networks Introduction Network Devices OSI Model TCP/IP Model Network Security Physical Layer Data Link Layer Network Layer Transport Layer Session Layer Presentation Layer Application Layer","title":"Index"},{"location":"computer_networks/index#computer-networks","text":"Introduction Network Devices OSI Model TCP/IP Model Network Security Physical Layer Data Link Layer Network Layer Transport Layer Session Layer Presentation Layer Application Layer","title":"Computer Networks"},{"location":"computer_networks/introduction","text":"Introduction Collection of computers & devices connected together to enable communication and data exchange System connected to network and ready for communication is called open system (vs closed system) Basic building blocks of a computer network are nodes and links Nodes: Devices capable of sending & receiving data like computers, servers, printers, routers, switches Links: Wires, cables, wireless networks Basic Terminology Protocol A set of rules and standards that govern how data is transmitted over a network Examples: TCP/IP, HTTP, FTP Protocol Data Unit: Single unit of information transmission among peer entities Topology Physical and logical arrangement of nodes in a network Examples: Bus, star, ring, mesh, tree IP Address (Internet Protocol Address) Unique numerical identifier that is assigned to every device in a network Used for identification & communication MAC Address (Media Access Control Address) Unique identifier of each host associated with its Network Interface Card (NIC) Used to identify a device in a local network DNS (Domain Name System) Translates human readable domain names to IP addresses that computers can understand For example, getting the IP address of www.google.com Dynamic Host Configuration Protocol (DHCP) Automatically assigns IP addresses and network configuration settings to devices in a network Firewall Monitors & controls incoming & outgoing network traffic Protects networks from unauthorized access and other security threats Network Criteria Performance Transit time: Time for a message to travel from one device to another Response time: Time elapsed between an inquiry and a response Throughput: Rate of message delivery Delay Factors Number of users Transmission medium and distance Hardware or software limitations Bandwidth (Capacity of network) Topology and protocols Congestion Reliability Failure frequency Recovery time after failure Reducing single points of failure Security Authentication Authorisation Damage and recovery Internet Global network of smaller networks interconnected using standardized protocols Allows people to communicate, share information, and access resources from anywhere in the world Consists of private, public, academic, business and government networks of local to global scope World Wide Web (WWW) Provides a way to access information through internet Only a subset of internet is connected through the web System of internet servers that support specially formatted documents in HTML Which are interlinked using hypertext links and are accessible via internet HTML (HyperText Markup Language): Markup language in which the documents are formatted HTTP (HyperText Transfer Protocol): Transfer protocol URI (Uniform Resource Identifier): Address of resource, can be a name or location or both URL (Uniform Resource Locator) Human readable text designed to substitute the IP addresses protocol://website_name.top_level_domain/path https://youtube.com/videos/id Working of Browser Step 1: Client-side We type a URL and the browser converts it to a file containing GET /HTTP/1.1 (1.1 refers to the version of HTTP) Host (www.google.com) Other information If connected to ethernet It is converted to binary code and sent down the wires If connected to wifi It is converted to a radio-signal which is decoded by a router in a very low level It is then converted to binary code and sent to the servers It is transmitted through routers until it reaches the destination Step 2: Server-side Receives the binary code and decodes it Generates a response HTTP/1.1 200 ok Content-type: type/html Body of the page Converts it to binary and sends it to IP requesting it Step 3: Client-side Receives the response and decodes it Checks the status Starts reading the html and constructs a tree like structure The HTML tree is converted to binary code and rendered on screen","title":"Introduction"},{"location":"computer_networks/introduction#introduction","text":"Collection of computers & devices connected together to enable communication and data exchange System connected to network and ready for communication is called open system (vs closed system) Basic building blocks of a computer network are nodes and links Nodes: Devices capable of sending & receiving data like computers, servers, printers, routers, switches Links: Wires, cables, wireless networks","title":"Introduction"},{"location":"computer_networks/introduction#basic-terminology","text":"Protocol A set of rules and standards that govern how data is transmitted over a network Examples: TCP/IP, HTTP, FTP Protocol Data Unit: Single unit of information transmission among peer entities Topology Physical and logical arrangement of nodes in a network Examples: Bus, star, ring, mesh, tree IP Address (Internet Protocol Address) Unique numerical identifier that is assigned to every device in a network Used for identification & communication MAC Address (Media Access Control Address) Unique identifier of each host associated with its Network Interface Card (NIC) Used to identify a device in a local network DNS (Domain Name System) Translates human readable domain names to IP addresses that computers can understand For example, getting the IP address of www.google.com Dynamic Host Configuration Protocol (DHCP) Automatically assigns IP addresses and network configuration settings to devices in a network Firewall Monitors & controls incoming & outgoing network traffic Protects networks from unauthorized access and other security threats","title":"Basic Terminology"},{"location":"computer_networks/introduction#network-criteria","text":"Performance Transit time: Time for a message to travel from one device to another Response time: Time elapsed between an inquiry and a response Throughput: Rate of message delivery Delay Factors Number of users Transmission medium and distance Hardware or software limitations Bandwidth (Capacity of network) Topology and protocols Congestion Reliability Failure frequency Recovery time after failure Reducing single points of failure Security Authentication Authorisation Damage and recovery","title":"Network Criteria"},{"location":"computer_networks/introduction#internet","text":"Global network of smaller networks interconnected using standardized protocols Allows people to communicate, share information, and access resources from anywhere in the world Consists of private, public, academic, business and government networks of local to global scope","title":"Internet"},{"location":"computer_networks/introduction#world-wide-web-www","text":"Provides a way to access information through internet Only a subset of internet is connected through the web System of internet servers that support specially formatted documents in HTML Which are interlinked using hypertext links and are accessible via internet HTML (HyperText Markup Language): Markup language in which the documents are formatted HTTP (HyperText Transfer Protocol): Transfer protocol URI (Uniform Resource Identifier): Address of resource, can be a name or location or both URL (Uniform Resource Locator) Human readable text designed to substitute the IP addresses protocol://website_name.top_level_domain/path https://youtube.com/videos/id","title":"World Wide Web (WWW)"},{"location":"computer_networks/introduction#working-of-browser","text":"","title":"Working of Browser"},{"location":"computer_networks/introduction#step-1-client-side","text":"We type a URL and the browser converts it to a file containing GET /HTTP/1.1 (1.1 refers to the version of HTTP) Host (www.google.com) Other information If connected to ethernet It is converted to binary code and sent down the wires If connected to wifi It is converted to a radio-signal which is decoded by a router in a very low level It is then converted to binary code and sent to the servers It is transmitted through routers until it reaches the destination","title":"Step 1: Client-side"},{"location":"computer_networks/introduction#step-2-server-side","text":"Receives the binary code and decodes it Generates a response HTTP/1.1 200 ok Content-type: type/html Body of the page Converts it to binary and sends it to IP requesting it","title":"Step 2: Server-side"},{"location":"computer_networks/introduction#step-3-client-side","text":"Receives the response and decodes it Checks the status Starts reading the html and constructs a tree like structure The HTML tree is converted to binary code and rendered on screen","title":"Step 3: Client-side"},{"location":"computer_networks/network_devices","text":"Network Devices Domains The more the number of collision domains & broadcast domains The better bandwidth the network provides Collision Domain When a device sends out a message to a network All the other devices in its collision domain have to pay attention to it No matter if it was destined for them or not When two devices send out their messages simultaneously Collision will occur leading them to wait and retransmit their messages one at a time It happens only in the case of half duplex mode Broadcast Domain When a device sends out a broadcast message All the devices present in its broadcast domain have to pay attention to it It creates a lot of congestion in the network (commonly called LAN congestion) It affects the bandwidth of the users present in that network Basic Network Devices Cables and connectors Modem: Connects computer to internet over telephone line Network Interface Card (NIC) Operates at physical and data link layer Helps computer to connect to network and communicate with other devices Contains hardware addresses (MAC address) used by data link layer Has a connector to connect a cable That acts as an interface between the computer and the router or modem Repeater Basic info Operates at physical layer Two ports (input & output) Collision domain and broadcast domain remains same Regenerates the signal over the same network before it becomes too weak or corrupted Not only amplifies the signal but also regenerates it by copying it bit by bit Hub Basic info Operates at physical layer Basically a multi-port repeater Collision domain and broadcast domain remains same Connects multiple devices from different branches or wires Computer request is sent to hub which distributes it to interconnected computers Cannot filter data so data packets are sent to all the connected devices Does not have capability to find out the best path for data packets Types Active Hub Has their own power supply Can clean, boost, relay signal along a network Serves as a repeater as well as a wiring center Used to extend the maximum distance between nodes Passive Hub Collects wiring from nodes and power supply from the active hub Relays signals onto a network without cleaning or boosting them Can't be used to extend distance between nodes Intelligent Hub Works like an active hub and includes remote management capabilities Provide flexible data rates Enables an administrator to monitor the passing network Bridge Basic info Operates at data link layer Two ports (input & output) Breaks only collision domain, broadcast domain remains same Repeater with functionality of filtering content By reading the MAC address of the source & destination Local internetworking device used to connect network segments together Used where the full power of router is not required (e.g. within the same organization) Uses MAC addresses to make forwarding decisions Hosts are unaware of the bridges and it appears to them as a single network Also used to divide large networks into smaller segments To improve network performance and reduce network congestion Types Transparent Bridge Stations are completely unaware of the bridge's existence Makes use of bridge forwarding and bridge learning Source Routing Bridge Routing operation is performed by the source station Frames specify which route to follow Hosts can discover the frame by sending a special frame called discovery frame Switch Basic info Operates at data link layer Multiport bridge with a buffer and a better efficiency Every port is in different collision domain but the broadcast domain remains the same Groups all devices over network to transfer data to another device Can perform error checking before forwarding data Doesn't broadcast over network like hub Sends message to the destination device based on the MAC address Learns the MAC address of the device on the switch port on which it received the frame Types Unmanaged: Simple configuration, suitable for small networks Managed: Advanded configuration like VLAN, QoS, suitable for large networks Layer 2: Operate at data link layer, forwards data between devices on the same network segment Layer 3: Operate at network layer, can route data between different network segments There are many other types of switches for different functionalities Router Basic info Operates at network layer Most routers include many ports that can connect a variety of devices to internet It separates both the collision domain and the broadcast domain Connects two or more network segments like LANs to a single network Device like switch that routes data packets based on their IP addresses By sending data packets to their intended IP addresses It manages traffic between different networks And permits several devices to share an internet connection Whenever a web request (packets) is sent from a browser It goes through a series of routers which accept these packets And forwards them to a correct path Working Examines the destination IP address from the header of a packet And compares it to the routing database A list of routing tables outline how to send data to a specific network location Dynamic routing tables are updated by dynamic routers based on network activity Static routing tables are configured manually Bridging Router (BRouter) Operates at data link and network layer Combines features of both bridge and router Capable of routing packets across networks as router and filtering LAN traffic as bridge Gateway Operates at network layer, also call protocol converters Passage to connect two networks that may work upon different networking models Works as messenger agent that take data from one system Then interpret it and transfer to another system Generally more complex than switches or routers","title":"Network Devices"},{"location":"computer_networks/network_devices#network-devices","text":"","title":"Network Devices"},{"location":"computer_networks/network_devices#domains","text":"The more the number of collision domains & broadcast domains The better bandwidth the network provides","title":"Domains"},{"location":"computer_networks/network_devices#collision-domain","text":"When a device sends out a message to a network All the other devices in its collision domain have to pay attention to it No matter if it was destined for them or not When two devices send out their messages simultaneously Collision will occur leading them to wait and retransmit their messages one at a time It happens only in the case of half duplex mode","title":"Collision Domain"},{"location":"computer_networks/network_devices#broadcast-domain","text":"When a device sends out a broadcast message All the devices present in its broadcast domain have to pay attention to it It creates a lot of congestion in the network (commonly called LAN congestion) It affects the bandwidth of the users present in that network","title":"Broadcast Domain"},{"location":"computer_networks/network_devices#basic-network-devices","text":"Cables and connectors Modem: Connects computer to internet over telephone line","title":"Basic Network Devices"},{"location":"computer_networks/network_devices#network-interface-card-nic","text":"Operates at physical and data link layer Helps computer to connect to network and communicate with other devices Contains hardware addresses (MAC address) used by data link layer Has a connector to connect a cable That acts as an interface between the computer and the router or modem","title":"Network Interface Card (NIC)"},{"location":"computer_networks/network_devices#repeater","text":"Basic info Operates at physical layer Two ports (input & output) Collision domain and broadcast domain remains same Regenerates the signal over the same network before it becomes too weak or corrupted Not only amplifies the signal but also regenerates it by copying it bit by bit","title":"Repeater"},{"location":"computer_networks/network_devices#hub","text":"Basic info Operates at physical layer Basically a multi-port repeater Collision domain and broadcast domain remains same Connects multiple devices from different branches or wires Computer request is sent to hub which distributes it to interconnected computers Cannot filter data so data packets are sent to all the connected devices Does not have capability to find out the best path for data packets","title":"Hub"},{"location":"computer_networks/network_devices#types","text":"Active Hub Has their own power supply Can clean, boost, relay signal along a network Serves as a repeater as well as a wiring center Used to extend the maximum distance between nodes Passive Hub Collects wiring from nodes and power supply from the active hub Relays signals onto a network without cleaning or boosting them Can't be used to extend distance between nodes Intelligent Hub Works like an active hub and includes remote management capabilities Provide flexible data rates Enables an administrator to monitor the passing network","title":"Types"},{"location":"computer_networks/network_devices#bridge","text":"Basic info Operates at data link layer Two ports (input & output) Breaks only collision domain, broadcast domain remains same Repeater with functionality of filtering content By reading the MAC address of the source & destination Local internetworking device used to connect network segments together Used where the full power of router is not required (e.g. within the same organization) Uses MAC addresses to make forwarding decisions Hosts are unaware of the bridges and it appears to them as a single network Also used to divide large networks into smaller segments To improve network performance and reduce network congestion","title":"Bridge"},{"location":"computer_networks/network_devices#types_1","text":"Transparent Bridge Stations are completely unaware of the bridge's existence Makes use of bridge forwarding and bridge learning Source Routing Bridge Routing operation is performed by the source station Frames specify which route to follow Hosts can discover the frame by sending a special frame called discovery frame","title":"Types"},{"location":"computer_networks/network_devices#switch","text":"Basic info Operates at data link layer Multiport bridge with a buffer and a better efficiency Every port is in different collision domain but the broadcast domain remains the same Groups all devices over network to transfer data to another device Can perform error checking before forwarding data Doesn't broadcast over network like hub Sends message to the destination device based on the MAC address Learns the MAC address of the device on the switch port on which it received the frame","title":"Switch"},{"location":"computer_networks/network_devices#types_2","text":"Unmanaged: Simple configuration, suitable for small networks Managed: Advanded configuration like VLAN, QoS, suitable for large networks Layer 2: Operate at data link layer, forwards data between devices on the same network segment Layer 3: Operate at network layer, can route data between different network segments There are many other types of switches for different functionalities","title":"Types"},{"location":"computer_networks/network_devices#router","text":"Basic info Operates at network layer Most routers include many ports that can connect a variety of devices to internet It separates both the collision domain and the broadcast domain Connects two or more network segments like LANs to a single network Device like switch that routes data packets based on their IP addresses By sending data packets to their intended IP addresses It manages traffic between different networks And permits several devices to share an internet connection Whenever a web request (packets) is sent from a browser It goes through a series of routers which accept these packets And forwards them to a correct path Working Examines the destination IP address from the header of a packet And compares it to the routing database A list of routing tables outline how to send data to a specific network location Dynamic routing tables are updated by dynamic routers based on network activity Static routing tables are configured manually","title":"Router"},{"location":"computer_networks/network_devices#bridging-router-brouter","text":"Operates at data link and network layer Combines features of both bridge and router Capable of routing packets across networks as router and filtering LAN traffic as bridge","title":"Bridging Router (BRouter)"},{"location":"computer_networks/network_devices#gateway","text":"Operates at network layer, also call protocol converters Passage to connect two networks that may work upon different networking models Works as messenger agent that take data from one system Then interpret it and transfer to another system Generally more complex than switches or routers","title":"Gateway"},{"location":"computer_networks/osi_model","text":"Open Systems Interconnection (OSI) Model Basic info Acts as a reference model Not implemented on internet because of its late invention The current model being used is the TCP/IP model Software or Upper layers Application, presentation, session layers Responsibility of host Hardware or Lower layers Transport, network, data link, physical layers Responsibility of network Flow of Data The data to be transferred travels through 7 layers of the model First it travels down the layers from the sender And then climbs back the layers towards the receiver Example: X sends an email to Y Application: X sends an email using an application like gmail Presentation: Mail application prepares for data transmission like encryption & formatting Session: Connection is established between the sender and the receiver on internet Transport Email data is broken into small segments Sequence number and error checking info is added to keep the data reliable Network: Addressing of packets is done to find the best route for transfer Data Link Data packets are encapsulated into frames MAC address is added for local devices Errors are detected Physical Data is transmitted in the form of electrical or optical signals Over a network medium like ethernet or wifi After the email reaches the receiver The process is reversed The email content is decrypted and shown to the receiver Physical Layer Physical medium through which bits are transmitted PDU (Protocol Data Unit): Bit Devices: Cables, Fibers, Wirelessm Modem, Repeater, Hub Data Link Layer Error free transfer of data frames PDU: Frame Devices: NIC/Adaptor/Chip, Device driver, Bridge, Switch Addressing: MAC address Network Layer Moving packets from source to destination PDU: Packet, Datagram Devices: Router, Brouter Addressing: IP address Protocols: IP, ICMP, ARP Transport Layer Reliable message delivery from process to process PDU: Segment Devices: OS, Gateways, Firewalls Addressing: Port Number Protocols: TCP, UDP Session Layer Establish, manage and terminate sessions Packet: Data Devices: OS, Gateways, Firewalls Protocols: SSL, API Presentation Layer Translation, compression, encryption Packet: Data Devices: OS, Gateways, Firewalls Protocols: SSL, SSH, IMAP Application Layer Services for the user Packet: Data Devices: Network applications, Browser, Messenger, Gateways, Firewalls Protocols: HTTP, DHCP, FTP, SSH, SMTP, DNS","title":"Osi Model"},{"location":"computer_networks/osi_model#open-systems-interconnection-osi-model","text":"Basic info Acts as a reference model Not implemented on internet because of its late invention The current model being used is the TCP/IP model Software or Upper layers Application, presentation, session layers Responsibility of host Hardware or Lower layers Transport, network, data link, physical layers Responsibility of network","title":"Open Systems Interconnection (OSI) Model"},{"location":"computer_networks/osi_model#flow-of-data","text":"The data to be transferred travels through 7 layers of the model First it travels down the layers from the sender And then climbs back the layers towards the receiver","title":"Flow of Data"},{"location":"computer_networks/osi_model#example-x-sends-an-email-to-y","text":"Application: X sends an email using an application like gmail Presentation: Mail application prepares for data transmission like encryption & formatting Session: Connection is established between the sender and the receiver on internet Transport Email data is broken into small segments Sequence number and error checking info is added to keep the data reliable Network: Addressing of packets is done to find the best route for transfer Data Link Data packets are encapsulated into frames MAC address is added for local devices Errors are detected Physical Data is transmitted in the form of electrical or optical signals Over a network medium like ethernet or wifi After the email reaches the receiver The process is reversed The email content is decrypted and shown to the receiver","title":"Example: X sends an email to Y"},{"location":"computer_networks/osi_model#physical-layer","text":"Physical medium through which bits are transmitted PDU (Protocol Data Unit): Bit Devices: Cables, Fibers, Wirelessm Modem, Repeater, Hub","title":"Physical Layer"},{"location":"computer_networks/osi_model#data-link-layer","text":"Error free transfer of data frames PDU: Frame Devices: NIC/Adaptor/Chip, Device driver, Bridge, Switch Addressing: MAC address","title":"Data Link Layer"},{"location":"computer_networks/osi_model#network-layer","text":"Moving packets from source to destination PDU: Packet, Datagram Devices: Router, Brouter Addressing: IP address Protocols: IP, ICMP, ARP","title":"Network Layer"},{"location":"computer_networks/osi_model#transport-layer","text":"Reliable message delivery from process to process PDU: Segment Devices: OS, Gateways, Firewalls Addressing: Port Number Protocols: TCP, UDP","title":"Transport Layer"},{"location":"computer_networks/osi_model#session-layer","text":"Establish, manage and terminate sessions Packet: Data Devices: OS, Gateways, Firewalls Protocols: SSL, API","title":"Session Layer"},{"location":"computer_networks/osi_model#presentation-layer","text":"Translation, compression, encryption Packet: Data Devices: OS, Gateways, Firewalls Protocols: SSL, SSH, IMAP","title":"Presentation Layer"},{"location":"computer_networks/osi_model#application-layer","text":"Services for the user Packet: Data Devices: Network applications, Browser, Messenger, Gateways, Firewalls Protocols: HTTP, DHCP, FTP, SSH, SMTP, DNS","title":"Application Layer"},{"location":"computer_networks/tcp_ip_model","text":"TCP/IP Model Basic info The OSI model just acts as a reference model because of its late invention Used to transfer data reliably and accurately from one device to another Divides data into packets at the sender and recombines them at the receiver Protocols TCP (Transmission Control Protocol): Sends and receives data IP (Internet Protocol): Finds the destination of the data Network Access Layer OSI counterparts: Data link, Physical Physical layer: Responsible for generating the data and requesting connections Data link layer: Error prevention and dividing data into frames Network or Internet Layer OSI counterparts: Network Protocols: IP, ICMP, ARP Responsible for routing data packets from one device to another across a network Transport Layer OSI counterparts: Transport Protocols: TCP, UDP Exchanges data receipt acknowledgements Retransmits missing packets to ensure that packets arrive in order and without error Application Layer OSI counterparts: Application, Presentation, Session Protocols: HTTP, HTTPS, FTP, SSH, SMTP, DNS, DHCP Responsiible for end to end communication and error free delivery of data Shields the upper layer applications from the complexities of data Also called Process or Software layer","title":"Tcp Ip Model"},{"location":"computer_networks/tcp_ip_model#tcpip-model","text":"Basic info The OSI model just acts as a reference model because of its late invention Used to transfer data reliably and accurately from one device to another Divides data into packets at the sender and recombines them at the receiver Protocols TCP (Transmission Control Protocol): Sends and receives data IP (Internet Protocol): Finds the destination of the data","title":"TCP/IP Model"},{"location":"computer_networks/tcp_ip_model#network-access-layer","text":"OSI counterparts: Data link, Physical Physical layer: Responsible for generating the data and requesting connections Data link layer: Error prevention and dividing data into frames","title":"Network Access Layer"},{"location":"computer_networks/tcp_ip_model#network-or-internet-layer","text":"OSI counterparts: Network Protocols: IP, ICMP, ARP Responsible for routing data packets from one device to another across a network","title":"Network or Internet Layer"},{"location":"computer_networks/tcp_ip_model#transport-layer","text":"OSI counterparts: Transport Protocols: TCP, UDP Exchanges data receipt acknowledgements Retransmits missing packets to ensure that packets arrive in order and without error","title":"Transport Layer"},{"location":"computer_networks/tcp_ip_model#application-layer","text":"OSI counterparts: Application, Presentation, Session Protocols: HTTP, HTTPS, FTP, SSH, SMTP, DNS, DHCP Responsiible for end to end communication and error free delivery of data Shields the upper layer applications from the complexities of data Also called Process or Software layer","title":"Application Layer"},{"location":"computer_networks/network_security/index","text":"Network Security Introduction Threat Modeling Malware Denial of Service Miscellaneous Attacks Firewall Message Authentication Codes","title":"Index"},{"location":"computer_networks/network_security/index#network-security","text":"Introduction Threat Modeling Malware Denial of Service Miscellaneous Attacks Firewall Message Authentication Codes","title":"Network Security"},{"location":"computer_networks/network_security/introduction","text":"Introduction System Security Security can be compromised via any of these breaches Breach of confidentiality: Unauthorized reading of data Breach of integrity: Uauthorized modification of data Break of availability: Unauthorized destruction of data Theft of service: Unauthorized use of resources Denial of service: Preventing legitimate use of system The security of a system can be threatened via two violations Threat: A program that has the potential to cause serious damage to the system Program Threats A program is written to hijack the security or change the behavior A user program is altered and make to perform malicious unwanted tasks Examples: Virus, worm, trojan horse, trap door, logic bomb Security Threats System services, resources or user files are misused Also used as medium to launch program threats Examples: Worm, port scanning, denial of service Attack: An attempt to break security and make unauthorized use of an asset CIA Triad Confidentiality Only authorized individuals or systems Should be permitted to view sensitive or classified information A primary way to safegaurd data is to use encryption techniques AES (Advanced Encryption Standard) DES (Data Encryption Standard) Another way to protect data is through VPN (Virtual Private Network) tunnel Integrity The system should make sure that data has not been modified Corruption of data is a failure to maintain data integrity To check this, a hash value is generated using hash functions like SHA (Secure Hash Algorithm): 160-bit hash in SHA-1 MD5 (Message Direct 5): 128-bit hash This hash value is attached to the data When the target host receives the packet, it runs the same function And checks if the generated hash matches the received hash Availability Network (systems, data) should be readily available to its users Or else it may impact the business Network administrator should maintain hardware and make regular upgrades Should have a plan for fail-over and prevent bottlenecks Attacks like DoS or DDoS may render a network unavailable As the network resources get exhausted","title":"Introduction"},{"location":"computer_networks/network_security/introduction#introduction","text":"","title":"Introduction"},{"location":"computer_networks/network_security/introduction#system-security","text":"Security can be compromised via any of these breaches Breach of confidentiality: Unauthorized reading of data Breach of integrity: Uauthorized modification of data Break of availability: Unauthorized destruction of data Theft of service: Unauthorized use of resources Denial of service: Preventing legitimate use of system The security of a system can be threatened via two violations Threat: A program that has the potential to cause serious damage to the system Program Threats A program is written to hijack the security or change the behavior A user program is altered and make to perform malicious unwanted tasks Examples: Virus, worm, trojan horse, trap door, logic bomb Security Threats System services, resources or user files are misused Also used as medium to launch program threats Examples: Worm, port scanning, denial of service Attack: An attempt to break security and make unauthorized use of an asset","title":"System Security"},{"location":"computer_networks/network_security/introduction#cia-triad","text":"","title":"CIA Triad"},{"location":"computer_networks/network_security/introduction#confidentiality","text":"Only authorized individuals or systems Should be permitted to view sensitive or classified information A primary way to safegaurd data is to use encryption techniques AES (Advanced Encryption Standard) DES (Data Encryption Standard) Another way to protect data is through VPN (Virtual Private Network) tunnel","title":"Confidentiality"},{"location":"computer_networks/network_security/introduction#integrity","text":"The system should make sure that data has not been modified Corruption of data is a failure to maintain data integrity To check this, a hash value is generated using hash functions like SHA (Secure Hash Algorithm): 160-bit hash in SHA-1 MD5 (Message Direct 5): 128-bit hash This hash value is attached to the data When the target host receives the packet, it runs the same function And checks if the generated hash matches the received hash","title":"Integrity"},{"location":"computer_networks/network_security/introduction#availability","text":"Network (systems, data) should be readily available to its users Or else it may impact the business Network administrator should maintain hardware and make regular upgrades Should have a plan for fail-over and prevent bottlenecks Attacks like DoS or DDoS may render a network unavailable As the network resources get exhausted","title":"Availability"},{"location":"computer_networks/network_security/threat_modeling","text":"Threat Modeling Threat can be anything that can take advantage of a vulnerability to breach security And negatively alter, erase, or harm objects of interest Threat modeling is used to identify, communicate, understand & mitigate threats Documentation from this process provides system analysts and defenders With a complete analysis of probable attacker profiles, attack vectors, assets of interest Process Aim Establish the aim for carrying this process Pay attention to the CIA triad Visualization & Identification Understand the flow of data Find processes with user interactions Mitigation Continuous investigation of each vulnerability Action plan to deal with threats Validation Check if the threats have been mitigated or not Methodologies STRIDE Spoofing: An adversary posing as another user or component existing in system Tampering: Modification of data within the system Repudiation: Ability of user to deny having performed a particular action Can be done using false identity, manipulation of logs, deletion or evidence Information Disclosure: Exposure of protected data to non-allowed user Denial of Service Elevation of Privilege: Breaching administrative controls and tampering privileges DREAD Damage Potential Reproducibility: How easy it is to reproduce an attack Exploitability: Effort required to launch an attack Affected Users Discoverability: How easy it is to discover the threat Others PASTA (Process for Attack Simulation and Threat Analysis) Dynamic threat identification, enumeration, scoring process Develops an asset centric mitigation strategy by analyzing attacker centric view of system Trike: Establishes stakeholder defined acceptable level of risk assigned to each asset class Vast (Visual, Agile, and Simple Threat modeling) Provides an application and infrastructure visualization schemme Attack Tree: Conceptual diagram about how an asset might be attacked CVSS (Common Vulnerability Scooring System) Captures principal characteristics of a vulnerability with a numerical score T-Map: Calculates weights of attack paths","title":"Threat Modeling"},{"location":"computer_networks/network_security/threat_modeling#threat-modeling","text":"Threat can be anything that can take advantage of a vulnerability to breach security And negatively alter, erase, or harm objects of interest Threat modeling is used to identify, communicate, understand & mitigate threats Documentation from this process provides system analysts and defenders With a complete analysis of probable attacker profiles, attack vectors, assets of interest","title":"Threat Modeling"},{"location":"computer_networks/network_security/threat_modeling#process","text":"Aim Establish the aim for carrying this process Pay attention to the CIA triad Visualization & Identification Understand the flow of data Find processes with user interactions Mitigation Continuous investigation of each vulnerability Action plan to deal with threats Validation Check if the threats have been mitigated or not","title":"Process"},{"location":"computer_networks/network_security/threat_modeling#methodologies","text":"","title":"Methodologies"},{"location":"computer_networks/network_security/threat_modeling#stride","text":"Spoofing: An adversary posing as another user or component existing in system Tampering: Modification of data within the system Repudiation: Ability of user to deny having performed a particular action Can be done using false identity, manipulation of logs, deletion or evidence Information Disclosure: Exposure of protected data to non-allowed user Denial of Service Elevation of Privilege: Breaching administrative controls and tampering privileges","title":"STRIDE"},{"location":"computer_networks/network_security/threat_modeling#dread","text":"Damage Potential Reproducibility: How easy it is to reproduce an attack Exploitability: Effort required to launch an attack Affected Users Discoverability: How easy it is to discover the threat","title":"DREAD"},{"location":"computer_networks/network_security/threat_modeling#others","text":"PASTA (Process for Attack Simulation and Threat Analysis) Dynamic threat identification, enumeration, scoring process Develops an asset centric mitigation strategy by analyzing attacker centric view of system Trike: Establishes stakeholder defined acceptable level of risk assigned to each asset class Vast (Visual, Agile, and Simple Threat modeling) Provides an application and infrastructure visualization schemme Attack Tree: Conceptual diagram about how an asset might be attacked CVSS (Common Vulnerability Scooring System) Captures principal characteristics of a vulnerability with a numerical score T-Map: Calculates weights of attack paths","title":"Others"},{"location":"computer_networks/network_security/malware","text":"Malware Designed to disrupt, damage or gain unauthorized access to a system Tries to replicate from one infected host to new hosts Virus Malware that requires some form of user interaction to infect a device Attaches itself to a system file and rapidly replicates itself Modifying and destroying essential files leading to a system breakdown For example, email attachment with malicious executable code Which when opened runs malware on the device Worm Malware that can enter a device without any explicit user interaction For example, an attacker can send malware to a vulnerable network application Botnet A network of private computers infected with malicious software And contrrolled as a group without the owner's knowledge For example, to send spams Rootkit Stealthy packages designed to benefit administrative rights And get the right of entry to a community toll Once installed, can have complete and unrestrictive get right of entry to a tool And can execute any movement like spying customers or stealing data Logic Bomb Malicious program which is inserted into the system and triggers on specific conditions Trojan Horse A code segment that misuses its environment Seem to be attractive and harmless cover programs That are harmful hidden programs that can be used as virus carrier In one of the versions, user is fooled to enter confidential login details on an application These details are stolen by a login emulator and used to breach information Spyware is another variance Accompanies a program or website and displays ads by creating pop-up browser windows Captures essential information and sends it over to a remote server Zeus Malware or Zbot Malware bundle that utilizes client-server model and to make gigantic botnets Assists with acquiring unapproved admittance to monetary frameworks By taking accreditations, banking data, monetory infromation The penetrated information is then sent back to the assailants Through zeus order and control server Has compromised significant associations like NASA & Bank of America And north of 3 million PCs in USA","title":"Malware"},{"location":"computer_networks/network_security/malware#malware","text":"Designed to disrupt, damage or gain unauthorized access to a system Tries to replicate from one infected host to new hosts Virus Malware that requires some form of user interaction to infect a device Attaches itself to a system file and rapidly replicates itself Modifying and destroying essential files leading to a system breakdown For example, email attachment with malicious executable code Which when opened runs malware on the device Worm Malware that can enter a device without any explicit user interaction For example, an attacker can send malware to a vulnerable network application Botnet A network of private computers infected with malicious software And contrrolled as a group without the owner's knowledge For example, to send spams Rootkit Stealthy packages designed to benefit administrative rights And get the right of entry to a community toll Once installed, can have complete and unrestrictive get right of entry to a tool And can execute any movement like spying customers or stealing data Logic Bomb Malicious program which is inserted into the system and triggers on specific conditions","title":"Malware"},{"location":"computer_networks/network_security/malware#trojan-horse","text":"A code segment that misuses its environment Seem to be attractive and harmless cover programs That are harmful hidden programs that can be used as virus carrier In one of the versions, user is fooled to enter confidential login details on an application These details are stolen by a login emulator and used to breach information Spyware is another variance Accompanies a program or website and displays ads by creating pop-up browser windows Captures essential information and sends it over to a remote server","title":"Trojan Horse"},{"location":"computer_networks/network_security/malware#zeus-malware-or-zbot","text":"Malware bundle that utilizes client-server model and to make gigantic botnets Assists with acquiring unapproved admittance to monetary frameworks By taking accreditations, banking data, monetory infromation The penetrated information is then sent back to the assailants Through zeus order and control server Has compromised significant associations like NASA & Bank of America And north of 3 million PCs in USA","title":"Zeus Malware or Zbot"},{"location":"computer_networks/network_security/dos_denial_of_service","text":"Denial of Service (DoS) Renders a network, host or other pieces of infrastructure unusable by legitimate users May target servers, routers or communication links Example Ping of death: Uses pings with malformed ICMP packets of non standard sizes Smurf attack: Sending emails with fake return addresses and automatic responses Types Vulnerability attack Well-crafted messages are sent to a vulnerable application or operating system Running on a targeted host To stop or crash the service Bandwidth flooding Target's access link becomes clogged and legitimate packets cannot reach the server Connection flooding A large number of half or fully open TCP connections are established The host becomes bogged down with these bogus connections And stops accepting legitimate connections DDoS (Distributed DDoS) Multiple compromised systems are used to target a single system causing a DoS Can leverage botnets with thousands of comprised hosts Harder to detect and defend against than DoS attack from a single host Types Application layer attacks Responding to a request takes a considerable load for the server To build webpages, compute queries, load the results form database But a client can generate and send multiple requests without any load Examples: HTTP flood attack, attack on DNS services Protocol attacks Focuses on vulnerabilites in layer 3 & 4 Consumes resources like servers, firewalls, load balancers Examples: SYN flood attack, ping of death Volumetric attacks Consumes network bandwidth and saturates it by amplification or botnet Directs a massive amount of traffic to target server Examples: NTP amplification, DNS amplification, UDP flood attack, TCP flood attack Common Attacks SYN flood attack Exploits TCP handshake by sending SYN messages with a spoofed IP address The victim server keeps on responding but does not receive a final acknowledgement HTTP flood attack Multiple HTTP requests are generated simultaneously against a server This exhausts network resources of that server and fails to serve actual requests DNS amplification DNS server is requested from a spoofed IP address The request is structured such that the DNS server responds with a large amount of data Mitigation Preventing DDoS attack is harder than DoS attack since traffic comes from multiple sources And it becomes difficult to separate malicious hosts from actual hosts Blackhole routing: All traffic is diverted to a black hole where it gets lost Rate limiting Controls the rate of traffic and reduces the pace of web scrapers and brute force logins Unlikely to prevent compound DDoS attacks Blacklisting / whitelisting IP addresses","title":"Dos Denial Of Service"},{"location":"computer_networks/network_security/dos_denial_of_service#denial-of-service-dos","text":"Renders a network, host or other pieces of infrastructure unusable by legitimate users May target servers, routers or communication links Example Ping of death: Uses pings with malformed ICMP packets of non standard sizes Smurf attack: Sending emails with fake return addresses and automatic responses","title":"Denial of Service (DoS)"},{"location":"computer_networks/network_security/dos_denial_of_service#types","text":"Vulnerability attack Well-crafted messages are sent to a vulnerable application or operating system Running on a targeted host To stop or crash the service Bandwidth flooding Target's access link becomes clogged and legitimate packets cannot reach the server Connection flooding A large number of half or fully open TCP connections are established The host becomes bogged down with these bogus connections And stops accepting legitimate connections","title":"Types"},{"location":"computer_networks/network_security/dos_denial_of_service#ddos-distributed-ddos","text":"Multiple compromised systems are used to target a single system causing a DoS Can leverage botnets with thousands of comprised hosts Harder to detect and defend against than DoS attack from a single host","title":"DDoS (Distributed DDoS)"},{"location":"computer_networks/network_security/dos_denial_of_service#types_1","text":"Application layer attacks Responding to a request takes a considerable load for the server To build webpages, compute queries, load the results form database But a client can generate and send multiple requests without any load Examples: HTTP flood attack, attack on DNS services Protocol attacks Focuses on vulnerabilites in layer 3 & 4 Consumes resources like servers, firewalls, load balancers Examples: SYN flood attack, ping of death Volumetric attacks Consumes network bandwidth and saturates it by amplification or botnet Directs a massive amount of traffic to target server Examples: NTP amplification, DNS amplification, UDP flood attack, TCP flood attack","title":"Types"},{"location":"computer_networks/network_security/dos_denial_of_service#common-attacks","text":"SYN flood attack Exploits TCP handshake by sending SYN messages with a spoofed IP address The victim server keeps on responding but does not receive a final acknowledgement HTTP flood attack Multiple HTTP requests are generated simultaneously against a server This exhausts network resources of that server and fails to serve actual requests DNS amplification DNS server is requested from a spoofed IP address The request is structured such that the DNS server responds with a large amount of data","title":"Common Attacks"},{"location":"computer_networks/network_security/dos_denial_of_service#mitigation","text":"Preventing DDoS attack is harder than DoS attack since traffic comes from multiple sources And it becomes difficult to separate malicious hosts from actual hosts Blackhole routing: All traffic is diverted to a black hole where it gets lost Rate limiting Controls the rate of traffic and reduces the pace of web scrapers and brute force logins Unlikely to prevent compound DDoS attacks Blacklisting / whitelisting IP addresses","title":"Mitigation"},{"location":"computer_networks/network_security/miscellaneous_attacks","text":"Miscellaneous Attacks Spoofing & Phishing IP Spoofing Injects packet into the interrnet with a false source address Can be solved using end-point authentication DNS spoofing or DNS cache poisoning Corrupt DNS data is introduced into a DNS resolver's cache Causing the name server to return an incorrect IP address Phishing Sending emails purporting to be from reputable companies In order to induce individuals to reveal personal information & sensitive data When done through phone calls, it's called vishing (voice phishing) Packet Sniffer A passive receiver that records a copy of every packet that flies by Placed in the vicinity of a wireless transmitter Some of the best defenses involve cryptography Hacking Attacks Man in the Middle attack Someone between the source & destination Actively monitors, captures and controls the communication transparently For example, re-route a data exchange When communicating at low levels of network layer Computers might not be able to determine with whom they are exchanging data Compromized Key attacks A key is a secret code or number necessary to interpret secured information Obtaining a key is difficult and resource intensive process for an attacker But it is possible and referred as compromised key when obtained Vulnerability Attacks Trap Door The designer of a program or system might leave a hole that only he is capable of using Quite difficult to detect as one needs to go through the source code of all the components Port Scanning Automated process that creates a TCP/IP connection to a specific port To protect the identity of attacker, they are launched from zombie systems Brute Force Attacks Birthday Attack Type of cryptographic attack that belongs to a class of brute force attacks Exploits the mathematics behind the birthday problem in probability theory Success of this attack largely depends upon likelihood of collisions Found between random attack attempts and a fixed degree of permutations Birthday paradox problem Let's say there is a classroom of 30 students and a teacher The teacher wants to find pairs of students that have the same birthday For a particular date, probability of at least one student born is 1 - (364 / 365)^n = 7.9% for n = 30 Probability that at least one student has the same birthday as any other is 1 - (365! / ((365 - n!) * 365^n)) = 70% for n = 30","title":"Miscellaneous Attacks"},{"location":"computer_networks/network_security/miscellaneous_attacks#miscellaneous-attacks","text":"","title":"Miscellaneous Attacks"},{"location":"computer_networks/network_security/miscellaneous_attacks#spoofing-phishing","text":"IP Spoofing Injects packet into the interrnet with a false source address Can be solved using end-point authentication DNS spoofing or DNS cache poisoning Corrupt DNS data is introduced into a DNS resolver's cache Causing the name server to return an incorrect IP address Phishing Sending emails purporting to be from reputable companies In order to induce individuals to reveal personal information & sensitive data When done through phone calls, it's called vishing (voice phishing) Packet Sniffer A passive receiver that records a copy of every packet that flies by Placed in the vicinity of a wireless transmitter Some of the best defenses involve cryptography","title":"Spoofing &amp; Phishing"},{"location":"computer_networks/network_security/miscellaneous_attacks#hacking-attacks","text":"Man in the Middle attack Someone between the source & destination Actively monitors, captures and controls the communication transparently For example, re-route a data exchange When communicating at low levels of network layer Computers might not be able to determine with whom they are exchanging data Compromized Key attacks A key is a secret code or number necessary to interpret secured information Obtaining a key is difficult and resource intensive process for an attacker But it is possible and referred as compromised key when obtained","title":"Hacking Attacks"},{"location":"computer_networks/network_security/miscellaneous_attacks#vulnerability-attacks","text":"Trap Door The designer of a program or system might leave a hole that only he is capable of using Quite difficult to detect as one needs to go through the source code of all the components Port Scanning Automated process that creates a TCP/IP connection to a specific port To protect the identity of attacker, they are launched from zombie systems","title":"Vulnerability Attacks"},{"location":"computer_networks/network_security/miscellaneous_attacks#brute-force-attacks","text":"Birthday Attack Type of cryptographic attack that belongs to a class of brute force attacks Exploits the mathematics behind the birthday problem in probability theory Success of this attack largely depends upon likelihood of collisions Found between random attack attempts and a fixed degree of permutations Birthday paradox problem Let's say there is a classroom of 30 students and a teacher The teacher wants to find pairs of students that have the same birthday For a particular date, probability of at least one student born is 1 - (364 / 365)^n = 7.9% for n = 30 Probability that at least one student has the same birthday as any other is 1 - (365! / ((365 - n!) * 365^n)) = 70% for n = 30","title":"Brute Force Attacks"},{"location":"computer_networks/network_security/firewall","text":"Firewall Network security device That prevents unauthorized access to a network Monitors both incoming & outgoing traffic to detect and prevent threats Can be either hardware or software based Actions Accept: Allow th traffic Reject: Block the traffic and reply with an unreachable error Drop: Block the traffic with no reply History Before firewalls, network security was performed by ACLs residing on routers ACL: Access Control List ACL rules can determine whether network access should be granted or denied But they cannot determine the nature of the packet it is blocking And they do not have capacity to keep threats out of the network Hence, firewall was introduced Working Firewall matches the network traffic against the set rules defined in its table Maintains distinct set of rules for outgoing and incoming traffic Most traffic that reaches on the firewall Is one of the three major transport layer protocols TCP, UDP, ICMP which all have a source & a destination address TCP & UDP have port numbers while ICMP uses type code instead of port number It is difficult to explicitly cover every possible rule Hence a firewall must always have a default policy Types Static Packet Filtering Monitors outgoing & incoming packets to control network access Works on the network & transport layer Based on source & destination IP address, protocols, ports present in IP headers Maintains a filtering table with these attributes To decide if a packet will be forwarded or discarded Stateful Packet Filtering Based on the same attributes as static packet filtering Determines the connection state of packet travelling across it like TCP streams Which makes it more efficient than packet filtering So the filtering decisions are based on defined rules As well as packet's history in the state table Application Gateways or Proxy Firewalls Multiple application gateways can run with separate servers on the same host Examines & filters packets on any OSI layer upto application layer Recognizes when certain application and protocols are being misused Next Generation Firewalls (NGFW) Deep packet inspection, application inspection, SSL/SSH inspection Many functionalities to protect the network from modern threats Zone-based Firewall If an organization cannot afford a hardware firewall, it can use an alternative Implement the firewall features on router By using CBAC (by maintaining access list) Zone-based firewall (new approach than CBAC) Zone Logical area in which the devices have the same trust levels By default, traffic is not allowed from one zone to another There are two zones: inside (private network) and outside (WAN connection) Zone pair We can define zone pairs to allow traffic based on direction Inside to outside Outside to inside Self zone (traffic within the zone)","title":"Firewall"},{"location":"computer_networks/network_security/firewall#firewall","text":"Network security device That prevents unauthorized access to a network Monitors both incoming & outgoing traffic to detect and prevent threats Can be either hardware or software based Actions Accept: Allow th traffic Reject: Block the traffic and reply with an unreachable error Drop: Block the traffic with no reply History Before firewalls, network security was performed by ACLs residing on routers ACL: Access Control List ACL rules can determine whether network access should be granted or denied But they cannot determine the nature of the packet it is blocking And they do not have capacity to keep threats out of the network Hence, firewall was introduced","title":"Firewall"},{"location":"computer_networks/network_security/firewall#working","text":"Firewall matches the network traffic against the set rules defined in its table Maintains distinct set of rules for outgoing and incoming traffic Most traffic that reaches on the firewall Is one of the three major transport layer protocols TCP, UDP, ICMP which all have a source & a destination address TCP & UDP have port numbers while ICMP uses type code instead of port number It is difficult to explicitly cover every possible rule Hence a firewall must always have a default policy","title":"Working"},{"location":"computer_networks/network_security/firewall#types","text":"Static Packet Filtering Monitors outgoing & incoming packets to control network access Works on the network & transport layer Based on source & destination IP address, protocols, ports present in IP headers Maintains a filtering table with these attributes To decide if a packet will be forwarded or discarded Stateful Packet Filtering Based on the same attributes as static packet filtering Determines the connection state of packet travelling across it like TCP streams Which makes it more efficient than packet filtering So the filtering decisions are based on defined rules As well as packet's history in the state table Application Gateways or Proxy Firewalls Multiple application gateways can run with separate servers on the same host Examines & filters packets on any OSI layer upto application layer Recognizes when certain application and protocols are being misused Next Generation Firewalls (NGFW) Deep packet inspection, application inspection, SSL/SSH inspection Many functionalities to protect the network from modern threats","title":"Types"},{"location":"computer_networks/network_security/firewall#zone-based-firewall","text":"If an organization cannot afford a hardware firewall, it can use an alternative Implement the firewall features on router By using CBAC (by maintaining access list) Zone-based firewall (new approach than CBAC) Zone Logical area in which the devices have the same trust levels By default, traffic is not allowed from one zone to another There are two zones: inside (private network) and outside (WAN connection) Zone pair We can define zone pairs to allow traffic based on direction Inside to outside Outside to inside Self zone (traffic within the zone)","title":"Zone-based Firewall"},{"location":"computer_networks/network_security/message_authentication_codes","text":"Message Authentication Codes (MAC) Also known as error detection code or cyptographic checksum Let's say user A wants to send a message to user B A encrypts and sends the message using shared-cryptosystem A sends the key to B using public-key cryptosystem B uses the key to decrypt to ciphertext and obtains the message What if a malicious user falsifies the ciphertext during the transmission Or the message alters due to external problems like noise When B decrypts the message, it will get the wrong message B has to check whether the ciphertext is falsified or not By using message authentication code Ciphertext + Key = Message Authentication Code HMAC (Hashed MAC) Involves a cryptographic hash function and a secret cryptographic key For example, SHA-256 or MD-5 Uses two passes of hash computation First pass produces an internal hash from the message and the inner key Second pass produces the final HMAC code from the internal hash and the outer key Message (encrypted or not) is sent along with the HMAC hash Parties with the secret key will hash the message again If it is authentic, the received and computed hashes will match RSA Algorithm RSA is the acronym for the names of the developers Asymmetric cryptography algorithm Means that it works on two different keys: public key & private key Considered very secure and widely used Working A client sends its public key to the server and requests some data The server encrypts the data using the client's public key and sends to client The client receives this data and decrypts it using private key Concept It is difficult to factorize a large integer Public key consists of multiplication of two large prime numbers Private key is also derived from the same two prime numbers If somebody can factorize the large number, private key is compromised Hence, encryption strength lies on the key size Key size is typically 1024 or 2048 bits Due to this, it is slower than other encryption algorithms","title":"Message Authentication Codes"},{"location":"computer_networks/network_security/message_authentication_codes#message-authentication-codes-mac","text":"Also known as error detection code or cyptographic checksum Let's say user A wants to send a message to user B A encrypts and sends the message using shared-cryptosystem A sends the key to B using public-key cryptosystem B uses the key to decrypt to ciphertext and obtains the message What if a malicious user falsifies the ciphertext during the transmission Or the message alters due to external problems like noise When B decrypts the message, it will get the wrong message B has to check whether the ciphertext is falsified or not By using message authentication code Ciphertext + Key = Message Authentication Code","title":"Message Authentication Codes (MAC)"},{"location":"computer_networks/network_security/message_authentication_codes#hmac-hashed-mac","text":"Involves a cryptographic hash function and a secret cryptographic key For example, SHA-256 or MD-5 Uses two passes of hash computation First pass produces an internal hash from the message and the inner key Second pass produces the final HMAC code from the internal hash and the outer key Message (encrypted or not) is sent along with the HMAC hash Parties with the secret key will hash the message again If it is authentic, the received and computed hashes will match","title":"HMAC (Hashed MAC)"},{"location":"computer_networks/network_security/message_authentication_codes#rsa-algorithm","text":"RSA is the acronym for the names of the developers Asymmetric cryptography algorithm Means that it works on two different keys: public key & private key Considered very secure and widely used Working A client sends its public key to the server and requests some data The server encrypts the data using the client's public key and sends to client The client receives this data and decrypts it using private key Concept It is difficult to factorize a large integer Public key consists of multiplication of two large prime numbers Private key is also derived from the same two prime numbers If somebody can factorize the large number, private key is compromised Hence, encryption strength lies on the key size Key size is typically 1024 or 2048 bits Due to this, it is slower than other encryption algorithms","title":"RSA Algorithm"},{"location":"computer_networks/L1_physical_layer/index","text":"L1: Physical Layer Introduction Architecture Transmission","title":"Index"},{"location":"computer_networks/L1_physical_layer/index#l1-physical-layer","text":"Introduction Architecture Transmission","title":"L1: Physical Layer"},{"location":"computer_networks/L1_physical_layer/introduction","text":"Introduction Basic info Packet: Bit Devices: Hub, Repeater, Modem, Cables, Fibers, Wireless Features Physical medium through which bits are transmitted from one node to the next Converts the received data into binary and sends them to the data link layer Functions Establish, maintain & deactivate physical connection Defines the transmission media, mode & rate Line Configuration: How to connect devices physically Specifies the topology and network interface for the devices Bit transfer from node to node Provides a clock that helps with bit synchronization","title":"Introduction"},{"location":"computer_networks/L1_physical_layer/introduction#introduction","text":"Basic info Packet: Bit Devices: Hub, Repeater, Modem, Cables, Fibers, Wireless Features Physical medium through which bits are transmitted from one node to the next Converts the received data into binary and sends them to the data link layer","title":"Introduction"},{"location":"computer_networks/L1_physical_layer/introduction#functions","text":"Establish, maintain & deactivate physical connection Defines the transmission media, mode & rate Line Configuration: How to connect devices physically Specifies the topology and network interface for the devices Bit transfer from node to node Provides a clock that helps with bit synchronization","title":"Functions"},{"location":"computer_networks/L1_physical_layer/architecture","text":"Architecture Line Configuration A link is a communication pathway that transfers data from one device to another Point to point connection Provides a dedicated link between two devices Reserves the entire capacity of the link for transmission between the two devices Multi-point connection Multiple devices share a single link Prone to network congestion Types Spatial sharing: Several devices can share the link simultaneously Temporal sharing: Users must take turns to use the link Connection Types Peer to Peer (P2P) All computer linked with equal privileges Special permissions are assigned to each computer for resource sharing Used for small setups like 10 computers Advantages No server: less costly, easy setup & maintainence No single point of failure: others will work even if one stops Disadvantages No centralized system Devices manage themselves which can be a security issue Client Server Server performs all major operations like security, network & resource management All clients communicate through server Advantages Centralized system and backup Server improves overall performance including speed & security Disadvantages Server needs resources which are costly E.g. large memory, Network Operating System (NOS) Requires dedicated network administrator to manage resources Network Types Primary LAN (Local Area Network) MAN (Metropolitan Area Network) WAN (Wide Area Network) Others PAN (Personal Area Network) SAN (Storage Area Network) EPN (Enterprise Private Network) VPN (Virtual Private Network) Topology The way in which computers, devices, and links are arranged in a network Mesh: Every device is connected to another device Star: All the devices are connected to a single hub (or central node) through a cable Bus: Every device is connected with extension cables to a single bi-directional cable Ring: All the devices are connected to each other in a cyclic manner Tree: A central hub is at the root, secondary hubs are the internal nodes, systems are at the leaves Hybrid","title":"Architecture"},{"location":"computer_networks/L1_physical_layer/architecture#architecture","text":"","title":"Architecture"},{"location":"computer_networks/L1_physical_layer/architecture#line-configuration","text":"A link is a communication pathway that transfers data from one device to another Point to point connection Provides a dedicated link between two devices Reserves the entire capacity of the link for transmission between the two devices Multi-point connection Multiple devices share a single link Prone to network congestion Types Spatial sharing: Several devices can share the link simultaneously Temporal sharing: Users must take turns to use the link","title":"Line Configuration"},{"location":"computer_networks/L1_physical_layer/architecture#connection-types","text":"","title":"Connection Types"},{"location":"computer_networks/L1_physical_layer/architecture#peer-to-peer-p2p","text":"All computer linked with equal privileges Special permissions are assigned to each computer for resource sharing Used for small setups like 10 computers Advantages No server: less costly, easy setup & maintainence No single point of failure: others will work even if one stops Disadvantages No centralized system Devices manage themselves which can be a security issue","title":"Peer to Peer (P2P)"},{"location":"computer_networks/L1_physical_layer/architecture#client-server","text":"Server performs all major operations like security, network & resource management All clients communicate through server Advantages Centralized system and backup Server improves overall performance including speed & security Disadvantages Server needs resources which are costly E.g. large memory, Network Operating System (NOS) Requires dedicated network administrator to manage resources","title":"Client Server"},{"location":"computer_networks/L1_physical_layer/architecture#network-types","text":"Primary LAN (Local Area Network) MAN (Metropolitan Area Network) WAN (Wide Area Network) Others PAN (Personal Area Network) SAN (Storage Area Network) EPN (Enterprise Private Network) VPN (Virtual Private Network)","title":"Network Types"},{"location":"computer_networks/L1_physical_layer/architecture#topology","text":"The way in which computers, devices, and links are arranged in a network Mesh: Every device is connected to another device Star: All the devices are connected to a single hub (or central node) through a cable Bus: Every device is connected with extension cables to a single bi-directional cable Ring: All the devices are connected to each other in a cyclic manner Tree: A central hub is at the root, secondary hubs are the internal nodes, systems are at the leaves Hybrid","title":"Topology"},{"location":"computer_networks/L1_physical_layer/transmission","text":"Transmission Modes Simplex Unidirectional communication Only one of the devices on the link can transmit, the other can only receive Useful where feedback or response is not required, like broadcasting or surveillance Examples: radio, monitor, keyboard Half-duplex Each station can transmit and receive, but one at a time When one device is sending, the other can only receive Examples: walkie-talkie Full-duplex Both stations can transmit and receive simultaneously Signals in both the directions share the capacity of the link with each other Either the link must contain two physically separated transmission path One for sending & the other for receiving Or the capacity must be divided between signals travelling in both the directions Requires a high level of bandwidth May not be suitable for all types of applications Examples: phone, video conferencing, online gaming Transmission Types Unicast Message is sent from one sender to one receiver Examples: email, file transfer Broadcast Message is sent from one sender to all receivers Examples: DHCP requests, ARP (Address Resolution Protocol) requests Multicast Message is sent from one sender to a group of receivers Examples: video streaming, online gaming Transmission Media The channel through which data is sent from the transmitter to the receiver Guided Media Wired or bounded media High speed & secure Unguided Media Wireless or unbounded media Less secure, transmitted through electromagnetic signal Guided Media Twisted Pair Cable Consists of two separately insulated conductor wires wound about each other Several such pairs are bundled together in a protective sheath Unshielded Twisted Pair Consists of two insulated copper wires twisted around one another Block interferences without depending on a physical shield Used for telephone connections and LAN networks Shielded Twisted Pair Consists of a special jacket to block external interference Copper braid covering or foil shield Better performance at higher data rate than unshielded one But more expensive & difficult to install Used in fast-data-rate ethernet and in voice & data channels of telephone lines Coaxial Cable Has two parallel co-axial conductors each having a separate insulated cover Transmits information in two modes Baseband mode: Dedicated cable bandwidth Broadband mode: Cable bandwidth split into separate ranges Widely used by cable TVs and analog television networks Optical Fiber Cable Uses refraction of light through a core made up of glass or plastic Used for transmission of large volumes of data Supports unidirectional and bidirectional modes Stripline Transverse electromagnetic transmission line Uses a conducting material to transmit high frequency waves Conducting material is sandwiched between two layers of the ground plane Which are usually shorted to provide EMI immunity Microstripline Conducting material is separated from the ground plane by a layer of dielectric Unguided Media Radiowaves Easy to generate and can penetrate through buildings Sending and receiving antennas need not be aligned Frequency range: 3KHz to 1GHz Used by AM & FM radios, cordless phones Microwaves Sending & receiving antennas need to be properly aligned Frequency range: 1GHz to 300 GHz Majorly used for mobile phone communication and television distribution Infrared Used for very short distance communication Can penetrate through obstacles and prevents interference between systems Frequency range: 300GHz - 400THz Used in TV remotes, wireless mouse & keyboard","title":"Transmission"},{"location":"computer_networks/L1_physical_layer/transmission#transmission","text":"","title":"Transmission"},{"location":"computer_networks/L1_physical_layer/transmission#modes","text":"","title":"Modes"},{"location":"computer_networks/L1_physical_layer/transmission#simplex","text":"Unidirectional communication Only one of the devices on the link can transmit, the other can only receive Useful where feedback or response is not required, like broadcasting or surveillance Examples: radio, monitor, keyboard","title":"Simplex"},{"location":"computer_networks/L1_physical_layer/transmission#half-duplex","text":"Each station can transmit and receive, but one at a time When one device is sending, the other can only receive Examples: walkie-talkie","title":"Half-duplex"},{"location":"computer_networks/L1_physical_layer/transmission#full-duplex","text":"Both stations can transmit and receive simultaneously Signals in both the directions share the capacity of the link with each other Either the link must contain two physically separated transmission path One for sending & the other for receiving Or the capacity must be divided between signals travelling in both the directions Requires a high level of bandwidth May not be suitable for all types of applications Examples: phone, video conferencing, online gaming","title":"Full-duplex"},{"location":"computer_networks/L1_physical_layer/transmission#transmission-types","text":"Unicast Message is sent from one sender to one receiver Examples: email, file transfer Broadcast Message is sent from one sender to all receivers Examples: DHCP requests, ARP (Address Resolution Protocol) requests Multicast Message is sent from one sender to a group of receivers Examples: video streaming, online gaming","title":"Transmission Types"},{"location":"computer_networks/L1_physical_layer/transmission#transmission-media","text":"The channel through which data is sent from the transmitter to the receiver Guided Media Wired or bounded media High speed & secure Unguided Media Wireless or unbounded media Less secure, transmitted through electromagnetic signal","title":"Transmission Media"},{"location":"computer_networks/L1_physical_layer/transmission#guided-media","text":"","title":"Guided Media"},{"location":"computer_networks/L1_physical_layer/transmission#twisted-pair-cable","text":"Consists of two separately insulated conductor wires wound about each other Several such pairs are bundled together in a protective sheath Unshielded Twisted Pair Consists of two insulated copper wires twisted around one another Block interferences without depending on a physical shield Used for telephone connections and LAN networks Shielded Twisted Pair Consists of a special jacket to block external interference Copper braid covering or foil shield Better performance at higher data rate than unshielded one But more expensive & difficult to install Used in fast-data-rate ethernet and in voice & data channels of telephone lines","title":"Twisted Pair Cable"},{"location":"computer_networks/L1_physical_layer/transmission#coaxial-cable","text":"Has two parallel co-axial conductors each having a separate insulated cover Transmits information in two modes Baseband mode: Dedicated cable bandwidth Broadband mode: Cable bandwidth split into separate ranges Widely used by cable TVs and analog television networks","title":"Coaxial Cable"},{"location":"computer_networks/L1_physical_layer/transmission#optical-fiber-cable","text":"Uses refraction of light through a core made up of glass or plastic Used for transmission of large volumes of data Supports unidirectional and bidirectional modes","title":"Optical Fiber Cable"},{"location":"computer_networks/L1_physical_layer/transmission#stripline","text":"Transverse electromagnetic transmission line Uses a conducting material to transmit high frequency waves Conducting material is sandwiched between two layers of the ground plane Which are usually shorted to provide EMI immunity Microstripline Conducting material is separated from the ground plane by a layer of dielectric","title":"Stripline"},{"location":"computer_networks/L1_physical_layer/transmission#unguided-media","text":"Radiowaves Easy to generate and can penetrate through buildings Sending and receiving antennas need not be aligned Frequency range: 3KHz to 1GHz Used by AM & FM radios, cordless phones Microwaves Sending & receiving antennas need to be properly aligned Frequency range: 1GHz to 300 GHz Majorly used for mobile phone communication and television distribution Infrared Used for very short distance communication Can penetrate through obstacles and prevents interference between systems Frequency range: 300GHz - 400THz Used in TV remotes, wireless mouse & keyboard","title":"Unguided Media"},{"location":"computer_networks/L2_data_link_layer/index","text":"L2: Data Link Layer Introduction Switching Multiple Access Control Sliding Window Protocol Error Detection Virtual LAN Mobile Communication","title":"Index"},{"location":"computer_networks/L2_data_link_layer/index#l2-data-link-layer","text":"Introduction Switching Multiple Access Control Sliding Window Protocol Error Detection Virtual LAN Mobile Communication","title":"L2: Data Link Layer"},{"location":"computer_networks/L2_data_link_layer/introduction","text":"Introduction Basic info Packet: Frame Devices: Switch, Bridge, NIC/adaptor/chip, device driver Features Error free transfer of data from one node to another over the physical layer Transmits a packet arrived in a network to the host using the MAC address Receiver's MAC address is obtained by placing an ARP (Address Resolution Protocol) request Has two sublayers Logical Link Control (LLC) Media Access Control (MAC) Functions Framing The packet received from the network layer is divided into frames Depending on the frame size of the NIC (Network Interface Card) Physical addressing In the header of each frame, sender and receiver's MAC addresses are encapsulated Error detection Provides error control mechanism Detects and retransmits damaged or lost frames Adds CRC (Cyclic Redundancy Check) Flow Control Coordinates the amount of data that can be sent before receiving an acknowledgement Data rate must be constant on both sides else the data may get corrupted Access Control Required in a multi-device communication channel Determines which device has control over the link at a given time Framing In a point to point connection between two devices Where data is transmitted as a stream of bits The bits must be framed into perceptible blocks of information Every frame has a header and a trailer That contains information like source & destination address, error detection code Different networking devices and protocols may use different framing methods Which might lead to incompatibility issues Synchronization can be challenging Particularly in high speed networks where frames are transmitted rapidly Types Fixed size Frame is of fixed size No need to provide boundaries to the frame, the length itself acts as a delimiter May suffer from internal fragmentation Variable size Need to define the beginning & end of the frame to distinguish A length field can be added for this, but sometimes it might get corrupted Or, an end delimiter can be added to indicate the end of a frame Byte stuffing or Character stuffing: ED = '$' Bit stuffing: ED = 01111 Logical Link Control (LLC) Sublayer that provides the logic for the data link Controls packet transfer, syncronization, multiplexing, flow control, error checking Identifies the address of network layer protocol from header Unacknowledged connection-less service that uses LLC PDU (Protocol Data Unit) LLC PDU (Protocol Data Unit) It has four parts Destination Service Access Point (DSAP) Logical address (8-bit) of the network layer entity meant to receive the message Indicates whether this is an individual or group address Source Service Access Point (SSAP) Logical address (8-bit) of the network layer entity meant to create the message Indicates whether this is a command or response PDU Information Field: Data or information Control Field: 8 or 16 bit field used for flow and error control Media Access Control (MAC) Links LLC and physical layer Provides globally unique identification number for a hardware When a single communication channel is shared by multiple devices MAC sublayer determines which device has control over the channel at a given time MAC Address Provides globally unique identification number for a hardware Present in NICs (Network Interface Cards) like wifi card, bluetooth card, ethernet card They have unchangeable MAC address embedded by the vendor MAC address is 6 bytes (48 bits) long Left 3 bytes are termed OUI (Organizationally Unique Identifier) Remains same for NICs manufactured by the same company Right 3 bytes are termed NICS (Network Interface Controller Specific) Responsible for communication by cables or wireless Types of MAC address Unicast: Sent only to a specific NIC (LSB of the first octet is set to zero) Multicast: Sent to a group of devices (LSB of the first octet is set to one) Broadcast: Sent to every device in a LAN segment (Have ones in all bits) MAC Address vs IP Address When a device sends data, the data is wrapped in an IP header It includes source & destination IP address IP address is used for end-to-end delivery Ensures that the data reaches the destination This IP header along with the data is encapsulated in a MAC header It includes source & destination MAC address for the current hop MAC address is used for hop-to-hop delivery Facilitates the physical transfer of data between network nodes As the data travels through routers MAC header is stripped off and a new one is generated for the next hop IP header generated by the original device remains intact till the destination","title":"Introduction"},{"location":"computer_networks/L2_data_link_layer/introduction#introduction","text":"Basic info Packet: Frame Devices: Switch, Bridge, NIC/adaptor/chip, device driver Features Error free transfer of data from one node to another over the physical layer Transmits a packet arrived in a network to the host using the MAC address Receiver's MAC address is obtained by placing an ARP (Address Resolution Protocol) request Has two sublayers Logical Link Control (LLC) Media Access Control (MAC)","title":"Introduction"},{"location":"computer_networks/L2_data_link_layer/introduction#functions","text":"Framing The packet received from the network layer is divided into frames Depending on the frame size of the NIC (Network Interface Card) Physical addressing In the header of each frame, sender and receiver's MAC addresses are encapsulated Error detection Provides error control mechanism Detects and retransmits damaged or lost frames Adds CRC (Cyclic Redundancy Check) Flow Control Coordinates the amount of data that can be sent before receiving an acknowledgement Data rate must be constant on both sides else the data may get corrupted Access Control Required in a multi-device communication channel Determines which device has control over the link at a given time","title":"Functions"},{"location":"computer_networks/L2_data_link_layer/introduction#framing","text":"In a point to point connection between two devices Where data is transmitted as a stream of bits The bits must be framed into perceptible blocks of information Every frame has a header and a trailer That contains information like source & destination address, error detection code Different networking devices and protocols may use different framing methods Which might lead to incompatibility issues Synchronization can be challenging Particularly in high speed networks where frames are transmitted rapidly","title":"Framing"},{"location":"computer_networks/L2_data_link_layer/introduction#types","text":"Fixed size Frame is of fixed size No need to provide boundaries to the frame, the length itself acts as a delimiter May suffer from internal fragmentation Variable size Need to define the beginning & end of the frame to distinguish A length field can be added for this, but sometimes it might get corrupted Or, an end delimiter can be added to indicate the end of a frame Byte stuffing or Character stuffing: ED = '$' Bit stuffing: ED = 01111","title":"Types"},{"location":"computer_networks/L2_data_link_layer/introduction#logical-link-control-llc","text":"Sublayer that provides the logic for the data link Controls packet transfer, syncronization, multiplexing, flow control, error checking Identifies the address of network layer protocol from header Unacknowledged connection-less service that uses LLC PDU (Protocol Data Unit)","title":"Logical Link Control (LLC)"},{"location":"computer_networks/L2_data_link_layer/introduction#llc-pdu-protocol-data-unit","text":"It has four parts Destination Service Access Point (DSAP) Logical address (8-bit) of the network layer entity meant to receive the message Indicates whether this is an individual or group address Source Service Access Point (SSAP) Logical address (8-bit) of the network layer entity meant to create the message Indicates whether this is a command or response PDU Information Field: Data or information Control Field: 8 or 16 bit field used for flow and error control","title":"LLC PDU (Protocol Data Unit)"},{"location":"computer_networks/L2_data_link_layer/introduction#media-access-control-mac","text":"Links LLC and physical layer Provides globally unique identification number for a hardware When a single communication channel is shared by multiple devices MAC sublayer determines which device has control over the channel at a given time","title":"Media Access Control (MAC)"},{"location":"computer_networks/L2_data_link_layer/introduction#mac-address","text":"Provides globally unique identification number for a hardware Present in NICs (Network Interface Cards) like wifi card, bluetooth card, ethernet card They have unchangeable MAC address embedded by the vendor MAC address is 6 bytes (48 bits) long Left 3 bytes are termed OUI (Organizationally Unique Identifier) Remains same for NICs manufactured by the same company Right 3 bytes are termed NICS (Network Interface Controller Specific) Responsible for communication by cables or wireless Types of MAC address Unicast: Sent only to a specific NIC (LSB of the first octet is set to zero) Multicast: Sent to a group of devices (LSB of the first octet is set to one) Broadcast: Sent to every device in a LAN segment (Have ones in all bits)","title":"MAC Address"},{"location":"computer_networks/L2_data_link_layer/introduction#mac-address-vs-ip-address","text":"When a device sends data, the data is wrapped in an IP header It includes source & destination IP address IP address is used for end-to-end delivery Ensures that the data reaches the destination This IP header along with the data is encapsulated in a MAC header It includes source & destination MAC address for the current hop MAC address is used for hop-to-hop delivery Facilitates the physical transfer of data between network nodes As the data travels through routers MAC header is stripped off and a new one is generated for the next hop IP header generated by the original device remains intact till the destination","title":"MAC Address vs IP Address"},{"location":"computer_networks/L2_data_link_layer/switching","text":"Switching Technique by which nodes control or switch data To transmit it between specific points on a network There are three common switching techniques Circuit switching Packet switching Message switching Circuit Switching Network resources (bandwidth) are divided into pieces Before the data transmission begins A dedicated path (circuit) is established between sender & receiver The circuit remains dedicated for the session and provides a guaranteed data rate The bandwidth is reserved even when no data is being transmitted Which might be inefficient The connection is not required to be established for each packet Hence data can be transmitted without any delays That's why it's used in real time communication like voice & video The number of circuits that can be established is finite So it has limited scalability And also expensive because it requires dedicated resources Examples: Telephone system network Multiplexing Methods Frequency Division Multiplexing Bandwidth is divided into a series of non-overlapping frequency sub-bands Each sub-band carry different signal Used in radio spectrum & optical fibre Time Division Multiplexing (Digital Circuit) Independing signals are transmitted over a common signal path by synchonized switches Used for long distance communication links and bears heavy data traffic Packet Switching Transferring data to a network in the form of packets Data is broken into small pieces of variable length called packet To transfer the data efficiently and minimize the transmission latency These packets may travel through different routes They are reassembled at the destination Uses the store and forward technique Packets may get discarded at any hop for some reason So while forwarding the packet, each hop first stores the packet and then forwards Advantages Efficient use of bandwidth since it's shared Less expensive than circuit switching since resources are shared Resources are allocated only during data transmission Flexible: Can handle a wide range of data rates and packet sizes Scalable: Can handle large amounts of traffic in a network Disadvantages Higher latency than circuit switching since packets are routed through multiple nodes May result in packet loss due to congestion or errors in transmission There can be transmission delay & packet loss, so not ideal for real time communication Types of delays Transmission: Time taken by station to transmit data to the link Propogation: Time spent to propogate data through the link Queueing: Time for which a packet waits at the destination's queue Processing: Processing time at the destination Connection-oriented Packet Switching (Virtual Circuit) Before starting the transmission It establishes a logical path or virtual connection using a signaling protocol Virtual circuit ID is provided by switches/routers To uniquely identify this virtual connection There are three phases: connection setup, data transfer, tear down Address information is transferred only during the setup phase Once the route is decided, entry is added To the switching table of each intermediate node Resources like buffers, CPU, bandwidth are reserved For the time in which the virtual circuit will be used If many clients are trying to reserve a router's resources simultaneously It can become problematic The first sent packet reserves resources at each server along the path Subsequent packets follow the same path as the first packet during the connection Only the first packet requires a global header Since all packets follow a specific path They are received in order at the destination Packets are also appended with sequence numbers Used by ATM (Asynchronous Transfer Mode) network, specifically for telephone calls Connection-less Packet Switching (Datagram) Packet belonging to one flow may take different routes Because routing decisions are made dynamically So the packets arriving at the destination might be out of order All packets are associated with a header Which contains all necessary addressing information Like source & destination address, port numbers There is no connection setup, teardown phase, resource reservation like virtual circuits Cost efficient and easy to implement than virtual circuit Packet delivery is not guaranteed Packet is discarded if resources like buffer, CUP, bandwidth are not available So reliable delivery must be provided by end systems using additional protocols Generally used by IP network, which is used for data services like the internet Message Switching Developed as an alternative to circuit switching before packet switching was introduced Many major networks used are packet switched or circuit switched But their delivery processes can be message switched (like email systems) End users communicate by sending & receiving messages That include the entire data to be shared Each message has a header with information about message routing, source, destination Store and forward Intermediate nodes transfer the entire message to the next node Since messages are stored indefinitely, switches require large storage capacity Message is delivered only if sufficient resources are available The next hop and the link connecting it both should be available It is slow Each node waits for the entire message to be received After processing the next node depending on availability & traffic It must store & transmit the message Cannot be used for real time communication Efficient traffic management by assigning priorities to the messages","title":"Switching"},{"location":"computer_networks/L2_data_link_layer/switching#switching","text":"Technique by which nodes control or switch data To transmit it between specific points on a network There are three common switching techniques Circuit switching Packet switching Message switching","title":"Switching"},{"location":"computer_networks/L2_data_link_layer/switching#circuit-switching","text":"Network resources (bandwidth) are divided into pieces Before the data transmission begins A dedicated path (circuit) is established between sender & receiver The circuit remains dedicated for the session and provides a guaranteed data rate The bandwidth is reserved even when no data is being transmitted Which might be inefficient The connection is not required to be established for each packet Hence data can be transmitted without any delays That's why it's used in real time communication like voice & video The number of circuits that can be established is finite So it has limited scalability And also expensive because it requires dedicated resources Examples: Telephone system network","title":"Circuit Switching"},{"location":"computer_networks/L2_data_link_layer/switching#multiplexing-methods","text":"Frequency Division Multiplexing Bandwidth is divided into a series of non-overlapping frequency sub-bands Each sub-band carry different signal Used in radio spectrum & optical fibre Time Division Multiplexing (Digital Circuit) Independing signals are transmitted over a common signal path by synchonized switches Used for long distance communication links and bears heavy data traffic","title":"Multiplexing Methods"},{"location":"computer_networks/L2_data_link_layer/switching#packet-switching","text":"Transferring data to a network in the form of packets Data is broken into small pieces of variable length called packet To transfer the data efficiently and minimize the transmission latency These packets may travel through different routes They are reassembled at the destination Uses the store and forward technique Packets may get discarded at any hop for some reason So while forwarding the packet, each hop first stores the packet and then forwards Advantages Efficient use of bandwidth since it's shared Less expensive than circuit switching since resources are shared Resources are allocated only during data transmission Flexible: Can handle a wide range of data rates and packet sizes Scalable: Can handle large amounts of traffic in a network Disadvantages Higher latency than circuit switching since packets are routed through multiple nodes May result in packet loss due to congestion or errors in transmission There can be transmission delay & packet loss, so not ideal for real time communication Types of delays Transmission: Time taken by station to transmit data to the link Propogation: Time spent to propogate data through the link Queueing: Time for which a packet waits at the destination's queue Processing: Processing time at the destination","title":"Packet Switching"},{"location":"computer_networks/L2_data_link_layer/switching#connection-oriented-packet-switching-virtual-circuit","text":"Before starting the transmission It establishes a logical path or virtual connection using a signaling protocol Virtual circuit ID is provided by switches/routers To uniquely identify this virtual connection There are three phases: connection setup, data transfer, tear down Address information is transferred only during the setup phase Once the route is decided, entry is added To the switching table of each intermediate node Resources like buffers, CPU, bandwidth are reserved For the time in which the virtual circuit will be used If many clients are trying to reserve a router's resources simultaneously It can become problematic The first sent packet reserves resources at each server along the path Subsequent packets follow the same path as the first packet during the connection Only the first packet requires a global header Since all packets follow a specific path They are received in order at the destination Packets are also appended with sequence numbers Used by ATM (Asynchronous Transfer Mode) network, specifically for telephone calls","title":"Connection-oriented Packet Switching (Virtual Circuit)"},{"location":"computer_networks/L2_data_link_layer/switching#connection-less-packet-switching-datagram","text":"Packet belonging to one flow may take different routes Because routing decisions are made dynamically So the packets arriving at the destination might be out of order All packets are associated with a header Which contains all necessary addressing information Like source & destination address, port numbers There is no connection setup, teardown phase, resource reservation like virtual circuits Cost efficient and easy to implement than virtual circuit Packet delivery is not guaranteed Packet is discarded if resources like buffer, CUP, bandwidth are not available So reliable delivery must be provided by end systems using additional protocols Generally used by IP network, which is used for data services like the internet","title":"Connection-less Packet Switching (Datagram)"},{"location":"computer_networks/L2_data_link_layer/switching#message-switching","text":"Developed as an alternative to circuit switching before packet switching was introduced Many major networks used are packet switched or circuit switched But their delivery processes can be message switched (like email systems) End users communicate by sending & receiving messages That include the entire data to be shared Each message has a header with information about message routing, source, destination Store and forward Intermediate nodes transfer the entire message to the next node Since messages are stored indefinitely, switches require large storage capacity Message is delivered only if sufficient resources are available The next hop and the link connecting it both should be available It is slow Each node waits for the entire message to be received After processing the next node depending on availability & traffic It must store & transmit the message Cannot be used for real time communication Efficient traffic management by assigning priorities to the messages","title":"Message Switching"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control","text":"Multiple Access Control If there is no dedicated link between the sender and the receiver Then multiple stations can access the channel simultaneously Multiple access protocols are required to decrease collision and avoid crosstalk Types Random access protocols Controlled access protocols Channelization protocols Random Access Protocols All stations have the same priority Any station can send data depending on the medium's state (idle or busy) There is no fixed time for sending data There is no fixed sequence of stations sending data Aloha Used in low traffic networks Pure Aloha Station waits for an acknowledgement after sending data If acknowledgement is not received within the alotted time Then the station waits for a random amount of time (backoff time) And then re-sends the data The probability of collision decreases Since different stations wait for different amount of time Slotted Aloha Time is divided into slots Sending data is allowed only at the beginning of these slots If a station misses the allowed time It must wait for the next slot This reduces the probability of collision CSMA (Carrier Sense Multiple Access) The station senses the medium (for idle or busy) before transmitting data If it is busy, then it waits till the channel becomes idle Better efficiency than aloha, used in high traffic networks There is a chance of collision due to propogation delay CSMA/CD (Collision Detection) Once the station sends an entire frame, it does not keep a copy of the frame And does not monitor the channel for collision detection So before sending the last bit of the frame, the collision must be detected If a collision signal is received by the node, transmission is stopped Resending the frame immediately after may lead to consequent collisions So back-off algorithm is used Where it waits for random time intervals before resending the frame The size of a frame must be large enough to detect the collision by the sender Frame transmission delay must be at least two times the maximum propogation delay T(t) >= 2 * T(p) T(t) = S / B (S = Frame Size, B = Bandwidth or Transmission Speed) T(p) = L / P (L = Distance between farthest nodes, P = Propogation Speed) From above equations, we can get the mimimum frame size (S) and the maximum cable length (L) CSMA/CA (Collision Avoidance) Interframe space If the medium is idle, the station waits for a period of time (interframe space) After that it checks for the medium status again This avoids collision due to propogation delay The interframe space depends on the priority of the station Contention window Divides time into slots and chooses a random number of slots as wait time The number of slots double every time medium is found busy Acknowledgement The sender re-transmits the data if acknowledgement is not received before time-out Controlled Access Protocols The stations seek information from one another to find which station has the right to send Allows only one node to send at a time to avoid collision of messages on a shared medium Reservation Station needs to make a reservation before sending data The timeline has two kind of periods Reservation interval of fixed time length Data transmission period of variable frames If there are N stations, reservation interval is divided into N slots Each station has one slot, no other station can transmit during this slot i'th station announces that it has a frame to send by inserting 1 bit into the i'th slot After all N slots have been checked, each station knows which stations wish to transmit The stations which have reserved their slots transfer their frames in that order After data transmission period, next reservation interval begins Polling A controller sends a message to each node in turn One station acts as a primary station (or controller) and others as secondary stations All data exchanges happen through the controller The message sent by the controller Contains the address of the node being selected for granting access All nodes receive the message But only the addressed one responds and sends data if any If there is no data, usually a 'poll reject' (NAK) message is sent back Problems High overhead of the polling messages High dependence on the controller Since every station has an equal chance in every round, link sharing is biased Token Passing The stations are connected logically to each other in form of ring or bus Access to stations is governed by tokens A token is a special bit pattern or a small message The token circulates from one station to the next in a predefined order When a station gets the token It sends the frame queued for transmission and passes the token Problems to tackle Duplication or loss of token Insertion or removal of a station Channelization Protocols The available bandwidth of the link is shared in time, frequency and code To multiple stations to access a channel simultaneously This is done using circuit switching This means dividing bandwidth into pieces by frequency or time Ways to share bandwidth Frequency Division Multiple Access Bandwidth is divided into equal bands and each station is alloted its own band Guard bands are added to avoid overlap, to avoid crosstalk and noise Time Division Multiple Access To avoid collision, time is divided into slots and alloted to stations There is an overhead of synchronization Which is solved by adding synchronization bits to each slot Propogation delay is resolved by adding guard bands Code Division Multiple Access One channel carries all transmissions simultaneously, no division of bandwidth or time Data from different stations are transmitted in different code languages By recognizing the code language, the identity of the station is mapped Orthogonal Frequency Division Multiple Access Bandwidth is divided into small subcarriers to increase the overall performance Widely used in 5G technology Spatial Division Multiple Access Uses multiple antennas at the transmitter and receiver To separate the signals of multiple users located in different spatial directions","title":"Multiple Access Control"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#multiple-access-control","text":"If there is no dedicated link between the sender and the receiver Then multiple stations can access the channel simultaneously Multiple access protocols are required to decrease collision and avoid crosstalk Types Random access protocols Controlled access protocols Channelization protocols","title":"Multiple Access Control"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#random-access-protocols","text":"All stations have the same priority Any station can send data depending on the medium's state (idle or busy) There is no fixed time for sending data There is no fixed sequence of stations sending data","title":"Random Access Protocols"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#aloha","text":"Used in low traffic networks Pure Aloha Station waits for an acknowledgement after sending data If acknowledgement is not received within the alotted time Then the station waits for a random amount of time (backoff time) And then re-sends the data The probability of collision decreases Since different stations wait for different amount of time Slotted Aloha Time is divided into slots Sending data is allowed only at the beginning of these slots If a station misses the allowed time It must wait for the next slot This reduces the probability of collision","title":"Aloha"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#csma-carrier-sense-multiple-access","text":"The station senses the medium (for idle or busy) before transmitting data If it is busy, then it waits till the channel becomes idle Better efficiency than aloha, used in high traffic networks There is a chance of collision due to propogation delay","title":"CSMA (Carrier Sense Multiple Access)"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#csmacd-collision-detection","text":"Once the station sends an entire frame, it does not keep a copy of the frame And does not monitor the channel for collision detection So before sending the last bit of the frame, the collision must be detected If a collision signal is received by the node, transmission is stopped Resending the frame immediately after may lead to consequent collisions So back-off algorithm is used Where it waits for random time intervals before resending the frame The size of a frame must be large enough to detect the collision by the sender Frame transmission delay must be at least two times the maximum propogation delay T(t) >= 2 * T(p) T(t) = S / B (S = Frame Size, B = Bandwidth or Transmission Speed) T(p) = L / P (L = Distance between farthest nodes, P = Propogation Speed) From above equations, we can get the mimimum frame size (S) and the maximum cable length (L)","title":"CSMA/CD (Collision Detection)"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#csmaca-collision-avoidance","text":"Interframe space If the medium is idle, the station waits for a period of time (interframe space) After that it checks for the medium status again This avoids collision due to propogation delay The interframe space depends on the priority of the station Contention window Divides time into slots and chooses a random number of slots as wait time The number of slots double every time medium is found busy Acknowledgement The sender re-transmits the data if acknowledgement is not received before time-out","title":"CSMA/CA (Collision Avoidance)"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#controlled-access-protocols","text":"The stations seek information from one another to find which station has the right to send Allows only one node to send at a time to avoid collision of messages on a shared medium","title":"Controlled Access Protocols"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#reservation","text":"Station needs to make a reservation before sending data The timeline has two kind of periods Reservation interval of fixed time length Data transmission period of variable frames If there are N stations, reservation interval is divided into N slots Each station has one slot, no other station can transmit during this slot i'th station announces that it has a frame to send by inserting 1 bit into the i'th slot After all N slots have been checked, each station knows which stations wish to transmit The stations which have reserved their slots transfer their frames in that order After data transmission period, next reservation interval begins","title":"Reservation"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#polling","text":"A controller sends a message to each node in turn One station acts as a primary station (or controller) and others as secondary stations All data exchanges happen through the controller The message sent by the controller Contains the address of the node being selected for granting access All nodes receive the message But only the addressed one responds and sends data if any If there is no data, usually a 'poll reject' (NAK) message is sent back Problems High overhead of the polling messages High dependence on the controller Since every station has an equal chance in every round, link sharing is biased","title":"Polling"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#token-passing","text":"The stations are connected logically to each other in form of ring or bus Access to stations is governed by tokens A token is a special bit pattern or a small message The token circulates from one station to the next in a predefined order When a station gets the token It sends the frame queued for transmission and passes the token Problems to tackle Duplication or loss of token Insertion or removal of a station","title":"Token Passing"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#channelization-protocols","text":"The available bandwidth of the link is shared in time, frequency and code To multiple stations to access a channel simultaneously This is done using circuit switching This means dividing bandwidth into pieces by frequency or time","title":"Channelization Protocols"},{"location":"computer_networks/L2_data_link_layer/multiple_access_control#ways-to-share-bandwidth","text":"Frequency Division Multiple Access Bandwidth is divided into equal bands and each station is alloted its own band Guard bands are added to avoid overlap, to avoid crosstalk and noise Time Division Multiple Access To avoid collision, time is divided into slots and alloted to stations There is an overhead of synchronization Which is solved by adding synchronization bits to each slot Propogation delay is resolved by adding guard bands Code Division Multiple Access One channel carries all transmissions simultaneously, no division of bandwidth or time Data from different stations are transmitted in different code languages By recognizing the code language, the identity of the station is mapped Orthogonal Frequency Division Multiple Access Bandwidth is divided into small subcarriers to increase the overall performance Widely used in 5G technology Spatial Division Multiple Access Uses multiple antennas at the transmitter and receiver To separate the signals of multiple users located in different spatial directions","title":"Ways to share bandwidth"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol","text":"Sliding Window Protocol ARQ (Automatic Repeat Request or Automatic Repeat Query) ARQ is an error-control strategy used in a two-way communication system It is a group of error-control protocols to achieve reliable data transmission Over an unreliable source or service These protocols Reside in the transport layer and data link layer Responsible for the automatic retransmission of packets That are found to be corrupted or lost during the transmission process Working Principle of ARQ The sender receives an acknowledgment from the receiver before timeout Implying that the frame or packet is received correctly Timeout is a specific period within which the acknowledgment has to be sent By the receiver to the sender If a timeout occurs It is implied that the frame or packet has been corrupt or lost during the transmission And the sender retransmits the packet This process is repeated until the correct packet is transmitted Stop and Wait ARQ Error and flow control used in connection-oriented communication Used in data link layer and transport layer Implements sliding window protocol with window size 1 Metrics Propogation Delay: Time taken by a packet from one router to another router Round Trip Time (RTT) Time taken by a packet to reach the receiver And the acknowledgement to reach the sender Time Out: 2 * RTT Time to Live (TTL): 2 * Time Out (Maximum TTL is 255 seconds) Simple Stop and Wait Sender Sends one packet at a time Sends the next packet only after receiving acknowledgement for the previous one Receiver Sends acknowledgement (ack) after receiving and consuming a packet Problems If a packet is lost Sender keeps waiting for ack and receiver keeps waiting for packet If an ack is lost, sender keeps waiting for ack If a packet or an ack is delayed (after timeout) It might be considered wrongly for some other recent packet Stop and Wait with ARQ (Automatic Repeat Request) Solves the problems of the simple stop & wait Sequence number is added to each packet Which solves the delayed packet or ack problem If a packet is lost, the packet is retransmitted after time out If an ack is lost Receiver sends ack instead of negative ack by considering sequence number If an error is detected Receiver sends a negative acknowledgement (nak) to request retransmission Working Sender sends a packet with sequence number 0 Receiver sends an ack with sequence number 1 That is the seq number of next expected packet 0 or 1 is a one bit seq number It implies that both sender & receiver have a buffer for one packet only So, the sender will send seq number 0, then 1, then 0, and so on May cause performance issues Due to sequenced sending of packets and waiting for ack Sliding Window Protocol Handles the performance & efficiency issue in stop & wait ARQ By sending multiple packets at a time Types Go back N ARQ Selective repeat ARQ Metrics Transmission Delay Time to transmit the packet from the host to the outgoing link T(t) = D / B (D = data size to transmit, B = bandwidth of the link) Propagation Delay Time taken by the first bit from host to reach the destination T(p) = d / s (d = distance, s = wave propagation speed of the medium) Total Time Transmission (data + ack) + Propagation (data) + Propagation (ack) TT = T(t) + 2 * T(p) Efficiency: Useful time / Total time, i.e. T(t) / TT Effective Bandwidth or Throughput Number of bits sent per second Throughput = D / TT = Efficiency * Bandwidth Pipelining Window size = Number of packets in one cycle One packet is transmitted in T(t) time W = TT / T(t) = 1 + 2 * (T(p) / T(t)) W = 1 + 2a, where a = T(p)/T(t) After receiving ack for packet 0 Sequence number are reused so that header size can be kept minimum Window slides and next packet is assigned seq number 0 Can be represented with a diagram Draw a vertical line on LHS for sender (S) and another one on RHS for receiver (R) The vertical axis represents time starting from the top as the initial time For packet 0, draw a line from S at T(0) which touches R at T(p) Draw similar lines for all the packets in a window and for acks Go Back N ARQ Window sizes Sender window (WS) = N Receiver window (WR) = 1 Example with sender window size as 4 Sender sends packets 0, 1, 2, 3 Receiver sends ack for 0, 1 and is expecting packet 2 After receiving ack for 0, 1, the sender window slides to transmit packets 4, 5 Let's say the packet 2 is lost in the network So, the receiver will discard all the packets after packet 2 On the sender side, the time-out timer will expire for packet 2 Hence, the sender window will go back to the packet 2 and resend all packets till 5 So, it goes back N times (packets 2, 3, 4, 5) from the last transmitted packet Acknowledgements Cumulative ack One ack is used for many packets It reduces the traffic but is less reliable Because if this one ack is lost, all the sent packets are treated as lost Independent ack Each packet gets an ack independently Reliability is high but traffic is also high Minimum sequence numbers required = N + 1 Let's say receiver gets all the packets (0, 1, 2, 3) for window size 4 While it's waiting for packet 0 again, let's say cumulative ack is lost in the network After timeout on the sender side, all the 4 packets will be transmitted again And the receiver is also waiting for new set of packets starting from 0 Which will result in duplicates (old 0 is retransmitted and new 0 is expected) To avoid this, one extra sequence number is required Selective Repeat ARQ Go back N protocol works well if errors are less But if the line is poor, it wastes a lot of bandwidth on retransmitted frames Allows receiver to accept & buffer the frames following a damaged or lost one Retransmits only those packets that are actually lost Receiver must be able to accept packets out of order Retransmission requests Implicit Receiver acks every good packet Packets that are not acked before time-out are assumed lost or erred Explicit NAK (selective reject) requests retransmission of just one packet This can expedite retransmission but is not strictly needed Window sizes Sender window = Receiver window Window size should be less than or equal to half the sequence number This is to avoid packets being recognized incorrectly Receiver may recognize new packets as retransmissions Efficiency is same as Go back N","title":"Sliding Window Protocol"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#sliding-window-protocol","text":"","title":"Sliding Window Protocol"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#arq-automatic-repeat-request-or-automatic-repeat-query","text":"ARQ is an error-control strategy used in a two-way communication system It is a group of error-control protocols to achieve reliable data transmission Over an unreliable source or service These protocols Reside in the transport layer and data link layer Responsible for the automatic retransmission of packets That are found to be corrupted or lost during the transmission process","title":"ARQ (Automatic Repeat Request or Automatic Repeat Query)"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#working-principle-of-arq","text":"The sender receives an acknowledgment from the receiver before timeout Implying that the frame or packet is received correctly Timeout is a specific period within which the acknowledgment has to be sent By the receiver to the sender If a timeout occurs It is implied that the frame or packet has been corrupt or lost during the transmission And the sender retransmits the packet This process is repeated until the correct packet is transmitted","title":"Working Principle of ARQ"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#stop-and-wait-arq","text":"Error and flow control used in connection-oriented communication Used in data link layer and transport layer Implements sliding window protocol with window size 1","title":"Stop and Wait ARQ"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#metrics","text":"Propogation Delay: Time taken by a packet from one router to another router Round Trip Time (RTT) Time taken by a packet to reach the receiver And the acknowledgement to reach the sender Time Out: 2 * RTT Time to Live (TTL): 2 * Time Out (Maximum TTL is 255 seconds)","title":"Metrics"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#simple-stop-and-wait","text":"Sender Sends one packet at a time Sends the next packet only after receiving acknowledgement for the previous one Receiver Sends acknowledgement (ack) after receiving and consuming a packet Problems If a packet is lost Sender keeps waiting for ack and receiver keeps waiting for packet If an ack is lost, sender keeps waiting for ack If a packet or an ack is delayed (after timeout) It might be considered wrongly for some other recent packet","title":"Simple Stop and Wait"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#stop-and-wait-with-arq-automatic-repeat-request","text":"Solves the problems of the simple stop & wait Sequence number is added to each packet Which solves the delayed packet or ack problem If a packet is lost, the packet is retransmitted after time out If an ack is lost Receiver sends ack instead of negative ack by considering sequence number If an error is detected Receiver sends a negative acknowledgement (nak) to request retransmission Working Sender sends a packet with sequence number 0 Receiver sends an ack with sequence number 1 That is the seq number of next expected packet 0 or 1 is a one bit seq number It implies that both sender & receiver have a buffer for one packet only So, the sender will send seq number 0, then 1, then 0, and so on May cause performance issues Due to sequenced sending of packets and waiting for ack","title":"Stop and Wait with ARQ (Automatic Repeat Request)"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#sliding-window-protocol_1","text":"Handles the performance & efficiency issue in stop & wait ARQ By sending multiple packets at a time Types Go back N ARQ Selective repeat ARQ","title":"Sliding Window Protocol"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#metrics_1","text":"Transmission Delay Time to transmit the packet from the host to the outgoing link T(t) = D / B (D = data size to transmit, B = bandwidth of the link) Propagation Delay Time taken by the first bit from host to reach the destination T(p) = d / s (d = distance, s = wave propagation speed of the medium) Total Time Transmission (data + ack) + Propagation (data) + Propagation (ack) TT = T(t) + 2 * T(p) Efficiency: Useful time / Total time, i.e. T(t) / TT Effective Bandwidth or Throughput Number of bits sent per second Throughput = D / TT = Efficiency * Bandwidth","title":"Metrics"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#pipelining","text":"Window size = Number of packets in one cycle One packet is transmitted in T(t) time W = TT / T(t) = 1 + 2 * (T(p) / T(t)) W = 1 + 2a, where a = T(p)/T(t) After receiving ack for packet 0 Sequence number are reused so that header size can be kept minimum Window slides and next packet is assigned seq number 0 Can be represented with a diagram Draw a vertical line on LHS for sender (S) and another one on RHS for receiver (R) The vertical axis represents time starting from the top as the initial time For packet 0, draw a line from S at T(0) which touches R at T(p) Draw similar lines for all the packets in a window and for acks","title":"Pipelining"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#go-back-n-arq","text":"Window sizes Sender window (WS) = N Receiver window (WR) = 1 Example with sender window size as 4 Sender sends packets 0, 1, 2, 3 Receiver sends ack for 0, 1 and is expecting packet 2 After receiving ack for 0, 1, the sender window slides to transmit packets 4, 5 Let's say the packet 2 is lost in the network So, the receiver will discard all the packets after packet 2 On the sender side, the time-out timer will expire for packet 2 Hence, the sender window will go back to the packet 2 and resend all packets till 5 So, it goes back N times (packets 2, 3, 4, 5) from the last transmitted packet Acknowledgements Cumulative ack One ack is used for many packets It reduces the traffic but is less reliable Because if this one ack is lost, all the sent packets are treated as lost Independent ack Each packet gets an ack independently Reliability is high but traffic is also high Minimum sequence numbers required = N + 1 Let's say receiver gets all the packets (0, 1, 2, 3) for window size 4 While it's waiting for packet 0 again, let's say cumulative ack is lost in the network After timeout on the sender side, all the 4 packets will be transmitted again And the receiver is also waiting for new set of packets starting from 0 Which will result in duplicates (old 0 is retransmitted and new 0 is expected) To avoid this, one extra sequence number is required","title":"Go Back N ARQ"},{"location":"computer_networks/L2_data_link_layer/sliding_window_protocol#selective-repeat-arq","text":"Go back N protocol works well if errors are less But if the line is poor, it wastes a lot of bandwidth on retransmitted frames Allows receiver to accept & buffer the frames following a damaged or lost one Retransmits only those packets that are actually lost Receiver must be able to accept packets out of order Retransmission requests Implicit Receiver acks every good packet Packets that are not acked before time-out are assumed lost or erred Explicit NAK (selective reject) requests retransmission of just one packet This can expedite retransmission but is not strictly needed Window sizes Sender window = Receiver window Window size should be less than or equal to half the sequence number This is to avoid packets being recognized incorrectly Receiver may recognize new packets as retransmissions Efficiency is same as Go back N","title":"Selective Repeat ARQ"},{"location":"computer_networks/L2_data_link_layer/error_detection","text":"Error Detection Error is a condition when receiver's information does not match sender's information During transmission Digital signals suffer from noise that can introduce errors in the binary bits That means 0 bit may change to 1 bit or vice versa To prevent such errors, error detection codes are added as extra data to digital messages Types of Errors Single Bit Error One bit of a transmitted data is altered during transmission 10-1-1... -> 10-0-1... Multi Bit Error Relatively rare than single bit error But can occur in high noise or high interference digital environments 1-0-111... -> 1-1-11-0-... Burst Error When several consecutive bits are flipped mistakenly in digital transmission 1-011-1... -> 1-100-1... Error Detection Methods Single Parity Check An extra bit is added to a data transmission 1 is added if it contains odd number of 1's 0 is added if it contains even number of 1's 100011 -> 100011-1 Cannot detect even number of bit errors That is, if two 1's or two 0's are flipped Two-dimensional Parity Check Parity check bits are calculated for each row and each column 1100-0 (parity bit for row) 1101-1 (parity bit for row) .... 0001 (parity bits for columns) Checksum Data is divided into equally sized segments Sum of each segment is calculated using a 1's complement The calculated sum is sent to the receiver along with the data Won't work if one or more bits of a segment are damaged And the corresponding bit(s) of opposite value in second segment are also damaged Cyclic Redundancy Check Based on binary division unlike checksum which is based on addition Sequence of redundant bits are appended to the end of the data unit So that the resulting data unit becomes exactly divisible By a second predetermined binary number It is accepted at the destination If there is no remainder on dividing by the same number","title":"Error Detection"},{"location":"computer_networks/L2_data_link_layer/error_detection#error-detection","text":"Error is a condition when receiver's information does not match sender's information During transmission Digital signals suffer from noise that can introduce errors in the binary bits That means 0 bit may change to 1 bit or vice versa To prevent such errors, error detection codes are added as extra data to digital messages","title":"Error Detection"},{"location":"computer_networks/L2_data_link_layer/error_detection#types-of-errors","text":"Single Bit Error One bit of a transmitted data is altered during transmission 10-1-1... -> 10-0-1... Multi Bit Error Relatively rare than single bit error But can occur in high noise or high interference digital environments 1-0-111... -> 1-1-11-0-... Burst Error When several consecutive bits are flipped mistakenly in digital transmission 1-011-1... -> 1-100-1...","title":"Types of Errors"},{"location":"computer_networks/L2_data_link_layer/error_detection#error-detection-methods","text":"","title":"Error Detection Methods"},{"location":"computer_networks/L2_data_link_layer/error_detection#single-parity-check","text":"An extra bit is added to a data transmission 1 is added if it contains odd number of 1's 0 is added if it contains even number of 1's 100011 -> 100011-1 Cannot detect even number of bit errors That is, if two 1's or two 0's are flipped","title":"Single Parity Check"},{"location":"computer_networks/L2_data_link_layer/error_detection#two-dimensional-parity-check","text":"Parity check bits are calculated for each row and each column 1100-0 (parity bit for row) 1101-1 (parity bit for row) .... 0001 (parity bits for columns)","title":"Two-dimensional Parity Check"},{"location":"computer_networks/L2_data_link_layer/error_detection#checksum","text":"Data is divided into equally sized segments Sum of each segment is calculated using a 1's complement The calculated sum is sent to the receiver along with the data Won't work if one or more bits of a segment are damaged And the corresponding bit(s) of opposite value in second segment are also damaged","title":"Checksum"},{"location":"computer_networks/L2_data_link_layer/error_detection#cyclic-redundancy-check","text":"Based on binary division unlike checksum which is based on addition Sequence of redundant bits are appended to the end of the data unit So that the resulting data unit becomes exactly divisible By a second predetermined binary number It is accepted at the destination If there is no remainder on dividing by the same number","title":"Cyclic Redundancy Check"},{"location":"computer_networks/L2_data_link_layer/virtual_lan","text":"Virtual LAN (VLAN) Dividing devices in a network logically on layer 2 (data link layer) Broadcast domain Broadcast domain is a network segment In which all the devices in that domain receive a packet broadcasted by a device But it is limited to switches only as routers don't forward a broadcast packet Generally, layer 3 devices divide the broadcast domain But it can also be divided by switches using VLAN Through VLAN, different small sized sub-networks are created Which are comparatively easy to handle Devices that understand VLAN formats & membership are called VLAN aware Three ways to connect devices in a VLAN Trunk link: All connected devices must be VLAN aware Access link: Connects VLAN unaware devices to VLAN aware bridge Hybrid link: Both VLAN aware & unware devices are attached Reduces the need to send traffic to unnecessary destinations and saves bandwidth For example, the traffic is intended for 2 devices But 10 devices are present in the broadcast domain Useful to form virtual groups in an organization based on departments like sales, finance Allows to control broadcast domains, set up firewalls & restrict access Eliminates the need for expensive routers to create specific broadcast domains Inter VLAN Routing Required for communication between different VLANs Switch Virtual Interface (SVI) Logical interface on a multilayer switch that processes packets on all switch ports Provides only management services like creating VLAN or telnet/SSH services on layer 2 Provides both management and routing services on layer 3 Private VLAN Used when some hosts should not be able to communicate with other hosts in the same VLAN There is a primary or promiscuous VLAN to which all the ports are connected Secondary VLANs provide isolation between the ports Isolated VLANs Cannot communicate with other hosts directly Can communicate only with associated promiscuous port Community VLANs: Can communicate with each other and associated promiscous port Switch Ports Access ports Carry the traffic of only the one native VLAN (known as VLAN 1) Trunk ports Carry the traffic of more than one VLAN Useful if required to exchange traffic between more than one switch VLAN identification method is used to identify traffic for a VLAN","title":"Virtual Lan"},{"location":"computer_networks/L2_data_link_layer/virtual_lan#virtual-lan-vlan","text":"Dividing devices in a network logically on layer 2 (data link layer) Broadcast domain Broadcast domain is a network segment In which all the devices in that domain receive a packet broadcasted by a device But it is limited to switches only as routers don't forward a broadcast packet Generally, layer 3 devices divide the broadcast domain But it can also be divided by switches using VLAN Through VLAN, different small sized sub-networks are created Which are comparatively easy to handle Devices that understand VLAN formats & membership are called VLAN aware Three ways to connect devices in a VLAN Trunk link: All connected devices must be VLAN aware Access link: Connects VLAN unaware devices to VLAN aware bridge Hybrid link: Both VLAN aware & unware devices are attached Reduces the need to send traffic to unnecessary destinations and saves bandwidth For example, the traffic is intended for 2 devices But 10 devices are present in the broadcast domain Useful to form virtual groups in an organization based on departments like sales, finance Allows to control broadcast domains, set up firewalls & restrict access Eliminates the need for expensive routers to create specific broadcast domains","title":"Virtual LAN (VLAN)"},{"location":"computer_networks/L2_data_link_layer/virtual_lan#inter-vlan-routing","text":"Required for communication between different VLANs Switch Virtual Interface (SVI) Logical interface on a multilayer switch that processes packets on all switch ports Provides only management services like creating VLAN or telnet/SSH services on layer 2 Provides both management and routing services on layer 3","title":"Inter VLAN Routing"},{"location":"computer_networks/L2_data_link_layer/virtual_lan#private-vlan","text":"Used when some hosts should not be able to communicate with other hosts in the same VLAN There is a primary or promiscuous VLAN to which all the ports are connected Secondary VLANs provide isolation between the ports Isolated VLANs Cannot communicate with other hosts directly Can communicate only with associated promiscuous port Community VLANs: Can communicate with each other and associated promiscous port","title":"Private VLAN"},{"location":"computer_networks/L2_data_link_layer/virtual_lan#switch-ports","text":"Access ports Carry the traffic of only the one native VLAN (known as VLAN 1) Trunk ports Carry the traffic of more than one VLAN Useful if required to exchange traffic between more than one switch VLAN identification method is used to identify traffic for a VLAN","title":"Switch Ports"},{"location":"computer_networks/L2_data_link_layer/mobile_communication","text":"Mobile Communication SIM (Subscriber Identity Module) card Stores subscriber's identification and account information Stores security credentials that allow a device to connect to the network A SIM card plugged into a mobile device forms GSM system GSM (Global System for Mobile Communication) GSM system can be dissected into radio, network & operation subsystems Radio Subsystem Mobile communication occurs in the form of radio waves that travel through air Mobile station (MS) Stores user specific data in SIM card Serial number, card type, PIN, PIN unblocking key, authentication key List of subscribed services Stores dynamic data required for wireless communication Location information, cipher key for encryption & decryption Base station system (BSS) Maintains radio connection to the mobile station Performs coding & decoding of the voice communication This happens through radio equipment present on cell tower Like antennas, amplifiers, signal processors Designates radio frequencies for communication And performs handover from one cell tower to another Network Subsystem Handles the handover from one BSS to another Which enables national & international roaming It is aware of the subscriber location via its databases Home location register & visitor location register The movement of a mobile station is traced And updated in the registers if it leaves the current location area Operation Subsystem Responsible for smooth operations of a network Traffic monitoring, subscriber management, security, accounting, billing This informatino is held in a consolidated database of existing mobile devices This database is called equipment identity register This database is updated to blacklist any stolen device And block communication on the associated SIM","title":"Mobile Communication"},{"location":"computer_networks/L2_data_link_layer/mobile_communication#mobile-communication","text":"SIM (Subscriber Identity Module) card Stores subscriber's identification and account information Stores security credentials that allow a device to connect to the network A SIM card plugged into a mobile device forms GSM system GSM (Global System for Mobile Communication) GSM system can be dissected into radio, network & operation subsystems","title":"Mobile Communication"},{"location":"computer_networks/L2_data_link_layer/mobile_communication#radio-subsystem","text":"Mobile communication occurs in the form of radio waves that travel through air Mobile station (MS) Stores user specific data in SIM card Serial number, card type, PIN, PIN unblocking key, authentication key List of subscribed services Stores dynamic data required for wireless communication Location information, cipher key for encryption & decryption Base station system (BSS) Maintains radio connection to the mobile station Performs coding & decoding of the voice communication This happens through radio equipment present on cell tower Like antennas, amplifiers, signal processors Designates radio frequencies for communication And performs handover from one cell tower to another","title":"Radio Subsystem"},{"location":"computer_networks/L2_data_link_layer/mobile_communication#network-subsystem","text":"Handles the handover from one BSS to another Which enables national & international roaming It is aware of the subscriber location via its databases Home location register & visitor location register The movement of a mobile station is traced And updated in the registers if it leaves the current location area","title":"Network Subsystem"},{"location":"computer_networks/L2_data_link_layer/mobile_communication#operation-subsystem","text":"Responsible for smooth operations of a network Traffic monitoring, subscriber management, security, accounting, billing This informatino is held in a consolidated database of existing mobile devices This database is called equipment identity register This database is updated to blacklist any stolen device And block communication on the associated SIM","title":"Operation Subsystem"},{"location":"computer_networks/L3_network_layer/index","text":"L3: Network Layer Introduction IP (Internet Protocol) IP v6 IP Datagram Fragmentation ICMP (Internet Control Message Protocol) ARP (Address Resolution Protocol) Routing Routing Protocols NAT (Network Address Translation) ISDN (Integrated Services Digital Network) AAA (Authentication, Authorization, Accounting) Access Control WiFi","title":"Index"},{"location":"computer_networks/L3_network_layer/index#l3-network-layer","text":"Introduction IP (Internet Protocol) IP v6 IP Datagram Fragmentation ICMP (Internet Control Message Protocol) ARP (Address Resolution Protocol) Routing Routing Protocols NAT (Network Address Translation) ISDN (Integrated Services Digital Network) AAA (Authentication, Authorization, Accounting) Access Control WiFi","title":"L3: Network Layer"},{"location":"computer_networks/L3_network_layer/introduction","text":"Introduction Basic info Packet: Packet, Datagram Protocols: IP, ICMP, ARP Devices: Router, Brouter Features Data Route Layer Transmission of data from one host to another located in different networks Packet Routing: Selects shortest path to transmit packets from the available routes Adds the IP addresses of the sender & the receiver in the header Functions Device Addressing Adds source & destination addresses to the header Identifies devices and tracks device location Routing: Determine optimal route based on factors like network condition & priority Internetworking: Logical communication between hosts Data plane (Forwarding): Within router, move packets from router's input to output Control plane (Routing): Determine route of packets from source to destination Synchronous Optical Network (SONET) Communication protocol used to transmit a large amount of data over large distances Transfers multiple digital streams at the same time over optical fibre Converts electrical signal to optical signal so that it can travel longer distances Synchronous network A single clock called PRC (Primary Reference Clock) is used To handle the timing of transmission of signals & equipments across the entire network Components Multiplexer: Converts electrical signals to optical signals Demultiplexer: Converts optical signals to electrical signals Regenerator: Repeater that takes an optical signal and increases its strength Add/drop multiplexer Allows to add or remove signals coming from different sources into a given path Functional layers Path layer: Movement of signal from optical source to optical destination Line layer: Movement of signal across physical line (between multiplexers) Section layer: Movement of signal across physical section (neigbouring devices) Photonic layer: Physical specifications for the optical fibre channel","title":"Introduction"},{"location":"computer_networks/L3_network_layer/introduction#introduction","text":"Basic info Packet: Packet, Datagram Protocols: IP, ICMP, ARP Devices: Router, Brouter Features Data Route Layer Transmission of data from one host to another located in different networks Packet Routing: Selects shortest path to transmit packets from the available routes Adds the IP addresses of the sender & the receiver in the header","title":"Introduction"},{"location":"computer_networks/L3_network_layer/introduction#functions","text":"Device Addressing Adds source & destination addresses to the header Identifies devices and tracks device location Routing: Determine optimal route based on factors like network condition & priority Internetworking: Logical communication between hosts Data plane (Forwarding): Within router, move packets from router's input to output Control plane (Routing): Determine route of packets from source to destination","title":"Functions"},{"location":"computer_networks/L3_network_layer/introduction#synchronous-optical-network-sonet","text":"Communication protocol used to transmit a large amount of data over large distances Transfers multiple digital streams at the same time over optical fibre Converts electrical signal to optical signal so that it can travel longer distances Synchronous network A single clock called PRC (Primary Reference Clock) is used To handle the timing of transmission of signals & equipments across the entire network Components Multiplexer: Converts electrical signals to optical signals Demultiplexer: Converts optical signals to electrical signals Regenerator: Repeater that takes an optical signal and increases its strength Add/drop multiplexer Allows to add or remove signals coming from different sources into a given path Functional layers Path layer: Movement of signal from optical source to optical destination Line layer: Movement of signal across physical line (between multiplexers) Section layer: Movement of signal across physical section (neigbouring devices) Photonic layer: Physical specifications for the optical fibre channel","title":"Synchronous Optical Network (SONET)"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol","text":"IP (Internet Protocol) Responsible for delivering packets from the source host to the destination host IP addresses are included in the packet headers Connection-less protocol used for packet switched networks Operates on a best effort delivery model Neither delivery is guaranteed Nor proper sequencing nor avoidance of duplicate delivery Host-to-host communication: Determines the path of transmission Data Encapsulation and Formatting Accepts data from transport layer protocol Ensures that data is sent and received securely Encapsulates data into message known as IP datagram Routing When IP datagram is sent over the same local network (LAN, MAN, WAN) It is known as direct delivery When source and destination are on distant network Then the IP datagram is sent indirectly using routers Fragmentation Maximum Transmission Unit (MTU) Limit imposed on the size of IP datagram by data link layer protocol If datagram > MTU, datagram is split into smaller units So that they can travel over the local network Fragmentation can be done by the sender or intermediate router At the receiver side All the fragments are reassembled to form an original message IP Addressing Logical or software based address to reach a specific host IP addresses are used by internet & higher layers To identify devices and provide internetwork routing 32 bits (4 bytes) unique address having address space of 2^32 Can be written in two notations: dotted decimal & hexadecimal Dotted decimal notation Each segment (byte) can have any value from 0 to 255 (2^8 - 1) No zeroes precede the value in any segment (054 is wrong, 54 is correct) Classful Addressing The 4 bytes of the address are divided into two parts Network ID (Identify the network) Host ID (Identify the host within a network) The class of IP address determines the bytes used for network ID & host ID And the number of total networks and hosts possible More number of bytes assigned for host ID means that more number of hosts are possible Each ISP or network administrator assigns an IP address to each connected device The first address of any network is the network number So in host ID, all bits cannot be set 0 The last address is reserved for broadcast IP So in host ID, all bits cannot be set 1 Problems Millions of class A and many of class B addresses are wasted Number of addresses available in class C is small (254 hosts) And cannot cater to the needs of an organisation Class D & E are reserved and cannot be used Due to these problems Classful addressing was replaced by classless inter-domain routing (CIDR) in 1993 Classes Class A Network ID: 1 byte, Host ID: 3 bytes Starting bits: 0 Format: 0, Network ID (7 bits), Host ID (24 bits) Range: 0.0.0.0 - 127.255.255.255 Class B Network ID: 2 bytes, Host ID: 2 bytes Starting bits: 01 Format: 01, Network ID (14 bits), Host ID (16 bits) Range: 128.0.0.0 - 191.255.255.255 Class C Network ID: 3 bytes, Host ID: 1 byte Starting bits: 110 Format: 110, Network ID (21 bits), Host ID (8 bits) Range: 192.0.0.0 - 223.255.255.255 Class D Multicast addresses Starting bits: 1110 Range: 224.0.0.0 - 239.255.255.255 Class E Reserved for military & experimental purposes Starting bits: 1111 Range: 240.0.0.0 - 255.255.255.255 Classless Addressing Invented to keep internet running out of IP addresses and reduce its wastage Also known as Classless Inter-Domain Routing (CIDR) Subnetting Partitioning a single physical network into smaller logical sub-networks Divides a large block of addresses into several contiguous sub-blocks And assigns them to smaller networks A subnet or subnetwork is a network inside a network Reduces network traffic & complexity Traffic can travel shorter distance without passing through unnecessary routers Subnet Mask 32-bit number that masks an IP address by dividing it into network and host address Used to identify the subnet to which an IP address belongs Subnet mask: Network bits are set to 1 and host bits are set to 0 Network address: Bitwise AND is performed on the IP address and the mask Broadcast address: Bitwise OR is performed on the network address and the inverted mask Number of hosts per subnet: 2 ^ (32 - given bits for mask) - 2 The address includes the number of bits for mask (assigned to the network address) Usually represented by /n Classes Class A: /8, 255.0.0.0 Class B: /16, 255.255.0.0 Class C: /24, 255.255.255.0 Two addresses are reserved First address is the network address Last address is the broadcast address Example 216.3.128.12/25 32 bits = 25 bits (network) + 7 bits (host) Put 25 bits as 1 and 7 bits as 0 to get the subnet mask 216.3.128.12 with subnet mask of 255.255.255.128 Network address: 216.3.128.0 Broadcast address: 216.3.128.127 Host IP range: 216.3.128.0 to 216.3.128.126 IP class: C Supernetting Combining multiple networks to form a bigger network Process of aggregating routes for multiple smaller networks Saves storage space in routing table Simplifies routing decisions Reduces route advertisements to neighboring gateways Conditions All the networks should be contiguous The block size of every network should be equal and must be in form of 2^n First network ID should be exactly divisible by whole size of supernet","title":"Ip Internet Protocol"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol#ip-internet-protocol","text":"Responsible for delivering packets from the source host to the destination host IP addresses are included in the packet headers Connection-less protocol used for packet switched networks Operates on a best effort delivery model Neither delivery is guaranteed Nor proper sequencing nor avoidance of duplicate delivery Host-to-host communication: Determines the path of transmission Data Encapsulation and Formatting Accepts data from transport layer protocol Ensures that data is sent and received securely Encapsulates data into message known as IP datagram Routing When IP datagram is sent over the same local network (LAN, MAN, WAN) It is known as direct delivery When source and destination are on distant network Then the IP datagram is sent indirectly using routers","title":"IP (Internet Protocol)"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol#fragmentation","text":"Maximum Transmission Unit (MTU) Limit imposed on the size of IP datagram by data link layer protocol If datagram > MTU, datagram is split into smaller units So that they can travel over the local network Fragmentation can be done by the sender or intermediate router At the receiver side All the fragments are reassembled to form an original message","title":"Fragmentation"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol#ip-addressing","text":"Logical or software based address to reach a specific host IP addresses are used by internet & higher layers To identify devices and provide internetwork routing 32 bits (4 bytes) unique address having address space of 2^32 Can be written in two notations: dotted decimal & hexadecimal Dotted decimal notation Each segment (byte) can have any value from 0 to 255 (2^8 - 1) No zeroes precede the value in any segment (054 is wrong, 54 is correct)","title":"IP Addressing"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol#classful-addressing","text":"The 4 bytes of the address are divided into two parts Network ID (Identify the network) Host ID (Identify the host within a network) The class of IP address determines the bytes used for network ID & host ID And the number of total networks and hosts possible More number of bytes assigned for host ID means that more number of hosts are possible Each ISP or network administrator assigns an IP address to each connected device The first address of any network is the network number So in host ID, all bits cannot be set 0 The last address is reserved for broadcast IP So in host ID, all bits cannot be set 1 Problems Millions of class A and many of class B addresses are wasted Number of addresses available in class C is small (254 hosts) And cannot cater to the needs of an organisation Class D & E are reserved and cannot be used Due to these problems Classful addressing was replaced by classless inter-domain routing (CIDR) in 1993","title":"Classful Addressing"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol#classes","text":"Class A Network ID: 1 byte, Host ID: 3 bytes Starting bits: 0 Format: 0, Network ID (7 bits), Host ID (24 bits) Range: 0.0.0.0 - 127.255.255.255 Class B Network ID: 2 bytes, Host ID: 2 bytes Starting bits: 01 Format: 01, Network ID (14 bits), Host ID (16 bits) Range: 128.0.0.0 - 191.255.255.255 Class C Network ID: 3 bytes, Host ID: 1 byte Starting bits: 110 Format: 110, Network ID (21 bits), Host ID (8 bits) Range: 192.0.0.0 - 223.255.255.255 Class D Multicast addresses Starting bits: 1110 Range: 224.0.0.0 - 239.255.255.255 Class E Reserved for military & experimental purposes Starting bits: 1111 Range: 240.0.0.0 - 255.255.255.255","title":"Classes"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol#classless-addressing","text":"Invented to keep internet running out of IP addresses and reduce its wastage Also known as Classless Inter-Domain Routing (CIDR)","title":"Classless Addressing"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol#subnetting","text":"Partitioning a single physical network into smaller logical sub-networks Divides a large block of addresses into several contiguous sub-blocks And assigns them to smaller networks A subnet or subnetwork is a network inside a network Reduces network traffic & complexity Traffic can travel shorter distance without passing through unnecessary routers","title":"Subnetting"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol#subnet-mask","text":"32-bit number that masks an IP address by dividing it into network and host address Used to identify the subnet to which an IP address belongs Subnet mask: Network bits are set to 1 and host bits are set to 0 Network address: Bitwise AND is performed on the IP address and the mask Broadcast address: Bitwise OR is performed on the network address and the inverted mask Number of hosts per subnet: 2 ^ (32 - given bits for mask) - 2 The address includes the number of bits for mask (assigned to the network address) Usually represented by /n Classes Class A: /8, 255.0.0.0 Class B: /16, 255.255.0.0 Class C: /24, 255.255.255.0 Two addresses are reserved First address is the network address Last address is the broadcast address","title":"Subnet Mask"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol#example","text":"216.3.128.12/25 32 bits = 25 bits (network) + 7 bits (host) Put 25 bits as 1 and 7 bits as 0 to get the subnet mask 216.3.128.12 with subnet mask of 255.255.255.128 Network address: 216.3.128.0 Broadcast address: 216.3.128.127 Host IP range: 216.3.128.0 to 216.3.128.126 IP class: C","title":"Example"},{"location":"computer_networks/L3_network_layer/ip_internet_protocol#supernetting","text":"Combining multiple networks to form a bigger network Process of aggregating routes for multiple smaller networks Saves storage space in routing table Simplifies routing decisions Reduces route advertisements to neighboring gateways Conditions All the networks should be contiguous The block size of every network should be equal and must be in form of 2^n First network ID should be exactly divisible by whole size of supernet","title":"Supernetting"},{"location":"computer_networks/L3_network_layer/ip_v6","text":"Internet Protocol version 6 (IPv6) Developed to deal with the problem of IPv4 exhaustion Address depletion as the need for electronic devices rose quickly When internet of things (IOT) came into picture 128-bits address having address space of 2^128 which is way bigger than IPv4 Uses hexadecimal format separated by colon Components in address 8 groups, each group represents 2 bytes Each hexdigit is of 4 bits Better header format Options are separated from the base header And inserted when needed between the base header & upper layer data Simplifies and speeds up the routing process Because most of the options don't need to be checked by routers Allows new options for additional functionalities And extension of protocol for new technologies Provides better security, priortization, real-time communication, mobile device support Addressing Methods Unicast Address Identifies a single network interface Multicast Address Used by multiple hosts which need not be geographically together Broadcast address was removed due to performance reasons Though it can be achieved using multicasts Anycast Addresss Assigned to a group of interfaces Any packet sent is delivered to only one member interface Mostly the nearest host Unicast Addresses Provider based: Used for global communication, contains provider id & subscriber id Geography based: Based on location, contains details like lat & long Local Link local: Used for addressing a single link Site local: Equivalent to a private IP address in IPv4","title":"Ip V6"},{"location":"computer_networks/L3_network_layer/ip_v6#internet-protocol-version-6-ipv6","text":"Developed to deal with the problem of IPv4 exhaustion Address depletion as the need for electronic devices rose quickly When internet of things (IOT) came into picture 128-bits address having address space of 2^128 which is way bigger than IPv4 Uses hexadecimal format separated by colon Components in address 8 groups, each group represents 2 bytes Each hexdigit is of 4 bits Better header format Options are separated from the base header And inserted when needed between the base header & upper layer data Simplifies and speeds up the routing process Because most of the options don't need to be checked by routers Allows new options for additional functionalities And extension of protocol for new technologies Provides better security, priortization, real-time communication, mobile device support","title":"Internet Protocol version 6 (IPv6)"},{"location":"computer_networks/L3_network_layer/ip_v6#addressing-methods","text":"Unicast Address Identifies a single network interface Multicast Address Used by multiple hosts which need not be geographically together Broadcast address was removed due to performance reasons Though it can be achieved using multicasts Anycast Addresss Assigned to a group of interfaces Any packet sent is delivered to only one member interface Mostly the nearest host","title":"Addressing Methods"},{"location":"computer_networks/L3_network_layer/ip_v6#unicast-addresses","text":"Provider based: Used for global communication, contains provider id & subscriber id Geography based: Based on location, contains details like lat & long Local Link local: Used for addressing a single link Site local: Equivalent to a private IP address in IPv4","title":"Unicast Addresses"},{"location":"computer_networks/L3_network_layer/ip_datagram_fragmentation","text":"IP Datagram Fragmentation Different networks may have different maximum transmission unit (MTU) For example, it can be due to differences in LAN technology MTU determine the maximum size of a data packet that can be transmitted over that network When one network wants to transmit datagrams to a network with a smaller MTU The routers on the path may fragment and reassemble datagrams Each of the fragments contain a portion of the original packet Along with additional info that identifies a fragment's position in the original packet And how it fits into the sequence of fragments Done by the network layer at the destination side, usually at the routers Source side does not require fragmentation due to segmentation by transport layer Segmentation is done in such a way that Resulting data can easily fit in a frame without the need of fragmentation Delays Fragmentation can cause delays and other network issues Increased processing and memory overhead from the network devices involved in transmission Increased likelihood of packet loss or corruption Since each fragment is transmitted separately If any fragments are lost or corrupted The entire packet must be retransmitted which can introduce delays & network congestion Reassembly delays especially if there are delays in receiving all the fragments Or if they arrive out of order Avoiding Delays To avoid these issues, it is generally recommended to avoid fragmentation whenever possible By ensuring that packets are appropriately sized for the network links they will traverse This can be done through path MTU discovery It allows devices to determine the maximum packet size That can be transmitted without fragementation on a given network Additionaly, QoS mechanisms can be implemented To prioritize traffic and reduce delays by congestion Working When a packet is received at the router, destination is examined and MTU is determined If the size of the packet is bigger than MTU 'Do not fragment' (DF) bit is set to 0 in header Packet is fragmented into parts and sent one by one Maximum size of each fragment is (MTU - header size) Each fragment is converted to a packet Total length field is changed to the size of the fragment 'More fragment' (MF) bit is set for all the fragment packets except the last one Fragment offset field is set based on the number of fragments, which is used to identify the sequence of frames Header checksum is re-calculated Reassembly of fragment takes place only at the destination And not at routers since packets take an independent path","title":"Ip Datagram Fragmentation"},{"location":"computer_networks/L3_network_layer/ip_datagram_fragmentation#ip-datagram-fragmentation","text":"Different networks may have different maximum transmission unit (MTU) For example, it can be due to differences in LAN technology MTU determine the maximum size of a data packet that can be transmitted over that network When one network wants to transmit datagrams to a network with a smaller MTU The routers on the path may fragment and reassemble datagrams Each of the fragments contain a portion of the original packet Along with additional info that identifies a fragment's position in the original packet And how it fits into the sequence of fragments Done by the network layer at the destination side, usually at the routers Source side does not require fragmentation due to segmentation by transport layer Segmentation is done in such a way that Resulting data can easily fit in a frame without the need of fragmentation","title":"IP Datagram Fragmentation"},{"location":"computer_networks/L3_network_layer/ip_datagram_fragmentation#delays","text":"Fragmentation can cause delays and other network issues Increased processing and memory overhead from the network devices involved in transmission Increased likelihood of packet loss or corruption Since each fragment is transmitted separately If any fragments are lost or corrupted The entire packet must be retransmitted which can introduce delays & network congestion Reassembly delays especially if there are delays in receiving all the fragments Or if they arrive out of order","title":"Delays"},{"location":"computer_networks/L3_network_layer/ip_datagram_fragmentation#avoiding-delays","text":"To avoid these issues, it is generally recommended to avoid fragmentation whenever possible By ensuring that packets are appropriately sized for the network links they will traverse This can be done through path MTU discovery It allows devices to determine the maximum packet size That can be transmitted without fragementation on a given network Additionaly, QoS mechanisms can be implemented To prioritize traffic and reduce delays by congestion","title":"Avoiding Delays"},{"location":"computer_networks/L3_network_layer/ip_datagram_fragmentation#working","text":"When a packet is received at the router, destination is examined and MTU is determined If the size of the packet is bigger than MTU 'Do not fragment' (DF) bit is set to 0 in header Packet is fragmented into parts and sent one by one Maximum size of each fragment is (MTU - header size) Each fragment is converted to a packet Total length field is changed to the size of the fragment 'More fragment' (MF) bit is set for all the fragment packets except the last one Fragment offset field is set based on the number of fragments, which is used to identify the sequence of frames Header checksum is re-calculated Reassembly of fragment takes place only at the destination And not at routers since packets take an independent path","title":"Working"},{"location":"computer_networks/L3_network_layer/icmp_internet_control_message_protocol","text":"ICMP (Internet Control Message Protocol) Mostly utilized on network equipment like routers for error handling Provides hosts with information about network problems Encapsulated within IP datagrams with specific headers & data Helps in network diagnosis by using traceroute and ping utility IP depends on ICMP for sending error and control messages Because it does not have an inbuilt mechanism for it Connection-less protocol Doesn't need to establish a connection With the destination device before sending a message Types of Messages Source Quench Message Request to decrease traffic rate for messages sent to the host destination When the congested router is far away from the source ICMP will send this message hop by hop So that every router reduces the speed of transmission Parameter Problem Message When a packet comes to a router The calculated header checksum should be equal to the received header checksum If there is a mismatch, the packet is dropped by the router ICMP informs the source about this by sending a parameter problem message Redirection Message If a host tries to send data through router R1 And if R1 sends data to R2 and there is a direct way from the host to R2 Then R1 will send a redirect message to the source to inform about the best route Other messages Time exceeded Destination unreachable Traceroute Traces a packet from computer to host And shows the number of hops & time required to reach there Works by sending packets with low survival time i.e. time to live (TTL) It specifies how many hops can the packet survive When the packet expires The node where it expired returns the packet and identifies itself By increasing the TTL gradually, it is able to identify intermediate hosts If any of the hops returns with 'request timed out', it denotes netowork congestion Ping Helps to check if a particular IP address is accessible or not Works by sending a packet to the specified address and waits for a reply Measures round trip time and reports errors Also used to check if the computers on a local network are active","title":"Icmp Internet Control Message Protocol"},{"location":"computer_networks/L3_network_layer/icmp_internet_control_message_protocol#icmp-internet-control-message-protocol","text":"Mostly utilized on network equipment like routers for error handling Provides hosts with information about network problems Encapsulated within IP datagrams with specific headers & data Helps in network diagnosis by using traceroute and ping utility IP depends on ICMP for sending error and control messages Because it does not have an inbuilt mechanism for it Connection-less protocol Doesn't need to establish a connection With the destination device before sending a message","title":"ICMP (Internet Control Message Protocol)"},{"location":"computer_networks/L3_network_layer/icmp_internet_control_message_protocol#types-of-messages","text":"Source Quench Message Request to decrease traffic rate for messages sent to the host destination When the congested router is far away from the source ICMP will send this message hop by hop So that every router reduces the speed of transmission Parameter Problem Message When a packet comes to a router The calculated header checksum should be equal to the received header checksum If there is a mismatch, the packet is dropped by the router ICMP informs the source about this by sending a parameter problem message Redirection Message If a host tries to send data through router R1 And if R1 sends data to R2 and there is a direct way from the host to R2 Then R1 will send a redirect message to the source to inform about the best route Other messages Time exceeded Destination unreachable","title":"Types of Messages"},{"location":"computer_networks/L3_network_layer/icmp_internet_control_message_protocol#traceroute","text":"Traces a packet from computer to host And shows the number of hops & time required to reach there Works by sending packets with low survival time i.e. time to live (TTL) It specifies how many hops can the packet survive When the packet expires The node where it expired returns the packet and identifies itself By increasing the TTL gradually, it is able to identify intermediate hosts If any of the hops returns with 'request timed out', it denotes netowork congestion","title":"Traceroute"},{"location":"computer_networks/L3_network_layer/icmp_internet_control_message_protocol#ping","text":"Helps to check if a particular IP address is accessible or not Works by sending a packet to the specified address and waits for a reply Measures round trip time and reports errors Also used to check if the computers on a local network are active","title":"Ping"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol","text":"ARP (Address Resolution Protocol) Finds the hardware address of a host from a known address Network layer to data link layer mapping process Most applications use logical address (IP address) to send & receive messages But having IP address is necessary but not sufficient The actual communication happens over the physical address (MAC address) ARP Cache After resolving the MAC address ARP sends it to the source where it is stored in a table for future reference The cached MAC address may timeout after sometime Working It broadcasts a discovery packet to all the devices of the source network Requesting the MAC address of intended destination The packet will be discarded by everyone except the intented receiver host The devices peel the header of the data link layer called frame And transfer the packet to the network layer Where network ID of the packet is validated with the destination IP's network ID If it's equal It responds to the source with the MAC address of the destination using unicast packet Sender updates ARP cache and starts sending unicast messages to the destination Else the packet reaches the gateway of the network And broadcasts packet to the connected devices and validates their network ID ARP Spoofing or Poisoning Attacker sends a falsified ARP request over LAN Which connects its MAC address to the legitimate server After that, the attacker will start receiving the data intended for that IP address It can intercept data frames, modify traffic, stop data in transit Can act as the opening for other major attacks Like man in the middle, denial of service, session hijacking Types Reverse ARP Used in LAN by client machines For requesting IP address from the gateway router's ARP table Whenever a new machines comes The machine sends a RARP broadcast packet containing its own MAC address A special host configured inside LAN replies to these broadcast packages If an entry is found in the mapping table It sends the response packet with the IP address Has been replaced by BOOTP (Bootstrap Protocol) and DHCP Proxy ARP Resolves IP address to MAC address for devices separated into network segments Connected through a router in the same IP or sub-network When devices are not in the same data link layer network but are in the same IP network They try to transmit data to each other as if they were on the local network But the router that separates the devices cannot broadcast messages Because routers do not pass hardware-layer broadcasts The proxy router that resides between local networks responds with its MAC address As if it were the router to which the broadcast is addressed The sending device after receiving the MAC address of the proxy router Sends datagram to the proxy router which in turn sends it to the destination device Inverse ARP Uses MAC address to find the IP address (inverse of ARP) Enabled by default in ATM (Asynchronous Transfer Mode) networks and frame relays Gratuitous ARP Used in advanced network scenarios and detecting duplicate IP addresses Performed by computer while booting up When NIC (Network Interface Card) is powered for the first time It automatically broadcast its MAC address to entire network After that, MAC address of the computer is known to every switch And allows DHCP servers to know where to send the IP address if requested Packet Flow First of all, it is checked if the destination is present in the same network or not How the source device will know that AND operation is performed between Source IP address and source subnet mask Destination IP address and source subnet mask If the resultant of both are same then the destination is present in the same network Same Network It is checked if the ARP has been resolved or not To resolve ARP, ARP request is broadcasted to all the other hosts in the network This generates two packets, one for ICMP & other for ARP The broadcast is performed with the help of a switch Routers don't forward broadcast packets The request is received by the target host And it unicasts an ARP reply specifying its MAC address The reply is received by the switch and forwarded to the source host The switch is able to do so because it has an entry For the source host in its MAC table This was added when the source host broadcasted the ARP request After resolution, the ICMP ack packet is unicasted from the destination to the source host Different Network The packet is delivered to the default gateway first Which in turn delivers to the destination host MAC address never crosses its broadcast domain At the source network It is checked if the ARP has not been resolved or not To resolve ARP, ARP request is broadcasted to all the other hosts in the network This generates two packets, one for ICMP & other for ARP The router accepts the request and unicasts the ARP reply back to the source After resolution, ICMP packet is unicasted to the default gateway At the destination network Now the ARP has to be resolved again Because the router has to deliver the packet to the destination host The ARP request is broadcasted in the destination network and the same process follows ICMP echo-request packet is unicasted to the destination host The destination host generates an ICMP echo reply in response Which is delivered to the router and then unicasted to the source host The MAC addresses of the source & destination are used only till their respective router After that, the router's MAC address is used","title":"Arp Address Resolution Protocol"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#arp-address-resolution-protocol","text":"Finds the hardware address of a host from a known address Network layer to data link layer mapping process Most applications use logical address (IP address) to send & receive messages But having IP address is necessary but not sufficient The actual communication happens over the physical address (MAC address) ARP Cache After resolving the MAC address ARP sends it to the source where it is stored in a table for future reference The cached MAC address may timeout after sometime","title":"ARP (Address Resolution Protocol)"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#working","text":"It broadcasts a discovery packet to all the devices of the source network Requesting the MAC address of intended destination The packet will be discarded by everyone except the intented receiver host The devices peel the header of the data link layer called frame And transfer the packet to the network layer Where network ID of the packet is validated with the destination IP's network ID If it's equal It responds to the source with the MAC address of the destination using unicast packet Sender updates ARP cache and starts sending unicast messages to the destination Else the packet reaches the gateway of the network And broadcasts packet to the connected devices and validates their network ID","title":"Working"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#arp-spoofing-or-poisoning","text":"Attacker sends a falsified ARP request over LAN Which connects its MAC address to the legitimate server After that, the attacker will start receiving the data intended for that IP address It can intercept data frames, modify traffic, stop data in transit Can act as the opening for other major attacks Like man in the middle, denial of service, session hijacking","title":"ARP Spoofing or Poisoning"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#types","text":"","title":"Types"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#reverse-arp","text":"Used in LAN by client machines For requesting IP address from the gateway router's ARP table Whenever a new machines comes The machine sends a RARP broadcast packet containing its own MAC address A special host configured inside LAN replies to these broadcast packages If an entry is found in the mapping table It sends the response packet with the IP address Has been replaced by BOOTP (Bootstrap Protocol) and DHCP","title":"Reverse ARP"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#proxy-arp","text":"Resolves IP address to MAC address for devices separated into network segments Connected through a router in the same IP or sub-network When devices are not in the same data link layer network but are in the same IP network They try to transmit data to each other as if they were on the local network But the router that separates the devices cannot broadcast messages Because routers do not pass hardware-layer broadcasts The proxy router that resides between local networks responds with its MAC address As if it were the router to which the broadcast is addressed The sending device after receiving the MAC address of the proxy router Sends datagram to the proxy router which in turn sends it to the destination device","title":"Proxy ARP"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#inverse-arp","text":"Uses MAC address to find the IP address (inverse of ARP) Enabled by default in ATM (Asynchronous Transfer Mode) networks and frame relays","title":"Inverse ARP"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#gratuitous-arp","text":"Used in advanced network scenarios and detecting duplicate IP addresses Performed by computer while booting up When NIC (Network Interface Card) is powered for the first time It automatically broadcast its MAC address to entire network After that, MAC address of the computer is known to every switch And allows DHCP servers to know where to send the IP address if requested","title":"Gratuitous ARP"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#packet-flow","text":"First of all, it is checked if the destination is present in the same network or not How the source device will know that AND operation is performed between Source IP address and source subnet mask Destination IP address and source subnet mask If the resultant of both are same then the destination is present in the same network","title":"Packet Flow"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#same-network","text":"It is checked if the ARP has been resolved or not To resolve ARP, ARP request is broadcasted to all the other hosts in the network This generates two packets, one for ICMP & other for ARP The broadcast is performed with the help of a switch Routers don't forward broadcast packets The request is received by the target host And it unicasts an ARP reply specifying its MAC address The reply is received by the switch and forwarded to the source host The switch is able to do so because it has an entry For the source host in its MAC table This was added when the source host broadcasted the ARP request After resolution, the ICMP ack packet is unicasted from the destination to the source host","title":"Same Network"},{"location":"computer_networks/L3_network_layer/arp_address_resolution_protocol#different-network","text":"The packet is delivered to the default gateway first Which in turn delivers to the destination host MAC address never crosses its broadcast domain At the source network It is checked if the ARP has not been resolved or not To resolve ARP, ARP request is broadcasted to all the other hosts in the network This generates two packets, one for ICMP & other for ARP The router accepts the request and unicasts the ARP reply back to the source After resolution, ICMP packet is unicasted to the default gateway At the destination network Now the ARP has to be resolved again Because the router has to deliver the packet to the destination host The ARP request is broadcasted in the destination network and the same process follows ICMP echo-request packet is unicasted to the destination host The destination host generates an ICMP echo reply in response Which is delivered to the router and then unicasted to the source host The MAC addresses of the source & destination are used only till their respective router After that, the router's MAC address is used","title":"Different Network"},{"location":"computer_networks/L3_network_layer/routing","text":"Routing Parameters Performance Criteria Number of hops Cost (send packet with high bandwidth path) Delay (size of queue) Throughput time Decision Time When to decide to route a packet Per packet (datagram) or per session (virtual circuit) Decision Place Who will decide about routing Each node (distributed) or central node (centralized) or originate node (source) Network information Source: local, adjacent node, nodes along the route, all nodes Update time: continuous, periodic, major load change, topology change Strategies Fixed Routing A route is selected for each source & destination pair of nodes in the network The route is fixed and changes only if the topology changes Central routing matrix is created based on the least cost path It shows each source-destination and identity of the next node on the route Stored in the network control center, but if that fails everything will collapse Famous path algorithms: dijkstra, bellman ford Doesn't react to failure or network congestion Flooding Every incoming packet is sent out on every outgoing node All possible routes between the source & destination are tried Generates a vast amount of duplicate packets Requires no network info like topology, load condition, cost of different paths If an approximation is known, a hop counter is sent which is decremented at each hop The packet is discarded when the counter becomes zero Highly robust, always chooses the shortest path But wastes a lot of network resources and leads to congestion Used to send emergency messages or in military applications Redundant Link Problems Redundant links are used to prevent nasty network failures By providing backups but it can cause some problems Broadcast storm A switch forwards out a broadcast frame generated by another device to all its hosts If no loop avoidance schemes are applied, the switches will flood broadcasts endlessly This can shut down the entire network in seconds by consuming all the bandwidth Multiple copies A device receives multiple copies of the same frame From different network segements at the same time If a protocol cannot handle duplicate transmission, it can be a problem MAC table thrashing Switches use MAC address table to forward frames When a switch receives a frame It makes an entry of the device mac address with the switch port on which it's received But if the switch receives the frame of the same source from multiple links It can be confusing for the switch to make an entry This can lead to unstability in MAC table Spanning Tree Protocol (STP) is used to prevent these loops It will block down a port path for frame delivery at a time If one path goes down, then the blocked path becomes active Administrative Distance (AD) Used to rate the trustworthiness of routing information received from a neighbor router The route with the least AD is selected as the best route and placed in the routing table It is an integer value from 0 to 255 0 shows that the route is most trusted 255 means that no traffic will be passed through that route Default AD Connected interface: 0, Static route: 1 External BGP: 20 EIGRP: 90, OSPF: 110, RIP: 120 External EIGRP: 170, Internal BGP: 200 Unknown (not used): 255 Autonomous System (AS) Group of routers & networks working under a single administrative domain 16-bit value that defines the routing domain of the routers (1 to 65535) Public AS number Service provider provides a public AS If the customer is connected to multiple ISPs (mutli home network) Ranges from 1 to 64511 Private AS number Service provider provides a private AS If the customer wants multi-connection to a single ISP For example, single home or dual home network Longest Prefix Matching in Routers IP prefix All computers on one network have the same IP prefix For example, in 192.24.0.0/18, first 18 bits of the address is prefix Forwarding Moving incoming packets to the appropriate interface Routers use a forwarding table To decide which incoming packets should be forwarded to which hop They search the destination address's IP prefix in the forwarding table Prefixes might overlap since classless addressing is used everywhere In that case, routers use the longest prefix matching rule The table entry with the longest prefix matching With the incoming packet's destination IP is considered","title":"Routing"},{"location":"computer_networks/L3_network_layer/routing#routing","text":"","title":"Routing"},{"location":"computer_networks/L3_network_layer/routing#parameters","text":"Performance Criteria Number of hops Cost (send packet with high bandwidth path) Delay (size of queue) Throughput time Decision Time When to decide to route a packet Per packet (datagram) or per session (virtual circuit) Decision Place Who will decide about routing Each node (distributed) or central node (centralized) or originate node (source) Network information Source: local, adjacent node, nodes along the route, all nodes Update time: continuous, periodic, major load change, topology change","title":"Parameters"},{"location":"computer_networks/L3_network_layer/routing#strategies","text":"","title":"Strategies"},{"location":"computer_networks/L3_network_layer/routing#fixed-routing","text":"A route is selected for each source & destination pair of nodes in the network The route is fixed and changes only if the topology changes Central routing matrix is created based on the least cost path It shows each source-destination and identity of the next node on the route Stored in the network control center, but if that fails everything will collapse Famous path algorithms: dijkstra, bellman ford Doesn't react to failure or network congestion","title":"Fixed Routing"},{"location":"computer_networks/L3_network_layer/routing#flooding","text":"Every incoming packet is sent out on every outgoing node All possible routes between the source & destination are tried Generates a vast amount of duplicate packets Requires no network info like topology, load condition, cost of different paths If an approximation is known, a hop counter is sent which is decremented at each hop The packet is discarded when the counter becomes zero Highly robust, always chooses the shortest path But wastes a lot of network resources and leads to congestion Used to send emergency messages or in military applications","title":"Flooding"},{"location":"computer_networks/L3_network_layer/routing#redundant-link-problems","text":"Redundant links are used to prevent nasty network failures By providing backups but it can cause some problems Broadcast storm A switch forwards out a broadcast frame generated by another device to all its hosts If no loop avoidance schemes are applied, the switches will flood broadcasts endlessly This can shut down the entire network in seconds by consuming all the bandwidth Multiple copies A device receives multiple copies of the same frame From different network segements at the same time If a protocol cannot handle duplicate transmission, it can be a problem MAC table thrashing Switches use MAC address table to forward frames When a switch receives a frame It makes an entry of the device mac address with the switch port on which it's received But if the switch receives the frame of the same source from multiple links It can be confusing for the switch to make an entry This can lead to unstability in MAC table Spanning Tree Protocol (STP) is used to prevent these loops It will block down a port path for frame delivery at a time If one path goes down, then the blocked path becomes active","title":"Redundant Link Problems"},{"location":"computer_networks/L3_network_layer/routing#administrative-distance-ad","text":"Used to rate the trustworthiness of routing information received from a neighbor router The route with the least AD is selected as the best route and placed in the routing table It is an integer value from 0 to 255 0 shows that the route is most trusted 255 means that no traffic will be passed through that route Default AD Connected interface: 0, Static route: 1 External BGP: 20 EIGRP: 90, OSPF: 110, RIP: 120 External EIGRP: 170, Internal BGP: 200 Unknown (not used): 255","title":"Administrative Distance (AD)"},{"location":"computer_networks/L3_network_layer/routing#autonomous-system-as","text":"Group of routers & networks working under a single administrative domain 16-bit value that defines the routing domain of the routers (1 to 65535) Public AS number Service provider provides a public AS If the customer is connected to multiple ISPs (mutli home network) Ranges from 1 to 64511 Private AS number Service provider provides a private AS If the customer wants multi-connection to a single ISP For example, single home or dual home network","title":"Autonomous System (AS)"},{"location":"computer_networks/L3_network_layer/routing#longest-prefix-matching-in-routers","text":"IP prefix All computers on one network have the same IP prefix For example, in 192.24.0.0/18, first 18 bits of the address is prefix Forwarding Moving incoming packets to the appropriate interface Routers use a forwarding table To decide which incoming packets should be forwarded to which hop They search the destination address's IP prefix in the forwarding table Prefixes might overlap since classless addressing is used everywhere In that case, routers use the longest prefix matching rule The table entry with the longest prefix matching With the incoming packet's destination IP is considered","title":"Longest Prefix Matching in Routers"},{"location":"computer_networks/L3_network_layer/routing_protocols","text":"Routing Protocols Packet Types There are two types of packets used in the network layer Data packets Used to transfer user data Supported by routed protocols like IP Route update packets Used to update info about networks connected to all the routers To neighbouring routers Supported by routing protocols Like RIP (Routing Information Protocol), OSPF (Open Shortest Path First) Routing Protocols Help routers determine the best path for data to reach its destination Based on factors like network congestion, network latency, network distance Can detect failures and redirect traffic to alternative paths Allow networks to grow & change dyanmically Without any manual reconfiguration of individual routers A routing table is created which contains information about the routes Types Static or Non-adaptive Routes are manually configured And they are not dynamically updated based on network changes Best suited for small networks where topology does not change Dynamic or Adaptive Routes are automatically updated based on network changes Topology, load, delay, distance, number of hops, estimated transit time When a router finds a change in topology, it advertises to all other routers Best suited for large & complex networks where topology changes frequently Default Router is configured to send all packets toward a single router (next hop) It is forwared to the default router Irrespective of which network the packet belongs Heirarchical Network is divided into multiple levels or domains With each level having its own routing protocol Best suited for large & complex networks That needs to be divided into manageable sections Dynamic Routing Protocols Distance Vector Routing Protocol Selects the best path on the basis of hop counts to reach the destination network Each router computes distance of its immediate neighbours Router shares knowledge about whole network to its neighbours Updates (routing info) is not broadcasted But shared to neighbouring nodes periodically A router shares its knowledge about the whole network (full routing tables) This is called routing on rumours Works on bellman ford algorithm Each router maintains a distance vector table Containing its distance from all possible destination nodes Characteristics Based on: Local knowledge Bandwidth required: Less (local sharing, small packets, no flooding) Information sharing: Regular intervals Algorithm to make routing table: Bellman-ford Traffic: Less Convergence: Slow Problems: Count to infinity, Slow convergence, Persistent loops Routing Loops Routing loops is the main issue since bellman ford algorithm cannot prevent loops Usually occur when an interface goes down or two routers send updates at the same time Routing loops cause count to infinity problem Wrong information keeps propogating within each other toward infinity Let's say AB = 1 & BC = 1, so AC = 2 If B & C are disconnected, B will remove C from its table Meanwhile, if A advertises that AC = 2, then B updates BC = 3 since AB = 1 A then receives update from B that BC = 3 and it updates AC = 4 since AB = 1 Spreading the bad information is called route poisoning Solutions: Poison reverse, Split horizon Examples: RIP (Routing Information Protocol) Link State Routing Protocol Knows more about internetwork than distance vectors Each router has node map and calculates best path Router shares knowledge of its neighbours with all the routers Maintains neighbor table, topology table, routing table Knowledge about the neighborhood Instead of sending routing table, a router sends info about its neighborhood only A router broadcasts its identities and cost of directly attached links Hello messages or keep alive messages are used for neighbor discovery & recovery Flooding In flooding, each router sends info To every other router on the internetwork except its neighbors Every router that receives the packet sends the copies to all the neighbors Information Sharing Router sends information only when a change occurs in the information Only the updates requested by the neighbor router are exchanged Initially each node knows the cost of its neighbors And finally each node knows the entire graph Dijkstra's algorithm is used to calculate optimal routes Characteristics Based on: Global knowledge Bandwidth required: More (large packets, flooding) Information sharing: Whenever there is a change Algorithm to make routing table: Dijkstra Traffic: More Convergence: Fast Problems: Heavy traffic due to packet flooding Examples: OSPF (Open Shortest Path First) Advanced Distance Vector Routing Protocol Hybrid of distance vector & link state routing protocols Examples: EIGRP (Enhanced Interior Gateway Routing Protocol) Redistribution Using a single routing protocol in an organization is preferred But under some conditions, we have to use multiple protocols Like company mergers, multi-vendor devices Advertising a route learned through a routing protocol Into another routing protocol is called redistribution We have to define metric of the routing protocol in the advertising routing protocol For example, to advertise EIGRP into RIP, we have to define hop count (metric of RIP)","title":"Routing Protocols"},{"location":"computer_networks/L3_network_layer/routing_protocols#routing-protocols","text":"","title":"Routing Protocols"},{"location":"computer_networks/L3_network_layer/routing_protocols#packet-types","text":"There are two types of packets used in the network layer Data packets Used to transfer user data Supported by routed protocols like IP Route update packets Used to update info about networks connected to all the routers To neighbouring routers Supported by routing protocols Like RIP (Routing Information Protocol), OSPF (Open Shortest Path First)","title":"Packet Types"},{"location":"computer_networks/L3_network_layer/routing_protocols#routing-protocols_1","text":"Help routers determine the best path for data to reach its destination Based on factors like network congestion, network latency, network distance Can detect failures and redirect traffic to alternative paths Allow networks to grow & change dyanmically Without any manual reconfiguration of individual routers A routing table is created which contains information about the routes","title":"Routing Protocols"},{"location":"computer_networks/L3_network_layer/routing_protocols#types","text":"Static or Non-adaptive Routes are manually configured And they are not dynamically updated based on network changes Best suited for small networks where topology does not change Dynamic or Adaptive Routes are automatically updated based on network changes Topology, load, delay, distance, number of hops, estimated transit time When a router finds a change in topology, it advertises to all other routers Best suited for large & complex networks where topology changes frequently Default Router is configured to send all packets toward a single router (next hop) It is forwared to the default router Irrespective of which network the packet belongs Heirarchical Network is divided into multiple levels or domains With each level having its own routing protocol Best suited for large & complex networks That needs to be divided into manageable sections","title":"Types"},{"location":"computer_networks/L3_network_layer/routing_protocols#dynamic-routing-protocols","text":"","title":"Dynamic Routing Protocols"},{"location":"computer_networks/L3_network_layer/routing_protocols#distance-vector-routing-protocol","text":"Selects the best path on the basis of hop counts to reach the destination network Each router computes distance of its immediate neighbours Router shares knowledge about whole network to its neighbours Updates (routing info) is not broadcasted But shared to neighbouring nodes periodically A router shares its knowledge about the whole network (full routing tables) This is called routing on rumours Works on bellman ford algorithm Each router maintains a distance vector table Containing its distance from all possible destination nodes Characteristics Based on: Local knowledge Bandwidth required: Less (local sharing, small packets, no flooding) Information sharing: Regular intervals Algorithm to make routing table: Bellman-ford Traffic: Less Convergence: Slow Problems: Count to infinity, Slow convergence, Persistent loops","title":"Distance Vector Routing Protocol"},{"location":"computer_networks/L3_network_layer/routing_protocols#routing-loops","text":"Routing loops is the main issue since bellman ford algorithm cannot prevent loops Usually occur when an interface goes down or two routers send updates at the same time Routing loops cause count to infinity problem Wrong information keeps propogating within each other toward infinity Let's say AB = 1 & BC = 1, so AC = 2 If B & C are disconnected, B will remove C from its table Meanwhile, if A advertises that AC = 2, then B updates BC = 3 since AB = 1 A then receives update from B that BC = 3 and it updates AC = 4 since AB = 1 Spreading the bad information is called route poisoning Solutions: Poison reverse, Split horizon Examples: RIP (Routing Information Protocol)","title":"Routing Loops"},{"location":"computer_networks/L3_network_layer/routing_protocols#link-state-routing-protocol","text":"Knows more about internetwork than distance vectors Each router has node map and calculates best path Router shares knowledge of its neighbours with all the routers Maintains neighbor table, topology table, routing table Knowledge about the neighborhood Instead of sending routing table, a router sends info about its neighborhood only A router broadcasts its identities and cost of directly attached links Hello messages or keep alive messages are used for neighbor discovery & recovery Flooding In flooding, each router sends info To every other router on the internetwork except its neighbors Every router that receives the packet sends the copies to all the neighbors Information Sharing Router sends information only when a change occurs in the information Only the updates requested by the neighbor router are exchanged Initially each node knows the cost of its neighbors And finally each node knows the entire graph Dijkstra's algorithm is used to calculate optimal routes Characteristics Based on: Global knowledge Bandwidth required: More (large packets, flooding) Information sharing: Whenever there is a change Algorithm to make routing table: Dijkstra Traffic: More Convergence: Fast Problems: Heavy traffic due to packet flooding Examples: OSPF (Open Shortest Path First)","title":"Link State Routing Protocol"},{"location":"computer_networks/L3_network_layer/routing_protocols#advanced-distance-vector-routing-protocol","text":"Hybrid of distance vector & link state routing protocols Examples: EIGRP (Enhanced Interior Gateway Routing Protocol)","title":"Advanced Distance Vector Routing Protocol"},{"location":"computer_networks/L3_network_layer/routing_protocols#redistribution","text":"Using a single routing protocol in an organization is preferred But under some conditions, we have to use multiple protocols Like company mergers, multi-vendor devices Advertising a route learned through a routing protocol Into another routing protocol is called redistribution We have to define metric of the routing protocol in the advertising routing protocol For example, to advertise EIGRP into RIP, we have to define hop count (metric of RIP)","title":"Redistribution"},{"location":"computer_networks/L3_network_layer/nat_network_address_translation","text":"Network Address Translation (NAT) Allows multiple devices to access the internet through a single public address Also masks the port number of the host with another port Provides privacy to the local users And rejects malicious packet not requested by anyone A network device (router or firewall) assigns a public address To a computer (or group of computers) inside a private network The main use of NAT is to limit the number of public IP addresses That an organization or company must use For both economy and security purposes Working Generally, the border router is configured for NAT Border router is the one that has one interface in the local (inside) network And one interface in the global (outside) network When a packet traverse outside the local network NAT converts the local (private) IP address to global (public) IP address When a packet enters the local network Global IP address is converted to local IP address If NAT runs out of addresses in the configured pool, the packets are dropped And ICMP sents unreachable packet to the destination Masking Port Numbers Let's say two hosts A and B are connected Both of them request for the same destination On the same port number (say 1000) on the host side at the same time On receiving a reply from the destination It will be unclear to NAT which reply belongs to which host To avoid such a problem NAT masks the source port number and makes an entry in the NAT table Types Static NAT A single unregistered (private) IP address Is mapped with a registered (public) IP address Generally used for web hosting Not used in organization as there are many devices that need internet access Dynamic NAT An unregistered IP address is translated to a registered IP address From a pool of public addresses If no IP address of the pool is free, then the packet is dropped Used when the number of users who want internet access is fixed Not used in organization As each user that wants to access internet needs to be assigned a global address Port Address Translation (PAT) Also known as NAT overload Many local IP addresses can be translated to a single registered IP address Port numbers are used to distinguish the traffic Most frequently used, cost effective","title":"Nat Network Address Translation"},{"location":"computer_networks/L3_network_layer/nat_network_address_translation#network-address-translation-nat","text":"Allows multiple devices to access the internet through a single public address Also masks the port number of the host with another port Provides privacy to the local users And rejects malicious packet not requested by anyone A network device (router or firewall) assigns a public address To a computer (or group of computers) inside a private network The main use of NAT is to limit the number of public IP addresses That an organization or company must use For both economy and security purposes","title":"Network Address Translation (NAT)"},{"location":"computer_networks/L3_network_layer/nat_network_address_translation#working","text":"Generally, the border router is configured for NAT Border router is the one that has one interface in the local (inside) network And one interface in the global (outside) network When a packet traverse outside the local network NAT converts the local (private) IP address to global (public) IP address When a packet enters the local network Global IP address is converted to local IP address If NAT runs out of addresses in the configured pool, the packets are dropped And ICMP sents unreachable packet to the destination","title":"Working"},{"location":"computer_networks/L3_network_layer/nat_network_address_translation#masking-port-numbers","text":"Let's say two hosts A and B are connected Both of them request for the same destination On the same port number (say 1000) on the host side at the same time On receiving a reply from the destination It will be unclear to NAT which reply belongs to which host To avoid such a problem NAT masks the source port number and makes an entry in the NAT table","title":"Masking Port Numbers"},{"location":"computer_networks/L3_network_layer/nat_network_address_translation#types","text":"Static NAT A single unregistered (private) IP address Is mapped with a registered (public) IP address Generally used for web hosting Not used in organization as there are many devices that need internet access Dynamic NAT An unregistered IP address is translated to a registered IP address From a pool of public addresses If no IP address of the pool is free, then the packet is dropped Used when the number of users who want internet access is fixed Not used in organization As each user that wants to access internet needs to be assigned a global address Port Address Translation (PAT) Also known as NAT overload Many local IP addresses can be translated to a single registered IP address Port numbers are used to distinguish the traffic Most frequently used, cost effective","title":"Types"},{"location":"computer_networks/L3_network_layer/isdn_integrated_services_digital_network","text":"Integrated Services Digital Network (ISDN) Communication standards for simultaneous digital transmission Including voice, video, data, and other network services Over traditional circuits of the public switched telephone network It can integrate speech and data on the same lines, which was not available before It is a circuit switched telephone network system But also provides access to packet switched networks for data In increments of 64 Kbit/s This allows digital transmission of voice and data This results in better voice or data quality than an analog phone Costlier than other telephone system and requires specialized digital devices Interfaces Basic Rate Interface (BRI) There are two data bearing channels (B channels) and one signaling channel (D channel) B (Bearer) channels Operate at a max of 64 Kbps Carries user data like voice, video or computer data D (Data) channel Operates at a max of 16 Kbps Used for any combination of data, control, signaling Total speed = 64 * 2 + 16 = 144 Kbps 192 Kbps including 48 Kbps operating overhead of BRI service The two channels are independent of each other. For example: One channel is used as TCP/IP connection to a location Other channel is used to send fax to a remote location Primary Rate Interface (PRI) Consists of one D channel and either 23 or 30 B channels depending on the country Both types of channel operate at 64 Kbps Total speed = 1.546 Mbps (23 B channels + 1 D channel) 1.544 Kbps includeing 9 Kbps overhead Broadband-ISDN Narrowband ISDN designed to operate over the current communications infrastructure Heavily dependent on copper cable, but mainly relies on the evolution of fiber optics Capable of supporting rates greater than the primary rate Services Bearer Services Transfer of information (voice, data, video) between users Without the network manipulating the content No need for the network to process the information Belongs to the first three layers of the OSI model Provided using circuit switched, packet switched, frame switched, or cell switched networks Tele Services Network may change or process the contents of the data Corresponds to layers four to seven of the OSI model Relies on the facilities of the bearer services Designed to accomodate complex user needs Includes telephony, teletex, telefax, videotex, telex, teleconferencing Supplementary Service Provides additional functionality to the bearer services and the tele services Examples: Reverse charging, call waiting, message handling","title":"Isdn Integrated Services Digital Network"},{"location":"computer_networks/L3_network_layer/isdn_integrated_services_digital_network#integrated-services-digital-network-isdn","text":"Communication standards for simultaneous digital transmission Including voice, video, data, and other network services Over traditional circuits of the public switched telephone network It can integrate speech and data on the same lines, which was not available before It is a circuit switched telephone network system But also provides access to packet switched networks for data In increments of 64 Kbit/s This allows digital transmission of voice and data This results in better voice or data quality than an analog phone Costlier than other telephone system and requires specialized digital devices","title":"Integrated Services Digital Network (ISDN)"},{"location":"computer_networks/L3_network_layer/isdn_integrated_services_digital_network#interfaces","text":"Basic Rate Interface (BRI) There are two data bearing channels (B channels) and one signaling channel (D channel) B (Bearer) channels Operate at a max of 64 Kbps Carries user data like voice, video or computer data D (Data) channel Operates at a max of 16 Kbps Used for any combination of data, control, signaling Total speed = 64 * 2 + 16 = 144 Kbps 192 Kbps including 48 Kbps operating overhead of BRI service The two channels are independent of each other. For example: One channel is used as TCP/IP connection to a location Other channel is used to send fax to a remote location Primary Rate Interface (PRI) Consists of one D channel and either 23 or 30 B channels depending on the country Both types of channel operate at 64 Kbps Total speed = 1.546 Mbps (23 B channels + 1 D channel) 1.544 Kbps includeing 9 Kbps overhead Broadband-ISDN Narrowband ISDN designed to operate over the current communications infrastructure Heavily dependent on copper cable, but mainly relies on the evolution of fiber optics Capable of supporting rates greater than the primary rate","title":"Interfaces"},{"location":"computer_networks/L3_network_layer/isdn_integrated_services_digital_network#services","text":"Bearer Services Transfer of information (voice, data, video) between users Without the network manipulating the content No need for the network to process the information Belongs to the first three layers of the OSI model Provided using circuit switched, packet switched, frame switched, or cell switched networks Tele Services Network may change or process the contents of the data Corresponds to layers four to seven of the OSI model Relies on the facilities of the bearer services Designed to accomodate complex user needs Includes telephony, teletex, telefax, videotex, telex, teleconferencing Supplementary Service Provides additional functionality to the bearer services and the tele services Examples: Reverse charging, call waiting, message handling","title":"Services"},{"location":"computer_networks/L3_network_layer/aaa_authentication_authorization_accounting","text":"AAA (Authentication, Authorization, Accounting) AAA is a standard framework used to control Who is permitted to use network resources (authentication) What are they authorized to do (authorization) Capture the actions performed while accessing the network (accounting) An administrator can access a router or a device through a console But it is incovenient if he is sitting far from the place of that device So he has to take remote access to that device As remote access will be available by using an IP address It is possible that an unauthorized user can take access using that IP address So for security measures, we have to put authentication Also, the packets exchanged between the device should be encrypted So that any other person cannot capture sensitive info Authentication Identifying if a user that wants to access the network resources is valid or not Common methods are to put authentication on console port, AUX port, or VTY lines Authorization Enforces policies on network resources After user has gained access to the network resources through authentication Determines what resources is the user allowed to access And the operations that can be performed For example, junior engineer and senior engineer will have different permissions Accounting Monitoring and capturing events performed by a user while accessing network resources Monitors how long the user has access to the network Administrator can create an accounting method list To specify what should be accounted for To whom the accounting records should be sent Implementation AAA can be implemented by using the local database of router or by using external ACS server Local database of the device (router) First users are created for authentication Then privilege levels are provided to users for authorization Sending authentication requests to an external server like ACS server Configuration on both router and ACS is required If ACS server fails to authenticate, local database can be used as a backup Configuration includes creating user Separate customized method list for authentication, autorization, accounting Client or Network Access Server (NAS) sends authentication requests to ACS server Server takes the decision to allow the user to access the network resource or not According to the credentials provided by the user Challenge Response Authentication Mechanism (CRAM) Used to authenticate actions One side presents a challenge And the other side must present a correct answer to get authenticated Types of challenges Static User can select his challenge and authenticate himself For example, security questions That you select while account setup and asked in forget password Dynamic Challenges are selected randomly presuming that the user will know the valid answer Implementation CAPTCHA Completely automated public turing test to tell computers and humans apart Used to prevent spam and auto-registratoin of new accounts Machine learning is used to train different types of models Examples User needs to enter a text or number from the distorted image Images are presented and user needs to select the right pieces based on a prompt SSH (Secure Shell) Cyptographic network protocol For operating network services securely over an unsecured network Password Password is sent to the server for validation by matching with the correct password Salted CRAM Challenge is salted with a hash to make sure the password is used one time only Hash is sent to server for matching with the hash of the correct password So the password is not revealed to man in the middle attack and replay attacks Biometrics","title":"Aaa Authentication Authorization Accounting"},{"location":"computer_networks/L3_network_layer/aaa_authentication_authorization_accounting#aaa-authentication-authorization-accounting","text":"AAA is a standard framework used to control Who is permitted to use network resources (authentication) What are they authorized to do (authorization) Capture the actions performed while accessing the network (accounting) An administrator can access a router or a device through a console But it is incovenient if he is sitting far from the place of that device So he has to take remote access to that device As remote access will be available by using an IP address It is possible that an unauthorized user can take access using that IP address So for security measures, we have to put authentication Also, the packets exchanged between the device should be encrypted So that any other person cannot capture sensitive info","title":"AAA (Authentication, Authorization, Accounting)"},{"location":"computer_networks/L3_network_layer/aaa_authentication_authorization_accounting#authentication","text":"Identifying if a user that wants to access the network resources is valid or not Common methods are to put authentication on console port, AUX port, or VTY lines","title":"Authentication"},{"location":"computer_networks/L3_network_layer/aaa_authentication_authorization_accounting#authorization","text":"Enforces policies on network resources After user has gained access to the network resources through authentication Determines what resources is the user allowed to access And the operations that can be performed For example, junior engineer and senior engineer will have different permissions","title":"Authorization"},{"location":"computer_networks/L3_network_layer/aaa_authentication_authorization_accounting#accounting","text":"Monitoring and capturing events performed by a user while accessing network resources Monitors how long the user has access to the network Administrator can create an accounting method list To specify what should be accounted for To whom the accounting records should be sent","title":"Accounting"},{"location":"computer_networks/L3_network_layer/aaa_authentication_authorization_accounting#implementation","text":"AAA can be implemented by using the local database of router or by using external ACS server Local database of the device (router) First users are created for authentication Then privilege levels are provided to users for authorization Sending authentication requests to an external server like ACS server Configuration on both router and ACS is required If ACS server fails to authenticate, local database can be used as a backup Configuration includes creating user Separate customized method list for authentication, autorization, accounting Client or Network Access Server (NAS) sends authentication requests to ACS server Server takes the decision to allow the user to access the network resource or not According to the credentials provided by the user","title":"Implementation"},{"location":"computer_networks/L3_network_layer/aaa_authentication_authorization_accounting#challenge-response-authentication-mechanism-cram","text":"Used to authenticate actions One side presents a challenge And the other side must present a correct answer to get authenticated Types of challenges Static User can select his challenge and authenticate himself For example, security questions That you select while account setup and asked in forget password Dynamic Challenges are selected randomly presuming that the user will know the valid answer","title":"Challenge Response Authentication Mechanism (CRAM)"},{"location":"computer_networks/L3_network_layer/aaa_authentication_authorization_accounting#implementation_1","text":"CAPTCHA Completely automated public turing test to tell computers and humans apart Used to prevent spam and auto-registratoin of new accounts Machine learning is used to train different types of models Examples User needs to enter a text or number from the distorted image Images are presented and user needs to select the right pieces based on a prompt SSH (Secure Shell) Cyptographic network protocol For operating network services securely over an unsecured network Password Password is sent to the server for validation by matching with the correct password Salted CRAM Challenge is salted with a hash to make sure the password is used one time only Hash is sent to server for matching with the hash of the correct password So the password is not revealed to man in the middle attack and replay attacks Biometrics","title":"Implementation"},{"location":"computer_networks/L3_network_layer/access_control","text":"Access Control Lists (ACL) Set of rules defined to control network traffic and reduce network attacks Once a rule matches, no further comparison takes place If no rule matches, then the packet is discarded Direction Inbound access list is applied on inbound packets Outbound access list is applied on outbound packets Only one list per interface per protocol per direction can be assigned Types Standard access list Uses only the source IP address Permits or denies the entire protocol suite Doesn't distinguish between the IP traffic like TCP, UDP, HTTPS, etc. Extended access list Uses source IP & port and destination IP & port Can also mention which type of IP traffic should be allowed or denied Reflexive access list Acts as a stateful firewall As it allows only the traffic that is initiated within the network & its replies And denies other packets coming from outside the network When a session is initiated It creates a temporary entry for the traffic which allows the replies from outside Should be nested inside the extended access list Time-based access list Allows access based on particular time of the day or particular days of a week Can deny access to internet on working hours and allow access in lunch time Can work with absolute or periodic time range Best works with NTP (Network Time Protocol) synchronisation But can work with router clock Control Based Access Control (CBAC) Secures and protects the network from unauthorized access and malicious activity Enables granular control of network policies While maintaining flexibility & functionality Unlike traditional access control that rely on static rules & fixed conditions It analyses in real time by considering a wide range of contextual factors ACLs provide traffic filtering till transport layer While CBAC provides till application layer With the help of CBAC configuration, a router can act as a firewall In addition to access lists Maintains a state table in which the sessions are maintained in memory The outbound traffic & its replies can pass the router using this state entry Maintains TCP/UDP info to perform deeper inspection in packet payload Examines the rate at which the connection has been established To detect attacks like DoS attack, TCP syn attack and drop malicious packets Disadvantages Filters traffic passing through But not the traffic originating or terminating on the configured device Inspects only TCP & UDP traffic and not ICMP or any other traffic Only protects against traffic through firewall And not against attacks originating within the protected network","title":"Access Control"},{"location":"computer_networks/L3_network_layer/access_control#access-control-lists-acl","text":"Set of rules defined to control network traffic and reduce network attacks Once a rule matches, no further comparison takes place If no rule matches, then the packet is discarded Direction Inbound access list is applied on inbound packets Outbound access list is applied on outbound packets Only one list per interface per protocol per direction can be assigned","title":"Access Control Lists (ACL)"},{"location":"computer_networks/L3_network_layer/access_control#types","text":"Standard access list Uses only the source IP address Permits or denies the entire protocol suite Doesn't distinguish between the IP traffic like TCP, UDP, HTTPS, etc. Extended access list Uses source IP & port and destination IP & port Can also mention which type of IP traffic should be allowed or denied Reflexive access list Acts as a stateful firewall As it allows only the traffic that is initiated within the network & its replies And denies other packets coming from outside the network When a session is initiated It creates a temporary entry for the traffic which allows the replies from outside Should be nested inside the extended access list Time-based access list Allows access based on particular time of the day or particular days of a week Can deny access to internet on working hours and allow access in lunch time Can work with absolute or periodic time range Best works with NTP (Network Time Protocol) synchronisation But can work with router clock","title":"Types"},{"location":"computer_networks/L3_network_layer/access_control#control-based-access-control-cbac","text":"Secures and protects the network from unauthorized access and malicious activity Enables granular control of network policies While maintaining flexibility & functionality Unlike traditional access control that rely on static rules & fixed conditions It analyses in real time by considering a wide range of contextual factors ACLs provide traffic filtering till transport layer While CBAC provides till application layer With the help of CBAC configuration, a router can act as a firewall In addition to access lists Maintains a state table in which the sessions are maintained in memory The outbound traffic & its replies can pass the router using this state entry Maintains TCP/UDP info to perform deeper inspection in packet payload Examines the rate at which the connection has been established To detect attacks like DoS attack, TCP syn attack and drop malicious packets Disadvantages Filters traffic passing through But not the traffic originating or terminating on the configured device Inspects only TCP & UDP traffic and not ICMP or any other traffic Only protects against traffic through firewall And not against attacks originating within the protected network","title":"Control Based Access Control (CBAC)"},{"location":"computer_networks/L3_network_layer/wifi","text":"WiFi (Wireless Fidelity) Wireless networking technique that functions similar to a local area network Routers and radio frequency waves are used to transmit data Can be less expensive and easier to install than wires & cables It might be challenging to provide reliable coverage In some areas where signal can become weak Enables a large number of users to connect to internet At public places or organizations Allows mobile devices to connect to internet Security Protocols WEP (Wired Equivalent Privacy) 64-bit or 128-bit encryption key That must be manually entered on wireless access points & devices Once configured can never be changed Uses cyclic redundancy check (CRC) Security flaws Does not provide a sufficiently strong data integrity guarantee for the packets Message authentication codes are used to solve this issue But requires too much computation to be used on old network cards WPA (Wifi Protected Access) Intermediate measure in anticipation of the availability of the more secure & complex WPA2 Employs per-packet key dynamically generating a new 128-bit key for each packet Prevents the types of attacks that compromise WEP Includes a message integrity check called TKIP (Temporal Key Integrity Protocol) To prevent attackers from altering or resending data packets Much stronger than CRC used in WEP Security flaws Limitations of the message integrity code hash function That is used to retrieve the keystream from short packets Can be used for re-injection and spoofing WPA2 (Wifi Protected Access 2) Includes mandatory support for CCMP (Counter Mode CBC-MAC Protocol) Blocks chaining message authentication code protocol More robust and dependable than TKIP AES (Advanced Encryption Standard) based encryption mode Mandatory for all new devices to bear the Wifi trademark Security flaws Risk of unwanted access to the company wireless network Occurs when an attack vector on specific WPS access points is compromised WPA3 (Wifi Protected Access 3) 192-bit cryptographic strength 384-bit Hash Message Authentication Mode (HMAC) 256-bit Broadcat/Multicast Integrity Protocol (BIP-GMAC-256) 256-bit Galois/Counter Model Protocol encryption (GCMP-256) SAE exchange Wifi Device Provisioning Protocol (DPP) WPS (Wifi Protected Setup) A wireless network security standard that tries to make connections Between a router and wireless devices in a faster & easier way Works only for wireless networks that use password protection using WPA or WPA2 In a standard setup, you can't connect a wireless device to a wireless network Until you know the network name called Service Set Identifier (SSID) And its password called WPA-PSK (Pre-Shared Key) WPS can simplify this connection process Push button Press the WPS button located on the router and client devices The device connects automatically without password once the buttons are enabled PIN: Client device must enter the PIN found on the sticker for the access point Network Field Communication: Client device must be brought close to the access point Relatively new technology, so not all devices support it","title":"Wifi"},{"location":"computer_networks/L3_network_layer/wifi#wifi-wireless-fidelity","text":"Wireless networking technique that functions similar to a local area network Routers and radio frequency waves are used to transmit data Can be less expensive and easier to install than wires & cables It might be challenging to provide reliable coverage In some areas where signal can become weak Enables a large number of users to connect to internet At public places or organizations Allows mobile devices to connect to internet","title":"WiFi (Wireless Fidelity)"},{"location":"computer_networks/L3_network_layer/wifi#security-protocols","text":"","title":"Security Protocols"},{"location":"computer_networks/L3_network_layer/wifi#wep-wired-equivalent-privacy","text":"64-bit or 128-bit encryption key That must be manually entered on wireless access points & devices Once configured can never be changed Uses cyclic redundancy check (CRC) Security flaws Does not provide a sufficiently strong data integrity guarantee for the packets Message authentication codes are used to solve this issue But requires too much computation to be used on old network cards","title":"WEP (Wired Equivalent Privacy)"},{"location":"computer_networks/L3_network_layer/wifi#wpa-wifi-protected-access","text":"Intermediate measure in anticipation of the availability of the more secure & complex WPA2 Employs per-packet key dynamically generating a new 128-bit key for each packet Prevents the types of attacks that compromise WEP Includes a message integrity check called TKIP (Temporal Key Integrity Protocol) To prevent attackers from altering or resending data packets Much stronger than CRC used in WEP Security flaws Limitations of the message integrity code hash function That is used to retrieve the keystream from short packets Can be used for re-injection and spoofing","title":"WPA (Wifi Protected Access)"},{"location":"computer_networks/L3_network_layer/wifi#wpa2-wifi-protected-access-2","text":"Includes mandatory support for CCMP (Counter Mode CBC-MAC Protocol) Blocks chaining message authentication code protocol More robust and dependable than TKIP AES (Advanced Encryption Standard) based encryption mode Mandatory for all new devices to bear the Wifi trademark Security flaws Risk of unwanted access to the company wireless network Occurs when an attack vector on specific WPS access points is compromised","title":"WPA2 (Wifi Protected Access 2)"},{"location":"computer_networks/L3_network_layer/wifi#wpa3-wifi-protected-access-3","text":"192-bit cryptographic strength 384-bit Hash Message Authentication Mode (HMAC) 256-bit Broadcat/Multicast Integrity Protocol (BIP-GMAC-256) 256-bit Galois/Counter Model Protocol encryption (GCMP-256) SAE exchange Wifi Device Provisioning Protocol (DPP)","title":"WPA3 (Wifi Protected Access 3)"},{"location":"computer_networks/L3_network_layer/wifi#wps-wifi-protected-setup","text":"A wireless network security standard that tries to make connections Between a router and wireless devices in a faster & easier way Works only for wireless networks that use password protection using WPA or WPA2 In a standard setup, you can't connect a wireless device to a wireless network Until you know the network name called Service Set Identifier (SSID) And its password called WPA-PSK (Pre-Shared Key) WPS can simplify this connection process Push button Press the WPS button located on the router and client devices The device connects automatically without password once the buttons are enabled PIN: Client device must enter the PIN found on the sticker for the access point Network Field Communication: Client device must be brought close to the access point Relatively new technology, so not all devices support it","title":"WPS (Wifi Protected Setup)"},{"location":"computer_networks/L4_transport_layer/index","text":"L4: Transport Layer Introduction TCP (Transmission Control Protocol) UDP (User Datagram Protocol) Congestion Control","title":"Index"},{"location":"computer_networks/L4_transport_layer/index#l4-transport-layer","text":"Introduction TCP (Transmission Control Protocol) UDP (User Datagram Protocol) Congestion Control","title":"L4: Transport Layer"},{"location":"computer_networks/L4_transport_layer/introduction","text":"Introduction Basic info Packet: Segment Protocols: TCP, UDP Platforms: OS, Gateways, Firewalls End to end communication layer Reliable message delivery from process to process Ensures messages are in order and without duplication End-to-end (not across single link) delivery, flow control and error control Acknowledges successful data transmission And re-transmits the data if an error is found Provides services to application layer by making system calls And takes services from network layer Service-point addressing Allows computers to run several programs simultaneously Logical communication between processes Process to process delivery Requires port number to correctly deliver the segments of data To the correct process amongst the multiple processes running on a particular host Port number is 16-bit address used to identify any client-server program uniquely This is similar to data link layer requiring MAC address And network layer requiring IP address Workflow At the sender side Receives the formatted data from the upper layers and performs segmentation Implements flow & error control Adds source and destination port numbers (or service point address) in the headers This is called service point addressing The destination port number is configured either by default or manually Forwards the segmented data to the network layer At the receiver side Receives data from the network layer Reads the port number from the header and forwards the data Performs sequencing and reassembling of the segmented data Forwards the message to appropriate port in the application layer Services Connection-oriented service Three phase process: establish connection, transfer data, disconnect Reliable and secure Receiving device sends an acknowledgement to the source Before delivering the packets Connection is made with transport layer at the destination All the packets travel in the single route Connection-less service One phase process: data transfer Receiving device does not acknowledge receipt of a packet Faster communication Each segment is treated as an individual packet Packets travel in different routes to reach the destination Multiplexing/Demultiplexing Multiplexing (many to one) at sender Data is acquired from several processes (or sockets) from the sender And merged into one packet along with headers And sent as a single packet Allows simultaneous use of different processes running on a host over a network The processes are differentiated by their port number Demultiplexing (one to many) at receiver Header info is used to deliver segments to correct sockets or processes That are running on the receiver's machine Host receives IP datagrams Source IP, destination IP, segment(source port, destination port) Error and Flow Control Checks errors in messages coming from the applcation layer by Using error detection codes Computing checksums Checking if the received data is corrupted Using ACK & NACK services to inform the sender Protocols Stop-and-wait Sliding Window Go-back-N Receiver sends cumulative ack Sender can have up to N unacked packets in pipeline Sender has timer for oldest unacked packet When timer expires, it retransmits all packets starting from the unacked one Selective repeat Receiver sends individual ack Sender has timer for each unacked packet When timer expires, retransmit the unacked packet only","title":"Introduction"},{"location":"computer_networks/L4_transport_layer/introduction#introduction","text":"Basic info Packet: Segment Protocols: TCP, UDP Platforms: OS, Gateways, Firewalls End to end communication layer Reliable message delivery from process to process Ensures messages are in order and without duplication End-to-end (not across single link) delivery, flow control and error control Acknowledges successful data transmission And re-transmits the data if an error is found Provides services to application layer by making system calls And takes services from network layer Service-point addressing Allows computers to run several programs simultaneously Logical communication between processes","title":"Introduction"},{"location":"computer_networks/L4_transport_layer/introduction#process-to-process-delivery","text":"Requires port number to correctly deliver the segments of data To the correct process amongst the multiple processes running on a particular host Port number is 16-bit address used to identify any client-server program uniquely This is similar to data link layer requiring MAC address And network layer requiring IP address","title":"Process to process delivery"},{"location":"computer_networks/L4_transport_layer/introduction#workflow","text":"At the sender side Receives the formatted data from the upper layers and performs segmentation Implements flow & error control Adds source and destination port numbers (or service point address) in the headers This is called service point addressing The destination port number is configured either by default or manually Forwards the segmented data to the network layer At the receiver side Receives data from the network layer Reads the port number from the header and forwards the data Performs sequencing and reassembling of the segmented data Forwards the message to appropriate port in the application layer","title":"Workflow"},{"location":"computer_networks/L4_transport_layer/introduction#services","text":"Connection-oriented service Three phase process: establish connection, transfer data, disconnect Reliable and secure Receiving device sends an acknowledgement to the source Before delivering the packets Connection is made with transport layer at the destination All the packets travel in the single route Connection-less service One phase process: data transfer Receiving device does not acknowledge receipt of a packet Faster communication Each segment is treated as an individual packet Packets travel in different routes to reach the destination","title":"Services"},{"location":"computer_networks/L4_transport_layer/introduction#multiplexingdemultiplexing","text":"Multiplexing (many to one) at sender Data is acquired from several processes (or sockets) from the sender And merged into one packet along with headers And sent as a single packet Allows simultaneous use of different processes running on a host over a network The processes are differentiated by their port number Demultiplexing (one to many) at receiver Header info is used to deliver segments to correct sockets or processes That are running on the receiver's machine Host receives IP datagrams Source IP, destination IP, segment(source port, destination port)","title":"Multiplexing/Demultiplexing"},{"location":"computer_networks/L4_transport_layer/introduction#error-and-flow-control","text":"Checks errors in messages coming from the applcation layer by Using error detection codes Computing checksums Checking if the received data is corrupted Using ACK & NACK services to inform the sender","title":"Error and Flow Control"},{"location":"computer_networks/L4_transport_layer/introduction#protocols","text":"Stop-and-wait Sliding Window Go-back-N Receiver sends cumulative ack Sender can have up to N unacked packets in pipeline Sender has timer for oldest unacked packet When timer expires, it retransmits all packets starting from the unacked one Selective repeat Receiver sends individual ack Sender has timer for each unacked packet When timer expires, retransmit the unacked packet only","title":"Protocols"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol","text":"TCP (Transmission Control Protocol) Connection oriented protocol for communication between different devices in a network Sender & receiver are connected till the completion of the process Order of the data is maintained (order remains same before & after the transmission) Establishes and maintains full duplex connection between hosts And generates a virtual circuit between sender & receiver Works with IP that establishes the technique for sending data packets between devices Reliable communication using Positive Acknowledgement with Re-transmission (PAR) Detects errors and retransmits the damaged frames Segments are checked for error detection Corrupted segment, lost segment management, out of order segment, duplicate segment Before the transmission is completed Ensures that all segments are received and acknowledged Working Sender To ensure that each message reaches its target location intact Data/message is divided into small segments It keeps track of the segments by assigning sequence number As opposed to sending everything in one go This makes it simpler to maintain efficiency Segments may travel through multiple routes and arrive in different order It makes it easier to route segments if one route is jammed Receiver All segments are collected and reordered based on sequence numbers Received segmments are assigned acknowledgement numbers TCP then waits for the transmission to finish And acknowledges once all packets have been received Flow control Limits the rate at which a sender transfers data The receiver continually hints on how much data can be received Using a sliding window After the user request is received by the server It sends back an HTML page using HTTP HTTP requests TCP layer to set the required connection and send the HTML file Connection using 3 way handshake Step 1: SYN When a client wants to establish a connection It sends a segment with SYN (Synchronized Sequence Number) This informs the server that the client is likely to start communication And with what sequence number (32-bit number) it starts with Step 2: SYN + ACK Server responds to the client request with SYN-ACK signal bits set Acknowledgement (ACK) signifies that the response of the segment is received SYN signifies with what sequence number it is likely to start the segments with Step 3: ACK Client acknowledges the response of the server And they both establish a reliable connection With which they will start the actual data transfer TCP Timers TCP uses several timers during communications To ensure that excessive delays are not encountered Retransmission timer Retransmission timeout (RTO) is used to retransmit lost segments Starts when TCP sends a segment and stops when the ack is received This is determined using RTT (Round trip time) Measured RTT: Time taken by segment to reach destination & be acknowledged Smoothed RTT: Weighted average of measured RTT Persistent timer Used to deal with a zero-window-size deadlock situation When TCP receives an ack with window size of zero, it starts a persistence timer When it goes off, TCP sends a special segment called probe Probe contains only 1 byte of data It has a sequence number but it's never acked Also ignored in calculating sequence nuumber for rest of the data Probe causes the receiver to resend ack which was lost Keep alive timer Used to prevent a long idle connection between two TCPs Each time the server hears from client, it resets the timer (usually 2 hours) If the server does not hear from the client after timeout, it sends a probe segment If there is no response after 10 probes (75s apart) It assumes that the client is down and terminates the connection Time wait timer or quiet timer Used during tcp connection termination Starts after sending the last ack and closing the connnection After connection is closed It is possible for datagrams that are still their way through the network To attempt to access the closed port This timer prevents just closed port from reopening again quickly And receiving these last datagrams Usually set to twice the maximum segment lifetime Same value as time-to-live field in IP header Connection Termination Supports two types of connection releases Like most connection-oriented transport protocols Graceful connection release Connection is open until both parties have closed their sides of connection Carried out by using the TCP header's FIN (finish) flag Step 1 (FIN from client) Suppose that the client wants to close the connection Server can also choose to do so Client sends a segment to server with FIN bit set to 1 Client enters into FIN_WAIT_1 state and waits for ack from the server Step 2 (ACK from server) When the server receives FIN bit segment, it immediately sends ack to the client When the client receives the ack, it enters into FIN_WAIT_2 state And waits for another segment from server with FIN bit set to 1 Step 3 (FIN from server) After some time of sending ack, server sends FIN bit segment to client The time is taken due to some closing process in the server Step 4 (ACK from client) When the client receives FIN bit segment It sends ack to server and enters into TIME_WAIT state TIME_WAIT state lets client resend the final ack in case its lost Typically 30s, 1min, 2min After the wait, the connection formally closes And all resources on the client side (port numbers, buffer data) are released Abrupt connection release Either an TCP entity is forced to closed the connection Or one user closes both directions of data transfer Carried out when an RST (reset) segment is sent When an non-SYN segement is received for a non-exiting TCP connection When a segment with an invalid header is received in an open connection Prevents attacks by closing the corresponding connection When some implementations need to close an existing TCP connection due to Lack of resources or remote host is unreachable & has stopped responding RST segement should contain 00 if it does not belong to any existing connection Else it should contain current value of the sequence number And the ack number should be set to the next expected sequence number Wrap Around Concept At high rate of traffic, all the sequence numbers can get used up Sequence number should be unique for each packet Sequence number is of 32 bits (0 to 2^32 - 1 = 4 Giga numbers) Wrap around concept Using the sequence number again and again once all of them get used up In order to maintain the continuity of data transfer Wrap around time Time taken to wrap around If we start from sequence number n, after how much time is it used again Depends on the sequence numbers and bandwidth (rate of bits being consumed) It should be at least greater than the life time of a packet For that time the sequence number will be in use Wrap around time = Count of sequence numbers / Bandwidth For 1 GBps = 2^32 numbers / 10^9 = 4.3 seconds","title":"Tcp Transmission Control Protocol"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#tcp-transmission-control-protocol","text":"Connection oriented protocol for communication between different devices in a network Sender & receiver are connected till the completion of the process Order of the data is maintained (order remains same before & after the transmission) Establishes and maintains full duplex connection between hosts And generates a virtual circuit between sender & receiver Works with IP that establishes the technique for sending data packets between devices Reliable communication using Positive Acknowledgement with Re-transmission (PAR) Detects errors and retransmits the damaged frames Segments are checked for error detection Corrupted segment, lost segment management, out of order segment, duplicate segment Before the transmission is completed Ensures that all segments are received and acknowledged","title":"TCP (Transmission Control Protocol)"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#working","text":"Sender To ensure that each message reaches its target location intact Data/message is divided into small segments It keeps track of the segments by assigning sequence number As opposed to sending everything in one go This makes it simpler to maintain efficiency Segments may travel through multiple routes and arrive in different order It makes it easier to route segments if one route is jammed Receiver All segments are collected and reordered based on sequence numbers Received segmments are assigned acknowledgement numbers TCP then waits for the transmission to finish And acknowledges once all packets have been received Flow control Limits the rate at which a sender transfers data The receiver continually hints on how much data can be received Using a sliding window After the user request is received by the server It sends back an HTML page using HTTP HTTP requests TCP layer to set the required connection and send the HTML file","title":"Working"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#connection-using-3-way-handshake","text":"Step 1: SYN When a client wants to establish a connection It sends a segment with SYN (Synchronized Sequence Number) This informs the server that the client is likely to start communication And with what sequence number (32-bit number) it starts with Step 2: SYN + ACK Server responds to the client request with SYN-ACK signal bits set Acknowledgement (ACK) signifies that the response of the segment is received SYN signifies with what sequence number it is likely to start the segments with Step 3: ACK Client acknowledges the response of the server And they both establish a reliable connection With which they will start the actual data transfer","title":"Connection using 3 way handshake"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#tcp-timers","text":"TCP uses several timers during communications To ensure that excessive delays are not encountered","title":"TCP Timers"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#retransmission-timer","text":"Retransmission timeout (RTO) is used to retransmit lost segments Starts when TCP sends a segment and stops when the ack is received This is determined using RTT (Round trip time) Measured RTT: Time taken by segment to reach destination & be acknowledged Smoothed RTT: Weighted average of measured RTT","title":"Retransmission timer"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#persistent-timer","text":"Used to deal with a zero-window-size deadlock situation When TCP receives an ack with window size of zero, it starts a persistence timer When it goes off, TCP sends a special segment called probe Probe contains only 1 byte of data It has a sequence number but it's never acked Also ignored in calculating sequence nuumber for rest of the data Probe causes the receiver to resend ack which was lost","title":"Persistent timer"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#keep-alive-timer","text":"Used to prevent a long idle connection between two TCPs Each time the server hears from client, it resets the timer (usually 2 hours) If the server does not hear from the client after timeout, it sends a probe segment If there is no response after 10 probes (75s apart) It assumes that the client is down and terminates the connection","title":"Keep alive timer"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#time-wait-timer-or-quiet-timer","text":"Used during tcp connection termination Starts after sending the last ack and closing the connnection After connection is closed It is possible for datagrams that are still their way through the network To attempt to access the closed port This timer prevents just closed port from reopening again quickly And receiving these last datagrams Usually set to twice the maximum segment lifetime Same value as time-to-live field in IP header","title":"Time wait timer or quiet timer"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#connection-termination","text":"Supports two types of connection releases Like most connection-oriented transport protocols","title":"Connection Termination"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#graceful-connection-release","text":"Connection is open until both parties have closed their sides of connection Carried out by using the TCP header's FIN (finish) flag Step 1 (FIN from client) Suppose that the client wants to close the connection Server can also choose to do so Client sends a segment to server with FIN bit set to 1 Client enters into FIN_WAIT_1 state and waits for ack from the server Step 2 (ACK from server) When the server receives FIN bit segment, it immediately sends ack to the client When the client receives the ack, it enters into FIN_WAIT_2 state And waits for another segment from server with FIN bit set to 1 Step 3 (FIN from server) After some time of sending ack, server sends FIN bit segment to client The time is taken due to some closing process in the server Step 4 (ACK from client) When the client receives FIN bit segment It sends ack to server and enters into TIME_WAIT state TIME_WAIT state lets client resend the final ack in case its lost Typically 30s, 1min, 2min After the wait, the connection formally closes And all resources on the client side (port numbers, buffer data) are released","title":"Graceful connection release"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#abrupt-connection-release","text":"Either an TCP entity is forced to closed the connection Or one user closes both directions of data transfer Carried out when an RST (reset) segment is sent When an non-SYN segement is received for a non-exiting TCP connection When a segment with an invalid header is received in an open connection Prevents attacks by closing the corresponding connection When some implementations need to close an existing TCP connection due to Lack of resources or remote host is unreachable & has stopped responding RST segement should contain 00 if it does not belong to any existing connection Else it should contain current value of the sequence number And the ack number should be set to the next expected sequence number","title":"Abrupt connection release"},{"location":"computer_networks/L4_transport_layer/tcp_transmission_control_protocol#wrap-around-concept","text":"At high rate of traffic, all the sequence numbers can get used up Sequence number should be unique for each packet Sequence number is of 32 bits (0 to 2^32 - 1 = 4 Giga numbers) Wrap around concept Using the sequence number again and again once all of them get used up In order to maintain the continuity of data transfer Wrap around time Time taken to wrap around If we start from sequence number n, after how much time is it used again Depends on the sequence numbers and bandwidth (rate of bits being consumed) It should be at least greater than the life time of a packet For that time the sequence number will be in use Wrap around time = Count of sequence numbers / Bandwidth For 1 GBps = 2^32 numbers / 10^9 = 4.3 seconds","title":"Wrap Around Concept"},{"location":"computer_networks/L4_transport_layer/udp_user_datagram_protocol","text":"UDP (User Datagram Protocol) Unreliable and connectionless protocol unlike TCP No need to establish connection before data transfer No congestion control, no flow control TCP is the dominant transport layer protocol That provides delivery & reliability but costs additional overhead & latency For real-time services like computer gaming, voice or video communication, live conferences High performance is required UDP permits packets to be dropped instead of processing delayed packets There is no error checking which also saves bandwidth Smaller packets than TCP Also used by DNS, DHCP, VoIP (Voice over Internet Protocol) Takes datagram from network layer Attaches its header and sends it to user, so it works fast","title":"Udp User Datagram Protocol"},{"location":"computer_networks/L4_transport_layer/udp_user_datagram_protocol#udp-user-datagram-protocol","text":"Unreliable and connectionless protocol unlike TCP No need to establish connection before data transfer No congestion control, no flow control TCP is the dominant transport layer protocol That provides delivery & reliability but costs additional overhead & latency For real-time services like computer gaming, voice or video communication, live conferences High performance is required UDP permits packets to be dropped instead of processing delayed packets There is no error checking which also saves bandwidth Smaller packets than TCP Also used by DNS, DHCP, VoIP (Voice over Internet Protocol) Takes datagram from network layer Attaches its header and sends it to user, so it works fast","title":"UDP (User Datagram Protocol)"},{"location":"computer_networks/L4_transport_layer/congestion_control","text":"Congestion Control Congestion is a situation when too many sources attempt to send data And the router buffer starts overflowing Due to which packets are lost Retransmission of packets from the sources increases the congestion further Policy Slow Start Phase After every RTT, the congestion window size increments exponentially If congestion window is 1 segment & first segment is acked, window becomes 2 segments If next transmission of 2 segments is also acked, it doubles to 4, then 8, and so on Congestion Avoidance Phase After the threshold value, the congestion window increases additive If congestion window is 20 segments And all segments are acked within RTT, it increases to 21 segments If the next transmission is also acked, it increases to 22, and so on Congestion Detection Phase If congestion occurs, the congestion window size is decreased multiplicative The only way a sender can guess that congestion has happened is the need to retransmit Retransmission can occur when RTO timer times out Congestion possibility is high Threshold is reduced to half of the current window size Congestion window is set to 1 Slow start phase is started again Three duplicate ACKs are received Congestion possibility is less Threshold is reduced to half of the current window size Congestion window is set equal to threshold Congestion avoidance phase is started again Algorithms These two algorithms are used for traffic shaping That is, control the amount & rate of traffic sent to network Leaky Bucket Algorithm Controls the rate at which traffic is sent to the network And shape the burst traffic to a steady traffic stream Each network contains a leaky bucket When host wants to send packet, the packet is thrown into the bucket The bucket leaks (transmits packets) at a constant rate Bursty traffic is converted to uniform traffic Token Bucket Algorithm When large bursts arrive, the leaky bucket algorithm can lose packets This can happen if rate of traffic > rate of transmission of leaky bucket Since leaky bucket converts traffic to uniform traffic (fixed rate) Bucket contains tokens which define a packet of predetermined size Tokens in the bucket are deleted for the ability to share a packet No token means no flow sends its packets Tokens are generated at a fixed rate If there is no traffic, accumulated tokens could result in wasted resources Open Loop Techniques Applied to prevent congestion before it happens Retransmission Policy Packets are retransmitted if a sent packet is lost or corrupted To prevent congestion, retransmission timers must be designed efficiently Window Policy Several packets in go-back-n window are resent Although some of these packets may have been received successfully This duplication may increase the congestion Selective repeat window should be adopted As it sends only the specific lost packets Discarding Policy Routers can discard less sensitive or corrupted packages to prevent congestion Acknowledgement Policy The receiver can send cumulative ack for n packets rather than single acks It should send an ack only if it has to send a packet or timer expires Admission Policy Switches in a flow should first check the resource requirement Of the network flow before transmitting it further If there is a chance of congestion It should deny establishing a virtual network connection Closed Loop Techniques Used to alleviate congestion after it happens Backpressure Node to node congestion control that propogates in the opposite direction of data flow The congested node stops receiving packets from upstream node This may cause upstream node to become congested and reject data from above nodes Can be applied only to virtual circuit Where each node has info of its above upstream node Choke Packet Packet sent by a node to the source to inform about congestion Applicable to both virtual network and datagram subnets Each router monitors its resources and utilization at each of its output lines Whenever the resource utilization exceeds the threshold value set by administrator The router directly sends a choke packet to the source Giving the source feedback to reduce the traffic The intermediate nodes through which the packet has travelled Are not warned about congestion Implicit Signaling There is no communication between the congested nodes and the source The source guesses the congestion (e.g. not receiving acks for several packets) Explicit Signaling Node experiencing congestion explicitely sends a packet To source or destination to inform about the congestion Difference from the choke packet The signal is included in the packets that carry data Rather than creating a different packet (choke packet) Forward signaling: in the direction of congestion (destination is warned) Backward signaling: in the opposite direction of congestion (source is warned)","title":"Congestion Control"},{"location":"computer_networks/L4_transport_layer/congestion_control#congestion-control","text":"Congestion is a situation when too many sources attempt to send data And the router buffer starts overflowing Due to which packets are lost Retransmission of packets from the sources increases the congestion further","title":"Congestion Control"},{"location":"computer_networks/L4_transport_layer/congestion_control#policy","text":"","title":"Policy"},{"location":"computer_networks/L4_transport_layer/congestion_control#slow-start-phase","text":"After every RTT, the congestion window size increments exponentially If congestion window is 1 segment & first segment is acked, window becomes 2 segments If next transmission of 2 segments is also acked, it doubles to 4, then 8, and so on","title":"Slow Start Phase"},{"location":"computer_networks/L4_transport_layer/congestion_control#congestion-avoidance-phase","text":"After the threshold value, the congestion window increases additive If congestion window is 20 segments And all segments are acked within RTT, it increases to 21 segments If the next transmission is also acked, it increases to 22, and so on","title":"Congestion Avoidance Phase"},{"location":"computer_networks/L4_transport_layer/congestion_control#congestion-detection-phase","text":"If congestion occurs, the congestion window size is decreased multiplicative The only way a sender can guess that congestion has happened is the need to retransmit Retransmission can occur when RTO timer times out Congestion possibility is high Threshold is reduced to half of the current window size Congestion window is set to 1 Slow start phase is started again Three duplicate ACKs are received Congestion possibility is less Threshold is reduced to half of the current window size Congestion window is set equal to threshold Congestion avoidance phase is started again","title":"Congestion Detection Phase"},{"location":"computer_networks/L4_transport_layer/congestion_control#algorithms","text":"These two algorithms are used for traffic shaping That is, control the amount & rate of traffic sent to network","title":"Algorithms"},{"location":"computer_networks/L4_transport_layer/congestion_control#leaky-bucket-algorithm","text":"Controls the rate at which traffic is sent to the network And shape the burst traffic to a steady traffic stream Each network contains a leaky bucket When host wants to send packet, the packet is thrown into the bucket The bucket leaks (transmits packets) at a constant rate Bursty traffic is converted to uniform traffic","title":"Leaky Bucket Algorithm"},{"location":"computer_networks/L4_transport_layer/congestion_control#token-bucket-algorithm","text":"When large bursts arrive, the leaky bucket algorithm can lose packets This can happen if rate of traffic > rate of transmission of leaky bucket Since leaky bucket converts traffic to uniform traffic (fixed rate) Bucket contains tokens which define a packet of predetermined size Tokens in the bucket are deleted for the ability to share a packet No token means no flow sends its packets Tokens are generated at a fixed rate If there is no traffic, accumulated tokens could result in wasted resources","title":"Token Bucket Algorithm"},{"location":"computer_networks/L4_transport_layer/congestion_control#open-loop-techniques","text":"Applied to prevent congestion before it happens Retransmission Policy Packets are retransmitted if a sent packet is lost or corrupted To prevent congestion, retransmission timers must be designed efficiently Window Policy Several packets in go-back-n window are resent Although some of these packets may have been received successfully This duplication may increase the congestion Selective repeat window should be adopted As it sends only the specific lost packets Discarding Policy Routers can discard less sensitive or corrupted packages to prevent congestion Acknowledgement Policy The receiver can send cumulative ack for n packets rather than single acks It should send an ack only if it has to send a packet or timer expires Admission Policy Switches in a flow should first check the resource requirement Of the network flow before transmitting it further If there is a chance of congestion It should deny establishing a virtual network connection","title":"Open Loop Techniques"},{"location":"computer_networks/L4_transport_layer/congestion_control#closed-loop-techniques","text":"Used to alleviate congestion after it happens Backpressure Node to node congestion control that propogates in the opposite direction of data flow The congested node stops receiving packets from upstream node This may cause upstream node to become congested and reject data from above nodes Can be applied only to virtual circuit Where each node has info of its above upstream node Choke Packet Packet sent by a node to the source to inform about congestion Applicable to both virtual network and datagram subnets Each router monitors its resources and utilization at each of its output lines Whenever the resource utilization exceeds the threshold value set by administrator The router directly sends a choke packet to the source Giving the source feedback to reduce the traffic The intermediate nodes through which the packet has travelled Are not warned about congestion Implicit Signaling There is no communication between the congested nodes and the source The source guesses the congestion (e.g. not receiving acks for several packets) Explicit Signaling Node experiencing congestion explicitely sends a packet To source or destination to inform about the congestion Difference from the choke packet The signal is included in the packets that carry data Rather than creating a different packet (choke packet) Forward signaling: in the direction of congestion (destination is warned) Backward signaling: in the opposite direction of congestion (source is warned)","title":"Closed Loop Techniques"},{"location":"computer_networks/L5_session_layer/index","text":"L5: Session Layer Introduction","title":"Index"},{"location":"computer_networks/L5_session_layer/index#l5-session-layer","text":"Introduction","title":"L5: Session Layer"},{"location":"computer_networks/L5_session_layer/introduction","text":"Introduction Basic info Packet: Data Protocols: NetBIOS, PPTP, SSL, API Platforms: OS, Gateways, Firewalls Features Establishment of connection Maintenance & termination of sessions Ensuring security and managing authentication Allows a process to add checkpoints or synchronization points in the data Which help to identify errors and avoid data loss Allows systems to start communication in half-duplex or full-duplex mode","title":"Introduction"},{"location":"computer_networks/L5_session_layer/introduction#introduction","text":"Basic info Packet: Data Protocols: NetBIOS, PPTP, SSL, API Platforms: OS, Gateways, Firewalls Features Establishment of connection Maintenance & termination of sessions Ensuring security and managing authentication Allows a process to add checkpoints or synchronization points in the data Which help to identify errors and avoid data loss Allows systems to start communication in half-duplex or full-duplex mode","title":"Introduction"},{"location":"computer_networks/L6_presentation_layer/index","text":"L6: Presentation Layer Introduction","title":"Index"},{"location":"computer_networks/L6_presentation_layer/index#l6-presentation-layer","text":"Introduction","title":"L6: Presentation Layer"},{"location":"computer_networks/L6_presentation_layer/introduction","text":"Introduction Basic info Packet: Data Protocols: SSL, SSH, IMAP Platforms: OS, Gateways, Firewalls Features Data from application layer is extracted and manipulated to transmit over a network Concerned with syntax & semantics Translation, Compression, Encryption/Descryption","title":"Introduction"},{"location":"computer_networks/L6_presentation_layer/introduction#introduction","text":"Basic info Packet: Data Protocols: SSL, SSH, IMAP Platforms: OS, Gateways, Firewalls Features Data from application layer is extracted and manipulated to transmit over a network Concerned with syntax & semantics Translation, Compression, Encryption/Descryption","title":"Introduction"},{"location":"computer_networks/L7_application_layer/index","text":"L7: Application Layer Introduction HTTP (HyperText Transfer Protocol) ATM (Asynchronous Transfer Mode) SMTP (Simple Mail Transfer Protocol) FTP (File Transfer Protocol) SSH (Secure Shell) DNS (Domain Name System) DHCP (Dynamic Host Configuration Protocol)","title":"Index"},{"location":"computer_networks/L7_application_layer/index#l7-application-layer","text":"Introduction HTTP (HyperText Transfer Protocol) ATM (Asynchronous Transfer Mode) SMTP (Simple Mail Transfer Protocol) FTP (File Transfer Protocol) SSH (Secure Shell) DNS (Domain Name System) DHCP (Dynamic Host Configuration Protocol)","title":"L7: Application Layer"},{"location":"computer_networks/L7_application_layer/introduction","text":"Introduction Basic info Packet: Data Protocols: HTTP, DHCP, FTP, SSH, SMTP, DNS Platforms: Network applications, Browser, Messenger, Gateways, Firewalls Features Data produced by applications which needs to be transferred over the network Provides services to the user like file transfer, mail services, etc. Window for users and applications to access network services Network transparency, resource allocation Also called Desktop Layer Addressing Socket: Process sends/receive message to/from its socket Functions DNS (Domain Name System): Host Name to IP mapping File transfer, access and management Mail services Directory services: distributed database sources NTP (Network Time Protocol) Helps computer clock times to be synchronized in a network Uses UTC to synchronize CPU clock time Provides consistent timekeeping for file servers Hierarchical system of time resources At the topmost level, there are highly accurate time resources Atomic or GPS clocks These servers (stratum 0) are linked to the servers below Stratum 1, 2, 3 & so on Quality of Service (QoS) Traffic control mechanisms That differentiate performance based on application or network operator requirements Or provide predictable or guaranteed performance To applications, sessions, traffic aggregates Basic phenomenon is in terms of packet delay and losses of various kinds Used for time critical applications in which bounded delay is an important factor Video & audio conferencing or streaming requires bounded delay and loss rate Types Stateless solutions Routers maintain no fine-grained state about traffic Scalabe and robust But no guarantee about the kind of delay or performance in a particular application Stateful solutions Routers maintain per-flow state Much less scalable & robust But guaranteed services and high resource utilization Web Caching Substantially reduces response time and traffic for repeated requests Done by proxy server (intermediate entity between the original server & client) If a request is cached Proxy server forwards the cached result directly to the client Otherwise it queries on behalf of the host Caches it and forwards the result back to the host Usually installed by ISP, universities, corporate offices What if the content was modified on the original server Conditional GET is used Which queries the original server to get the last modified since The original server returns the data Only if the validator for last modified since passes If the content was modified, it updates the cache and forwards to the client","title":"Introduction"},{"location":"computer_networks/L7_application_layer/introduction#introduction","text":"Basic info Packet: Data Protocols: HTTP, DHCP, FTP, SSH, SMTP, DNS Platforms: Network applications, Browser, Messenger, Gateways, Firewalls Features Data produced by applications which needs to be transferred over the network Provides services to the user like file transfer, mail services, etc. Window for users and applications to access network services Network transparency, resource allocation Also called Desktop Layer Addressing Socket: Process sends/receive message to/from its socket Functions DNS (Domain Name System): Host Name to IP mapping File transfer, access and management Mail services Directory services: distributed database sources","title":"Introduction"},{"location":"computer_networks/L7_application_layer/introduction#ntp-network-time-protocol","text":"Helps computer clock times to be synchronized in a network Uses UTC to synchronize CPU clock time Provides consistent timekeeping for file servers Hierarchical system of time resources At the topmost level, there are highly accurate time resources Atomic or GPS clocks These servers (stratum 0) are linked to the servers below Stratum 1, 2, 3 & so on","title":"NTP (Network Time Protocol)"},{"location":"computer_networks/L7_application_layer/introduction#quality-of-service-qos","text":"Traffic control mechanisms That differentiate performance based on application or network operator requirements Or provide predictable or guaranteed performance To applications, sessions, traffic aggregates Basic phenomenon is in terms of packet delay and losses of various kinds Used for time critical applications in which bounded delay is an important factor Video & audio conferencing or streaming requires bounded delay and loss rate","title":"Quality of Service (QoS)"},{"location":"computer_networks/L7_application_layer/introduction#types","text":"Stateless solutions Routers maintain no fine-grained state about traffic Scalabe and robust But no guarantee about the kind of delay or performance in a particular application Stateful solutions Routers maintain per-flow state Much less scalable & robust But guaranteed services and high resource utilization","title":"Types"},{"location":"computer_networks/L7_application_layer/introduction#web-caching","text":"Substantially reduces response time and traffic for repeated requests Done by proxy server (intermediate entity between the original server & client) If a request is cached Proxy server forwards the cached result directly to the client Otherwise it queries on behalf of the host Caches it and forwards the result back to the host Usually installed by ISP, universities, corporate offices What if the content was modified on the original server Conditional GET is used Which queries the original server to get the last modified since The original server returns the data Only if the validator for last modified since passes If the content was modified, it updates the cache and forwards to the client","title":"Web Caching"},{"location":"computer_networks/L7_application_layer/http_hypertext_transfer_protocol","text":"HTTP (HyperText Transfer Protocol) Communication protocol used to deliver data between a client and a server Data such as text, images, and other multimedia files are shared on WWW Uses hypertext pages that can be interlinked with each other to form web pages HTML is used to generate these pages HTTP protocol transfers the hypertext pages from web server to web browser Methods HTTP/1.1: GET, POST, HEAD, PUT, DELETE Status Code: 200: OK 301: Moved Permanently 400: Bad Request 404: Not Found 505: HTTP version not supported Details Connectionless protocol After the connection is closed The client and the server don't remember anything about each other Stateless protocol Server maintains no information about past client requests Each transaction on the protocol is carried out independently of the others Without reference to the history After the transaction is finished The connection between the browser and the server ends Client-server model that uses TCP Client initiates TCP connection (creates socket) to server, port 80 Server accepts connection, notifying client HTTP messages are exchanged between browser (client) and web server HTTPS (HTTP Secure) Combination of HTTP with SSL/TLS convention to supply encrypted communication And secure distinguishing proof of an arranged web server Encrypts all message substance including HTTP headers and the request/reponse data Requires a trusted third party to sign server side digital certificate Types Non-persistent Each object requires a new TCP connection for transmission With parallel connection for multiple objects Requires extra overhead to transfer data Without parallel connection Requires 2 RTTs (Round Trip Time) per object Response time per object = 1 RTT for connection + 1 RTT for file transmission Connection is opened & closed each time Which is more secure & does not waste resources But results in an extra overhead and slow speed Persistent Multiple objects over one TCP connection After a connection is established that takes 1 RTT Multiple objects can be sent over the same network that takes 1 RTT Response time per object = 1 RTT (File transmission time) Types Non-pipelined: Another request can be sent only if previous request is acked Pipelined: Another request can be sent even if previous request is not acked Connection remains open Which is less secure & wastes network resources But removes the extra overhead of connection establishment and is fast Cookies Since HTTP is stateless protocol Cookies help to keep state & give customized experience to user Uses: authorization, shopping carts, recommendations, user session state Servers can take swift action using cookies even one week later Conditional Requests Similar to the standard HTTP requests But are only fulfilled by the server if the specified validators pass Useful to validate content of a cache, verify integrity of a document","title":"Http Hypertext Transfer Protocol"},{"location":"computer_networks/L7_application_layer/http_hypertext_transfer_protocol#http-hypertext-transfer-protocol","text":"Communication protocol used to deliver data between a client and a server Data such as text, images, and other multimedia files are shared on WWW Uses hypertext pages that can be interlinked with each other to form web pages HTML is used to generate these pages HTTP protocol transfers the hypertext pages from web server to web browser Methods HTTP/1.1: GET, POST, HEAD, PUT, DELETE Status Code: 200: OK 301: Moved Permanently 400: Bad Request 404: Not Found 505: HTTP version not supported","title":"HTTP (HyperText Transfer Protocol)"},{"location":"computer_networks/L7_application_layer/http_hypertext_transfer_protocol#details","text":"Connectionless protocol After the connection is closed The client and the server don't remember anything about each other Stateless protocol Server maintains no information about past client requests Each transaction on the protocol is carried out independently of the others Without reference to the history After the transaction is finished The connection between the browser and the server ends Client-server model that uses TCP Client initiates TCP connection (creates socket) to server, port 80 Server accepts connection, notifying client HTTP messages are exchanged between browser (client) and web server","title":"Details"},{"location":"computer_networks/L7_application_layer/http_hypertext_transfer_protocol#https-http-secure","text":"Combination of HTTP with SSL/TLS convention to supply encrypted communication And secure distinguishing proof of an arranged web server Encrypts all message substance including HTTP headers and the request/reponse data Requires a trusted third party to sign server side digital certificate","title":"HTTPS (HTTP Secure)"},{"location":"computer_networks/L7_application_layer/http_hypertext_transfer_protocol#types","text":"","title":"Types"},{"location":"computer_networks/L7_application_layer/http_hypertext_transfer_protocol#non-persistent","text":"Each object requires a new TCP connection for transmission With parallel connection for multiple objects Requires extra overhead to transfer data Without parallel connection Requires 2 RTTs (Round Trip Time) per object Response time per object = 1 RTT for connection + 1 RTT for file transmission Connection is opened & closed each time Which is more secure & does not waste resources But results in an extra overhead and slow speed","title":"Non-persistent"},{"location":"computer_networks/L7_application_layer/http_hypertext_transfer_protocol#persistent","text":"Multiple objects over one TCP connection After a connection is established that takes 1 RTT Multiple objects can be sent over the same network that takes 1 RTT Response time per object = 1 RTT (File transmission time) Types Non-pipelined: Another request can be sent only if previous request is acked Pipelined: Another request can be sent even if previous request is not acked Connection remains open Which is less secure & wastes network resources But removes the extra overhead of connection establishment and is fast","title":"Persistent"},{"location":"computer_networks/L7_application_layer/http_hypertext_transfer_protocol#cookies","text":"Since HTTP is stateless protocol Cookies help to keep state & give customized experience to user Uses: authorization, shopping carts, recommendations, user session state Servers can take swift action using cookies even one week later","title":"Cookies"},{"location":"computer_networks/L7_application_layer/http_hypertext_transfer_protocol#conditional-requests","text":"Similar to the standard HTTP requests But are only fulfilled by the server if the specified validators pass Useful to validate content of a cache, verify integrity of a document","title":"Conditional Requests"},{"location":"computer_networks/L7_application_layer/atm_asynchonous_transfer_mode","text":"Aysnchronous Transfer Mode (ATM) Telecommunications standard for digital transmission of multiple types of traffic Can handle both Traditional high throughput data And real-time low latency content Can handle both constant and variable rate traffic Transmits all information over connection-oriented network Including data, video, voice Was developed to meet the needs of Broadband ISDN And is a core protocol used in SONET Details Uses small fixed-size packets called cells which are transmitted asynchonously In contrast, IP packets are of variable size Independent of transmission medium Uses virtual circuit switching (path is reserved before transmission) Working Uses Virtual path connections (VPC) That consist of virtual channel connections (VCC) bundled together VCC is a basic unit carrying a single stream of cells from user to user Making an ATM call First sends a message to set up a connection Subsequently, all cells follow the same path to the destination Addressing 20-byte global NSAP (Network Service Access Point) address for signaling 32-bit locally assigned labels in cells Layers ATM Adaption Layer (AAL) Isolates higher layer protocols from details of ATM processes Prepares for conversion of user data into cells Physical Layer Controls transmission and receipt of bits in physical medium Converts cells to bitstream and tracks ATM cell boundaries ATM Layer Handles transmission, switching, congestion control Cell header processing, sequential delivery Cell multiplexing: Simultaneous sharing of virtual circuits over physical link Call relay Passing cells through an ATM network Making use of VPI & VCI info in cell header","title":"Atm Asynchonous Transfer Mode"},{"location":"computer_networks/L7_application_layer/atm_asynchonous_transfer_mode#aysnchronous-transfer-mode-atm","text":"Telecommunications standard for digital transmission of multiple types of traffic Can handle both Traditional high throughput data And real-time low latency content Can handle both constant and variable rate traffic Transmits all information over connection-oriented network Including data, video, voice Was developed to meet the needs of Broadband ISDN And is a core protocol used in SONET","title":"Aysnchronous Transfer Mode (ATM)"},{"location":"computer_networks/L7_application_layer/atm_asynchonous_transfer_mode#details","text":"Uses small fixed-size packets called cells which are transmitted asynchonously In contrast, IP packets are of variable size Independent of transmission medium Uses virtual circuit switching (path is reserved before transmission) Working Uses Virtual path connections (VPC) That consist of virtual channel connections (VCC) bundled together VCC is a basic unit carrying a single stream of cells from user to user Making an ATM call First sends a message to set up a connection Subsequently, all cells follow the same path to the destination Addressing 20-byte global NSAP (Network Service Access Point) address for signaling 32-bit locally assigned labels in cells","title":"Details"},{"location":"computer_networks/L7_application_layer/atm_asynchonous_transfer_mode#layers","text":"ATM Adaption Layer (AAL) Isolates higher layer protocols from details of ATM processes Prepares for conversion of user data into cells Physical Layer Controls transmission and receipt of bits in physical medium Converts cells to bitstream and tracks ATM cell boundaries ATM Layer Handles transmission, switching, congestion control Cell header processing, sequential delivery Cell multiplexing: Simultaneous sharing of virtual circuits over physical link Call relay Passing cells through an ATM network Making use of VPI & VCI info in cell header","title":"Layers"},{"location":"computer_networks/L7_application_layer/smtp_simple_mail_transfer_protocol","text":"SMTP (Simple Mail Transfer Protocol) SMTP is a push protocol used to send emails POP/IMAP are used to retrieve emails POP (Post Office Protocol) IMAP (Internet Message Access Protocol) Types End-to-end: Used to communicate between different organizations Store-and-forward: Used within an organization Working Sender opens a TCP connection to the SMTP server SMTP server is always on listening mode, it listens & establishes the TCP connection Sender sends the mail over the connection SMTP server keeps the mail to itself until it is successfully delivered Components Sender's user agent prepares a message and sends it to the Mail Transfer Agent (MTA) MTA maintains a small queue To schedule repeat delivery of mail in case receiver is not available MTA transfers the mail across the network to the receiver's MTA The user agent on the server side checks the mailboxes at regular intervals If any information is received, it informs the user about the mail MIME (Multipurpose Internet Mail Extension) Supplementary protocol that allows non-ASCII data to be sent through SMTP Allows users to exchange data like audio, video, images, application programs Enables to use HTML and CSS in emails to customize and beautify them Allows using different languages like Hindi, French, Japanese, etc Working SMTP has a simple structure and sends message only in NVT 7-bit ASCII format MIME transforms non-ASCII data to NVT 7-bit ASCII data at the sender side And delivers to the client SMTP where the inversion happens MIME header is added to the email to define transformation and content info","title":"Smtp Simple Mail Transfer Protocol"},{"location":"computer_networks/L7_application_layer/smtp_simple_mail_transfer_protocol#smtp-simple-mail-transfer-protocol","text":"SMTP is a push protocol used to send emails POP/IMAP are used to retrieve emails POP (Post Office Protocol) IMAP (Internet Message Access Protocol) Types End-to-end: Used to communicate between different organizations Store-and-forward: Used within an organization","title":"SMTP (Simple Mail Transfer Protocol)"},{"location":"computer_networks/L7_application_layer/smtp_simple_mail_transfer_protocol#working","text":"Sender opens a TCP connection to the SMTP server SMTP server is always on listening mode, it listens & establishes the TCP connection Sender sends the mail over the connection SMTP server keeps the mail to itself until it is successfully delivered","title":"Working"},{"location":"computer_networks/L7_application_layer/smtp_simple_mail_transfer_protocol#components","text":"Sender's user agent prepares a message and sends it to the Mail Transfer Agent (MTA) MTA maintains a small queue To schedule repeat delivery of mail in case receiver is not available MTA transfers the mail across the network to the receiver's MTA The user agent on the server side checks the mailboxes at regular intervals If any information is received, it informs the user about the mail","title":"Components"},{"location":"computer_networks/L7_application_layer/smtp_simple_mail_transfer_protocol#mime-multipurpose-internet-mail-extension","text":"Supplementary protocol that allows non-ASCII data to be sent through SMTP Allows users to exchange data like audio, video, images, application programs Enables to use HTML and CSS in emails to customize and beautify them Allows using different languages like Hindi, French, Japanese, etc Working SMTP has a simple structure and sends message only in NVT 7-bit ASCII format MIME transforms non-ASCII data to NVT 7-bit ASCII data at the sender side And delivers to the client SMTP where the inversion happens MIME header is added to the email to define transformation and content info","title":"MIME (Multipurpose Internet Mail Extension)"},{"location":"computer_networks/L7_application_layer/ftp_file_transfer_protocol","text":"File Transfer Protocol Moves files between local and remote file systems Shields users from system differences like OS, directory structure, character sets Can transfer these categories of data ASCII & EBCDIC Image File has no formal internal structure Transferred one byte at a time without any processing Local: File containing data in logical bytes Working Two TCP connections are used in parallel It sends control info in separate connection, so it's called out-of-band Protocols like HTTP & SMTP that send it in same connection are called in-band Control connection Initiated by client to send info like user identification, password Commands to change the remote directory Commands to retrieve & store files Initiated on port number 21 Persistent & stateful connection Remains active throughout the session to maintain a state about user Data connection Initiated by server after control info has been sent by client To send the actual file Initiated on port number 20 Non persistent & stateless connection","title":"Ftp File Transfer Protocol"},{"location":"computer_networks/L7_application_layer/ftp_file_transfer_protocol#file-transfer-protocol","text":"Moves files between local and remote file systems Shields users from system differences like OS, directory structure, character sets Can transfer these categories of data ASCII & EBCDIC Image File has no formal internal structure Transferred one byte at a time without any processing Local: File containing data in logical bytes","title":"File Transfer Protocol"},{"location":"computer_networks/L7_application_layer/ftp_file_transfer_protocol#working","text":"Two TCP connections are used in parallel It sends control info in separate connection, so it's called out-of-band Protocols like HTTP & SMTP that send it in same connection are called in-band","title":"Working"},{"location":"computer_networks/L7_application_layer/ftp_file_transfer_protocol#control-connection","text":"Initiated by client to send info like user identification, password Commands to change the remote directory Commands to retrieve & store files Initiated on port number 21 Persistent & stateful connection Remains active throughout the session to maintain a state about user","title":"Control connection"},{"location":"computer_networks/L7_application_layer/ftp_file_transfer_protocol#data-connection","text":"Initiated by server after control info has been sent by client To send the actual file Initiated on port number 20 Non persistent & stateless connection","title":"Data connection"},{"location":"computer_networks/L7_application_layer/ssh_secure_shell","text":"SSH (Secure Shell) Cryptographic network protocol used to transfer encrypted data over a network Allows you to connect to a server without having to enter password for each system The port number of SSH is 22 Features: Encryption, authentication, tunneling Comes in key pairs Public key: For encryption function, everyone can see it, no need to protect Private key: For decryption function, stays in computer, must be protected Types of key pairs User key: If public & private key remain with the user Host key: If public & private key are on a remote system Session key: Used when a large amount of data is to be transmitted Working Public keys from the local system are passed to the server The server identifies if the public key is registered If so, the server creates a new secret key And encrypts it with the public key The encrypted code is sent to the local system The data is unlocked by the private key of the system And is sent to the server The server after receiving this data verifies the local system SSH creates a route And all the encrypted data are transferred through it with no security issue","title":"Ssh Secure Shell"},{"location":"computer_networks/L7_application_layer/ssh_secure_shell#ssh-secure-shell","text":"Cryptographic network protocol used to transfer encrypted data over a network Allows you to connect to a server without having to enter password for each system The port number of SSH is 22 Features: Encryption, authentication, tunneling Comes in key pairs Public key: For encryption function, everyone can see it, no need to protect Private key: For decryption function, stays in computer, must be protected Types of key pairs User key: If public & private key remain with the user Host key: If public & private key are on a remote system Session key: Used when a large amount of data is to be transmitted","title":"SSH (Secure Shell)"},{"location":"computer_networks/L7_application_layer/ssh_secure_shell#working","text":"Public keys from the local system are passed to the server The server identifies if the public key is registered If so, the server creates a new secret key And encrypts it with the public key The encrypted code is sent to the local system The data is unlocked by the private key of the system And is sent to the server The server after receiving this data verifies the local system SSH creates a route And all the encrypted data are transferred through it with no security issue","title":"Working"},{"location":"computer_networks/L7_application_layer/dns_domain_system_name","text":"Domain Name System (DNS) Distributed database implemented in a heirarchy of name servers Every host is identified by its IP address But managing numbers is very difficult since there are millions of websites Also IP addreesses are not static, they can change So domain names are used instead and are converted to their IP address by DNS Uses UDP because UDP is much faster than TCP which uses 3 way handshake end-to-end connection DNS servers don't have to keep connections DNS requests are generally very small and fit well within UDP segments Reliability can be increased at application layer by using timeout & resend DNS Lookup Client sends a request to a DNS resolver to resolve a domain name If not found, it can Send request to other or high level servers (recursive lookup) Or it can refer the resolver to other servers (iterative lookup) This process keeps repeating at each level till the DNS is resolved Once found, the results are cached based on the frequency or other factors Servers in order of lookup Local name server Root name server Top level domain (TLD) Manages entries for domains like com, org, edu, uk, fr, ca, in Authoritative name server: Maintained by organization or service provider","title":"Dns Domain System Name"},{"location":"computer_networks/L7_application_layer/dns_domain_system_name#domain-name-system-dns","text":"Distributed database implemented in a heirarchy of name servers Every host is identified by its IP address But managing numbers is very difficult since there are millions of websites Also IP addreesses are not static, they can change So domain names are used instead and are converted to their IP address by DNS Uses UDP because UDP is much faster than TCP which uses 3 way handshake end-to-end connection DNS servers don't have to keep connections DNS requests are generally very small and fit well within UDP segments Reliability can be increased at application layer by using timeout & resend","title":"Domain Name System (DNS)"},{"location":"computer_networks/L7_application_layer/dns_domain_system_name#dns-lookup","text":"Client sends a request to a DNS resolver to resolve a domain name If not found, it can Send request to other or high level servers (recursive lookup) Or it can refer the resolver to other servers (iterative lookup) This process keeps repeating at each level till the DNS is resolved Once found, the results are cached based on the frequency or other factors Servers in order of lookup Local name server Root name server Top level domain (TLD) Manages entries for domains like com, org, edu, uk, fr, ca, in Authoritative name server: Maintained by organization or service provider","title":"DNS Lookup"},{"location":"computer_networks/L7_application_layer/dhcp_dynamic_host_configuration_protocol","text":"Dynamic Host Configuration Protocol (DHCP) Helps enterprises to smoothly manage the allocation of IP addresses to the client devices Maintains information on TCP/IP configuration IP addresses are assigned using DORA messages Discover, Offer, Request, Acknowledgements But if hosts have no IP address initially how they form IP packets to assign the address It uses two reserved IP addresses for this purpose 0.0.0.0 Reserved to use as sender's address for hosts That doesn't have IP address assigned yet 255.255.255.255 Local broadcast address Routers don't forward packet containing this address as destination addresss DNS broadcasts packages to the client host Switch takes care of the broadcasting Working (DORA Process) Discover message Client generates a DHCP discover message And broadcasts to all devices to find the DHCP server Offer message Server responds to the client by specifying IP address And other TCP configuration information This offer message is broadcasted by the DHCP server and includes the server id If there are multiple DHCP servers in the network The client will accept the first DHCP offer message Request message After receiving the offer message Client responds by broadcasting a DHCP request message It produces a gratuitous ARP To find if there is any other host in the network with the same IP address If there is no reply from another host The message is broadcasted to the server showing acceptance of the IP address A client id is also added to this message Acknowledgement message In response to the request message received Server will make an entry with the specified client ID And bind the IP address offered with lease time Other Messages Negative acknowledgement message If the request for IP address is invalid according to the configured scopes It sends NAK message to the client For example, when there is no IP address left in the pool Decline message If the offered configuration parameters are invalid The client sends a decline message to the server For example, when there is a reply to the gratuitous ARP by any host to the client Release message Client sends a release packet to the server To release the IP address and cancel any remaining lease time Inform message If the client has obtained the IP address manually Then it uses inform meessage To obtain other local configuration parameters like domain name In response to this, the server unicasts an ack message to the client with the info Relay Agent DHCP relay agent is any TCP/IP host Which is used to forward requests and replies between the DHCP server and client Listens for DHCP broadcast messages from client devices And forwards them to DHCP server encapsulating them in a unicast packet The discover and request messages are unicast to DHCP server by the relay agent It is required when the server is present on a different network Commonly used in large enterprise networks that have different network segments Adds a gateway address of the packet (giaddr) field to packets Used to indicate IP address of the relay agent interface On which the message was received To add additional info like interface or port number Relay agent information option 82 can be used Can be implemented in dedicated hardware devices Or in software on routers or other devices","title":"Dhcp Dynamic Host Configuration Protocol"},{"location":"computer_networks/L7_application_layer/dhcp_dynamic_host_configuration_protocol#dynamic-host-configuration-protocol-dhcp","text":"Helps enterprises to smoothly manage the allocation of IP addresses to the client devices Maintains information on TCP/IP configuration IP addresses are assigned using DORA messages Discover, Offer, Request, Acknowledgements But if hosts have no IP address initially how they form IP packets to assign the address It uses two reserved IP addresses for this purpose 0.0.0.0 Reserved to use as sender's address for hosts That doesn't have IP address assigned yet 255.255.255.255 Local broadcast address Routers don't forward packet containing this address as destination addresss DNS broadcasts packages to the client host Switch takes care of the broadcasting","title":"Dynamic Host Configuration Protocol (DHCP)"},{"location":"computer_networks/L7_application_layer/dhcp_dynamic_host_configuration_protocol#working-dora-process","text":"Discover message Client generates a DHCP discover message And broadcasts to all devices to find the DHCP server Offer message Server responds to the client by specifying IP address And other TCP configuration information This offer message is broadcasted by the DHCP server and includes the server id If there are multiple DHCP servers in the network The client will accept the first DHCP offer message Request message After receiving the offer message Client responds by broadcasting a DHCP request message It produces a gratuitous ARP To find if there is any other host in the network with the same IP address If there is no reply from another host The message is broadcasted to the server showing acceptance of the IP address A client id is also added to this message Acknowledgement message In response to the request message received Server will make an entry with the specified client ID And bind the IP address offered with lease time","title":"Working (DORA Process)"},{"location":"computer_networks/L7_application_layer/dhcp_dynamic_host_configuration_protocol#other-messages","text":"Negative acknowledgement message If the request for IP address is invalid according to the configured scopes It sends NAK message to the client For example, when there is no IP address left in the pool Decline message If the offered configuration parameters are invalid The client sends a decline message to the server For example, when there is a reply to the gratuitous ARP by any host to the client Release message Client sends a release packet to the server To release the IP address and cancel any remaining lease time Inform message If the client has obtained the IP address manually Then it uses inform meessage To obtain other local configuration parameters like domain name In response to this, the server unicasts an ack message to the client with the info","title":"Other Messages"},{"location":"computer_networks/L7_application_layer/dhcp_dynamic_host_configuration_protocol#relay-agent","text":"DHCP relay agent is any TCP/IP host Which is used to forward requests and replies between the DHCP server and client Listens for DHCP broadcast messages from client devices And forwards them to DHCP server encapsulating them in a unicast packet The discover and request messages are unicast to DHCP server by the relay agent It is required when the server is present on a different network Commonly used in large enterprise networks that have different network segments Adds a gateway address of the packet (giaddr) field to packets Used to indicate IP address of the relay agent interface On which the message was received To add additional info like interface or port number Relay agent information option 82 can be used Can be implemented in dedicated hardware devices Or in software on routers or other devices","title":"Relay Agent"},{"location":"database_system/index","text":"Database Management System Introduction Entity Relationship Model Relational Model Functional Dependency Normalization Transactions and Schedules Concurrency Control Concurrency Control Protocols Recoverability and Processing Indexing File Organization","title":"Index"},{"location":"database_system/index#database-management-system","text":"Introduction Entity Relationship Model Relational Model Functional Dependency Normalization Transactions and Schedules Concurrency Control Concurrency Control Protocols Recoverability and Processing Indexing File Organization","title":"Database Management System"},{"location":"database_system/introduction","text":"Introduction Data: Collection of units of information Database: Organized collection of data that can be easily managed Database Management System Software system designed to enable users to store, organize & manage a database Manages security and access control Scalability: Handles large amounts of data Drawbacks of File System Redundancy: If some data needs to be updated, it takes a lot of effort Inconsistency For the same information, there can be different data at different places Data access To access a particular info, user should already know the file The file that the info is stored in and its location Unauthorised access: Anyone can access and update the data in unauthorized way No backup & recovery Key features Data modeling: Data models define the structure & relationships of the data Data storage & retrieval: Create, modify, query data Concurrency control Allow multiple users to access data without conflicting with each other Data integrity & security Constraints on the values of data and access control to restrict users Backup & recorvery Multiple data views: Same data can be represented in different ways Analytics & reporting Types Relational DBMS: SQL The data is organized in the form of tables, and tables in rows & columns The data is related to each other through primary & foreign keys Non-Relational DBMS: NoSQL The data is organized in the form of key-value pairs, documents, graphs, or columns Designed to handle large scale, high performance scenarios Components Database Object Any defined object in database used to store, reference, hold or manipulate data Table: Basic unit of storage composed of rows & columns View: Logically represented subset of data from one or more tables Index: Improves performance of fetching data Sequence: Generates primary key values Synonym: Alternative name for an object Database Languages Data Definition Language (DDL) Deals with schemas and descriptions about how the data should reside in the database Create, Alter, Drop, Truncate (remove all records from table), Rename Data Manipulation Language (DML) Used to store, modify, retrieve, delete and update data Select, Insert, Update, Delete Data Control Lanuage (DCL) Access specifier to grant and revoke permissions to users Grant, Revoke Transaction Control Language (TCL) Manager for all transactional data and transaction Rollback, Commit, Savepoint (Save data temporarily) Three Layer Architecture Physical or Internal Layer Keeps info about the location of database objects in data store Describes how the data is being stored in secondary storage Conceptual or Logical Layer Data is represented in the form of tables and relations Describes what kind of data is to be stored (schema) External or View Layer View of data in terms of conceptual level tables Users can view data in form of rows & columns Different views can be generated for different users Data Independence Change of data at one level should not affect another level Physical data independence Change in physical location of tables & indexes Should not affect conceptual or external level The changes can be Using new storage devices Modifying data structures used for storage or altering indexes Using alternative file organization techniques Conceptual data independence Adding or deleting attributes in a table should not affect the user's view of table Other changes can be altering table structures or relationships Difficult to achieve compared to physical data independence Multimedia Database Stores documents, graphics, images, animations, video, audio, etc Types of media: Static media, dynamic media, dimensional media Contents Media data: Actual data representing an object Format data Information about the format of media data Like sampling rate, resolution, encoding scheme After it goes through acquisition, processing & encoding phase Keyword data Keyword description related to the generation of data like date, time, place Feature data Content dependent data Like distribution of colors, kinds of texture, different shapes present in data Types based on data management Repository applications Data & metadata stored for retrieval purpose Like format, date, keyword data, feature data Examples Repository of satellite images, engineering drawings, radiology scanned pictures Presentation applications Delivery of multimedia data subject to temporal constraint Optimal viewing or listening requires delivering data at certain rate Data is processed as it is delivered Offers quality of service above certain threshold Example: Annotating video & audio data, real time editing analysis Colloborative applications Executing complex task by merging drawings, changing notifications Example: Intelligent healthcare network Challenges Modelling & design There can be performance & tuning issues In external, conceptual & physical design layers Designing can be complex due to various formats like jpeg, gif, png, mpeg These formats are not easy to convert from one form to another Storage Challenge of representation, compression, archiving, buffering And mapping device hierarchies BLOB (Binary Large Object) facility allows untyped bitmaps to be stored and retrieved Performance Physical limitations in video playback or audio-video synchronization Parallel processing may alleviate some problems But such techniques are not fully developed Multimedia database consumes a lot of processing time and bandwidth Queries & retrieval Accessing data for multimedia through query have many issues Query formulation, query execution and optimization needs to be worked upon","title":"Introduction"},{"location":"database_system/introduction#introduction","text":"Data: Collection of units of information Database: Organized collection of data that can be easily managed Database Management System Software system designed to enable users to store, organize & manage a database Manages security and access control Scalability: Handles large amounts of data","title":"Introduction"},{"location":"database_system/introduction#drawbacks-of-file-system","text":"Redundancy: If some data needs to be updated, it takes a lot of effort Inconsistency For the same information, there can be different data at different places Data access To access a particular info, user should already know the file The file that the info is stored in and its location Unauthorised access: Anyone can access and update the data in unauthorized way No backup & recovery","title":"Drawbacks of File System"},{"location":"database_system/introduction#key-features","text":"Data modeling: Data models define the structure & relationships of the data Data storage & retrieval: Create, modify, query data Concurrency control Allow multiple users to access data without conflicting with each other Data integrity & security Constraints on the values of data and access control to restrict users Backup & recorvery Multiple data views: Same data can be represented in different ways Analytics & reporting","title":"Key features"},{"location":"database_system/introduction#types","text":"Relational DBMS: SQL The data is organized in the form of tables, and tables in rows & columns The data is related to each other through primary & foreign keys Non-Relational DBMS: NoSQL The data is organized in the form of key-value pairs, documents, graphs, or columns Designed to handle large scale, high performance scenarios","title":"Types"},{"location":"database_system/introduction#components","text":"","title":"Components"},{"location":"database_system/introduction#database-object","text":"Any defined object in database used to store, reference, hold or manipulate data Table: Basic unit of storage composed of rows & columns View: Logically represented subset of data from one or more tables Index: Improves performance of fetching data Sequence: Generates primary key values Synonym: Alternative name for an object","title":"Database Object"},{"location":"database_system/introduction#database-languages","text":"Data Definition Language (DDL) Deals with schemas and descriptions about how the data should reside in the database Create, Alter, Drop, Truncate (remove all records from table), Rename Data Manipulation Language (DML) Used to store, modify, retrieve, delete and update data Select, Insert, Update, Delete Data Control Lanuage (DCL) Access specifier to grant and revoke permissions to users Grant, Revoke Transaction Control Language (TCL) Manager for all transactional data and transaction Rollback, Commit, Savepoint (Save data temporarily)","title":"Database Languages"},{"location":"database_system/introduction#three-layer-architecture","text":"Physical or Internal Layer Keeps info about the location of database objects in data store Describes how the data is being stored in secondary storage Conceptual or Logical Layer Data is represented in the form of tables and relations Describes what kind of data is to be stored (schema) External or View Layer View of data in terms of conceptual level tables Users can view data in form of rows & columns Different views can be generated for different users","title":"Three Layer Architecture"},{"location":"database_system/introduction#data-independence","text":"Change of data at one level should not affect another level Physical data independence Change in physical location of tables & indexes Should not affect conceptual or external level The changes can be Using new storage devices Modifying data structures used for storage or altering indexes Using alternative file organization techniques Conceptual data independence Adding or deleting attributes in a table should not affect the user's view of table Other changes can be altering table structures or relationships Difficult to achieve compared to physical data independence","title":"Data Independence"},{"location":"database_system/introduction#multimedia-database","text":"Stores documents, graphics, images, animations, video, audio, etc Types of media: Static media, dynamic media, dimensional media","title":"Multimedia Database"},{"location":"database_system/introduction#contents","text":"Media data: Actual data representing an object Format data Information about the format of media data Like sampling rate, resolution, encoding scheme After it goes through acquisition, processing & encoding phase Keyword data Keyword description related to the generation of data like date, time, place Feature data Content dependent data Like distribution of colors, kinds of texture, different shapes present in data","title":"Contents"},{"location":"database_system/introduction#types-based-on-data-management","text":"Repository applications Data & metadata stored for retrieval purpose Like format, date, keyword data, feature data Examples Repository of satellite images, engineering drawings, radiology scanned pictures Presentation applications Delivery of multimedia data subject to temporal constraint Optimal viewing or listening requires delivering data at certain rate Data is processed as it is delivered Offers quality of service above certain threshold Example: Annotating video & audio data, real time editing analysis Colloborative applications Executing complex task by merging drawings, changing notifications Example: Intelligent healthcare network","title":"Types based on data management"},{"location":"database_system/introduction#challenges","text":"Modelling & design There can be performance & tuning issues In external, conceptual & physical design layers Designing can be complex due to various formats like jpeg, gif, png, mpeg These formats are not easy to convert from one form to another Storage Challenge of representation, compression, archiving, buffering And mapping device hierarchies BLOB (Binary Large Object) facility allows untyped bitmaps to be stored and retrieved Performance Physical limitations in video playback or audio-video synchronization Parallel processing may alleviate some problems But such techniques are not fully developed Multimedia database consumes a lot of processing time and bandwidth Queries & retrieval Accessing data for multimedia through query have many issues Query formulation, query execution and optimization needs to be worked upon","title":"Challenges"},{"location":"database_system/entity_relationship_model","text":"Entity Relationship Model Representation of entities and their relationships Representations Entity Strong: Rectange Weak: Double Rectangle Entity Set: Vertical Oval Attribute Single-valued: Oval Key: Oval with Underline Multi-valued: Double Oval Derived: Dashed Oval Relationship: Diamond Identifying Relationship: Double Diamond Participation Total: Double Line Partial: Line Entity Also known as Entity Type Strong Entity Entity that has a key attribute and does not depend on other entities Records are identified uniquely using primary key Weak Entity Dependent entity with no key attribute Example: Salary entity won't exist without employee entity Participation: Total Entity Set: Set of individual entities (instances of entity type) Attributes Properties that define the entity type Key Attribute: Uniquely identifies each entity in the entity set Composite Attribute Attribute composed of many other attributes Example: Address consists of street, city, state, country Multi-valued Attribute Example: There can be multiple Email for a user Derived Attribute Example: Age attribute can be derived from date of birth Relationship Association between entity types Identifying Relationship Relationship between weak entity & its identifying strong entity Relationship Set: Set of relationships of the same type Degree Number of different entity sets participating in a relationship set Unary One entity is related to another entity of the same type Example: A person is married to another person Binary One entity is related to another entity of a different type Example: A student is enrolled in a course N-ary More than 2 entities are related Example: A doctor prescribes a medicine to a patient Cardinality Number of times an entity participates in a relationship One to One An employee can have only one salary Minimum tables required Total Participation: 1 Employee (emp_id, salary) Partial Participation: 2 There can be disconnected entities in second table If so, it can lead to empty cells for salary column in above approach Employee (emp_id, salary_id), Salary (emp_id) One to Many A company can have many employees Minimum tables required: 2 Company (com_id), Employee (emp_id, com_id) Many to Many A student can enroll in many courses & a course can be enrolled by many students Minimum tables required: 3 Student (stu_id), Course (course_id), StudentCourses (stu_id, course_id) Participation Total Each entity in entity set participates in the relationship Each student must enroll in a course Partial Entity in entity set may or may not participate in the relationship A person may or may not have a car Enhanced ER Model Specialization (Subclass) Divide an entity into sub-entities based on characteristics (Top-down approach) 'is a' relationship Example: Laptop is a computer (laptop is a special/sub class of computer) Contraints: Total or Partial Total subclass if every super-class entity is to be associated with some sub-class entity Overlapped or Disjoint Overlapping subclass if an entity from a super-set can be related (can occur) in multiple sub-class sets Generalization (Superclass) Extracting common properties and creating a generalized entity (Bottom-up approach) Example: Laptop is a computer (computer is a general/super class of laptop) Inheritance Feature that allows subclasses to inherit attributes & relationships from superclasses Multiple Inheritance An entity can be a subclass of multiple entity types Teaching Assistant can be a subclass of Employee & Student both Attributes of the subclass are union of attributes of all superclasses Aggregation Abstraction that represents a group of entities as a single entity Example: An employee working on a project may require machinery Aggregate entities Employee & Project Are connected with the relationship 'working on' Entities Employee-Project-Aggregate and Machinery Are connected with the relationship 'requires' Recursive Relationship Employee & Boss (Boss is also employee) User & Friend (Friend is also user) Boss and Friend are called role names Employee - Boss Employee Min cardinality = 0 (CEO can't have boss) Max cardinality = 1 (employee can have only one boss) Boss Min cardinality = 0 (individual contributors don't manage any employee) Max cardinality = n (can manage many employees) Participation: Partial Relationship: Many to one Employee (emp_id, boss_id) Foreign keys: boss_id in Employee User - Friend User Min cardinality = 0 Max cardinality = n Friend Min cardinality = 0 Max cardinality = n Participation: Partial Relationship: Many to many User (user_id), Friendship (user_id, friend_user_id) Store both (user_id, friend_user_id) & (friend_user_id, user_id) To make it simple & scalable Impedance Mismatch When two systems or components that are supposed to work together Have different data models, structures or interfaces It can make communciation difficult or inefficient In databases, it refers to discrepancy between OOP model in application code & relational model in database OOP models represent data as objects with properties & methods Relational model represents data as tables with columns & rows Challenges in mapping objects to tables & vice versa Object heirarchy may need to be flattened into single table Multiple related tables may need to be joined together to represent a single object Data type mismatch between the programming language and the data models The query results can be sets or multisets of tuples Where each tuple is formed of attribute values The result's data structures needs to be binded To the programming language's data structures The tuples are required to be looped over to extract individual values These can lead to performance issues, data inconsistency, development time & cost To overcome the impedance mismatch problem, Object Relational Mapping (ORM) is used It automates the mapping process between objects & tables","title":"Entity Relationship Model"},{"location":"database_system/entity_relationship_model#entity-relationship-model","text":"Representation of entities and their relationships","title":"Entity Relationship Model"},{"location":"database_system/entity_relationship_model#representations","text":"Entity Strong: Rectange Weak: Double Rectangle Entity Set: Vertical Oval Attribute Single-valued: Oval Key: Oval with Underline Multi-valued: Double Oval Derived: Dashed Oval Relationship: Diamond Identifying Relationship: Double Diamond Participation Total: Double Line Partial: Line","title":"Representations"},{"location":"database_system/entity_relationship_model#entity","text":"Also known as Entity Type Strong Entity Entity that has a key attribute and does not depend on other entities Records are identified uniquely using primary key Weak Entity Dependent entity with no key attribute Example: Salary entity won't exist without employee entity Participation: Total Entity Set: Set of individual entities (instances of entity type)","title":"Entity"},{"location":"database_system/entity_relationship_model#attributes","text":"Properties that define the entity type Key Attribute: Uniquely identifies each entity in the entity set Composite Attribute Attribute composed of many other attributes Example: Address consists of street, city, state, country Multi-valued Attribute Example: There can be multiple Email for a user Derived Attribute Example: Age attribute can be derived from date of birth","title":"Attributes"},{"location":"database_system/entity_relationship_model#relationship","text":"Association between entity types Identifying Relationship Relationship between weak entity & its identifying strong entity Relationship Set: Set of relationships of the same type","title":"Relationship"},{"location":"database_system/entity_relationship_model#degree","text":"Number of different entity sets participating in a relationship set Unary One entity is related to another entity of the same type Example: A person is married to another person Binary One entity is related to another entity of a different type Example: A student is enrolled in a course N-ary More than 2 entities are related Example: A doctor prescribes a medicine to a patient","title":"Degree"},{"location":"database_system/entity_relationship_model#cardinality","text":"Number of times an entity participates in a relationship One to One An employee can have only one salary Minimum tables required Total Participation: 1 Employee (emp_id, salary) Partial Participation: 2 There can be disconnected entities in second table If so, it can lead to empty cells for salary column in above approach Employee (emp_id, salary_id), Salary (emp_id) One to Many A company can have many employees Minimum tables required: 2 Company (com_id), Employee (emp_id, com_id) Many to Many A student can enroll in many courses & a course can be enrolled by many students Minimum tables required: 3 Student (stu_id), Course (course_id), StudentCourses (stu_id, course_id)","title":"Cardinality"},{"location":"database_system/entity_relationship_model#participation","text":"Total Each entity in entity set participates in the relationship Each student must enroll in a course Partial Entity in entity set may or may not participate in the relationship A person may or may not have a car","title":"Participation"},{"location":"database_system/entity_relationship_model#enhanced-er-model","text":"Specialization (Subclass) Divide an entity into sub-entities based on characteristics (Top-down approach) 'is a' relationship Example: Laptop is a computer (laptop is a special/sub class of computer) Contraints: Total or Partial Total subclass if every super-class entity is to be associated with some sub-class entity Overlapped or Disjoint Overlapping subclass if an entity from a super-set can be related (can occur) in multiple sub-class sets Generalization (Superclass) Extracting common properties and creating a generalized entity (Bottom-up approach) Example: Laptop is a computer (computer is a general/super class of laptop) Inheritance Feature that allows subclasses to inherit attributes & relationships from superclasses Multiple Inheritance An entity can be a subclass of multiple entity types Teaching Assistant can be a subclass of Employee & Student both Attributes of the subclass are union of attributes of all superclasses Aggregation Abstraction that represents a group of entities as a single entity Example: An employee working on a project may require machinery Aggregate entities Employee & Project Are connected with the relationship 'working on' Entities Employee-Project-Aggregate and Machinery Are connected with the relationship 'requires'","title":"Enhanced ER Model"},{"location":"database_system/entity_relationship_model#recursive-relationship","text":"Employee & Boss (Boss is also employee) User & Friend (Friend is also user) Boss and Friend are called role names","title":"Recursive Relationship"},{"location":"database_system/entity_relationship_model#employee-boss","text":"Employee Min cardinality = 0 (CEO can't have boss) Max cardinality = 1 (employee can have only one boss) Boss Min cardinality = 0 (individual contributors don't manage any employee) Max cardinality = n (can manage many employees) Participation: Partial Relationship: Many to one Employee (emp_id, boss_id) Foreign keys: boss_id in Employee","title":"Employee - Boss"},{"location":"database_system/entity_relationship_model#user-friend","text":"User Min cardinality = 0 Max cardinality = n Friend Min cardinality = 0 Max cardinality = n Participation: Partial Relationship: Many to many User (user_id), Friendship (user_id, friend_user_id) Store both (user_id, friend_user_id) & (friend_user_id, user_id) To make it simple & scalable","title":"User - Friend"},{"location":"database_system/entity_relationship_model#impedance-mismatch","text":"When two systems or components that are supposed to work together Have different data models, structures or interfaces It can make communciation difficult or inefficient In databases, it refers to discrepancy between OOP model in application code & relational model in database OOP models represent data as objects with properties & methods Relational model represents data as tables with columns & rows Challenges in mapping objects to tables & vice versa Object heirarchy may need to be flattened into single table Multiple related tables may need to be joined together to represent a single object Data type mismatch between the programming language and the data models The query results can be sets or multisets of tuples Where each tuple is formed of attribute values The result's data structures needs to be binded To the programming language's data structures The tuples are required to be looped over to extract individual values These can lead to performance issues, data inconsistency, development time & cost To overcome the impedance mismatch problem, Object Relational Mapping (ORM) is used It automates the mapping process between objects & tables","title":"Impedance Mismatch"},{"location":"database_system/relational_model","text":"Relational Model Representing data in form of tables (or relations) connected by key fields After designing the conceptual model of the database using ER diagram It needs to be converted into a relational model So that it can be implemented using the language of RDBMS Relational Schema Structure of a relation The number of attributes in a relation is called its degree Example: Student (id, name, email) has a degree of 3 Relational Instance Set of values present in a relationship The number of these instances is called cardinality Example: Student (id: 1, name: 'Test', email: 'test@email.com') Relational Algebra Set of operations that can be performed on relations Codd's Rules Checks whether DBMS has the quality to become RDBMS It's rare to fulfill all the rules, generally 8-9 rules are followed These 13 rules are popularly known as Codd's 12 rules (index 0 - 12) Rule 0: Foundation Must be able to manage databases entirely through its relational capabilities Rule 1: Information Data stored must be a value of some cell of a table Rule 2: Guaranteed Access Every data element must be accessible By the table name, primary key, and attribute name Rule 3: Systematic Treatment of NULL values NULL value must only correspond to missing, unknown, or not applicable values Rule 4: Active Online Catalog Structure of the database must be stored in an online catalog That can be queried by authorized users Rule 5: Comprehensive Data Sub-language Database should be accessible by a language Supported for definition, manipulation, & transaction management Rule 6: View Updating Rule Different views should be updatable by the system Rule 7: High level insert, update & delete Should support operations like insert, delete, update, etc at each level of relations Rule 8: Physical Data Independence Any modification in physical location of table should not affect application level Rule 9: Logical Data Independence Any modification in conceptual schema of table should not affect application level Example: Merging two tables into one Should not affect the application accessing it (difficult to achieve) Rule 10: Integrity Independence Integrity constraints modified at database level should not affect application level Rule 11: Distribution Independence Distribution of data over various locations should not be visible to end-users Rule 12: Non-subversion Low level access to data should not be able to bypass the integrity rule to change data Relation Keys Keys are used to identify a row in a table uniquely It also helps in setting relationship between various columns & tables Super Key: A set of any number of attributes that can identify a row uniquely Candidate Key: Minimal set of attributes that can identify a row uniquely Primary Key: One key chosen out of candidate keys to identify a row uniquely Composite Key: If a combination of attributes are used as the primary key Alternate Key: Candidate keys except the primary key Foreign Key A reference key that can identify a row uniquely in the related table It should be a primary key in the referenced table Constraints While designing a relational model Conditions are defined that must hold true for the data, these are called constraints These constraints are checked before performing any operation in database Domain Constraints Attribute level constraints, attribute values must match the specified domain Example: age should be > 0 for Student relation Key Integrity (or Entity Integrity) Every relation should have at least one key to uniquely identify a row Primary key cannot have NULL values Referential Integrity When one attribute of a relation can only take values From another attribute of the same or another relation Foreign keys must match primary keys in the referenced table or be NULL Example: branch_code in Branch relation referenced in Student relation Referencing relation: Student (id, name, branch_code) Referenced relation: Branch (branch_code, branch_name) Anomalies Insertion Referencing attribute cannot have a value that is not present in the referenced attribute Deletion Referenced attribute cannot be deleted if its present in a referencing attribute Updation Referenced attribute cannot be updated if its present in a referencing attribute Example: if branch_code is updated from 'CS' to 'CSE' in Branch Then it should be updated in Student table as well Solutions for Deletion/Updation Cascade Delete Cascade: Deletes the referencing rows if the referenced row is deleted Update Cascade: Updates the referencing rows if the referenced row is updated Set NULL in referencing rows Normalization can be used to minimize these anamolies Data Warehouse Modeling Star Schema Data is organized into a central fact table That contains metrics or measures that are of interest In a sales data warehouse Fact table might contain sales revenue, units sold, profit margins Each record in the fact table represents a specific event or transaction Like a sale or order Fact table is surrounded by dimension tables That describe the attributes of the measures These attributes are used to slice and dice the data in fact table This allows users to analyze the data from different perspectives In a sales data warehouse Dimension tables might include product, customer, time & location Each dimension table is joined to fact table through a foreign key relationship A user might want sales revenue by product category or region or time period It improves the data retrieval and is used by many OLAP systems Snowflake Schema Variant of star schema Where dimensions are present in a normalized form in multiple related tables The dimensions are detailed and highly structured having several levels of relationship The child tables might have multiple parent tables These tables are maintained in normalized form to reduce redundancy It makes them easy to maintain Though more joins are required that impact the performance Relational Algebra Union: A U B Intersection: A \u2229 B Difference: A - B Cartesian Product: A X B Selection: \u03c3 condition (relation_name) Displays all attributes, works on rows Projection: \u03c0 (col1, col2) relation_name Works on columns, picks speciic columns Divide: A \u00f7 B Rename: \u03c1 (old_relation, new_relation) Joins Outer Joins Left: A \u27d5 B Right: A \u27d6 B Full: A \u27d7 B Inner Joins Conditional: A \u22c8 \u03b8 B , theta denotes conditions Equi: A \u22c8 [A.column1 = B.column2] (B) Special case of conditional join where only equality condition holds Natural: A \u22c8 B Special case of equijoin in which equality condition hold on all attributes Which have same name in relations If there is a common attribute with the same name & type Then that row will be joined Returns the similar attributes only once As their value will be the same in the resulting relation Nested vs Join Queries Nested queries Only relevant info from each table can be extracted Can lead to bugs or poor performance, optimization depends on the developer Every constant subquery is evaluated as many times encountered Large subqueries may take time to execute Join queries Whole tables are fetched and a large table is created from which filtering happens Joins are universally understood, so no optimization issues can arise Foreign & primary keys are usually indexed So performs better than large subqueries","title":"Relational Model"},{"location":"database_system/relational_model#relational-model","text":"Representing data in form of tables (or relations) connected by key fields After designing the conceptual model of the database using ER diagram It needs to be converted into a relational model So that it can be implemented using the language of RDBMS Relational Schema Structure of a relation The number of attributes in a relation is called its degree Example: Student (id, name, email) has a degree of 3 Relational Instance Set of values present in a relationship The number of these instances is called cardinality Example: Student (id: 1, name: 'Test', email: 'test@email.com') Relational Algebra Set of operations that can be performed on relations","title":"Relational Model"},{"location":"database_system/relational_model#codds-rules","text":"Checks whether DBMS has the quality to become RDBMS It's rare to fulfill all the rules, generally 8-9 rules are followed These 13 rules are popularly known as Codd's 12 rules (index 0 - 12) Rule 0: Foundation Must be able to manage databases entirely through its relational capabilities Rule 1: Information Data stored must be a value of some cell of a table Rule 2: Guaranteed Access Every data element must be accessible By the table name, primary key, and attribute name Rule 3: Systematic Treatment of NULL values NULL value must only correspond to missing, unknown, or not applicable values Rule 4: Active Online Catalog Structure of the database must be stored in an online catalog That can be queried by authorized users Rule 5: Comprehensive Data Sub-language Database should be accessible by a language Supported for definition, manipulation, & transaction management Rule 6: View Updating Rule Different views should be updatable by the system Rule 7: High level insert, update & delete Should support operations like insert, delete, update, etc at each level of relations Rule 8: Physical Data Independence Any modification in physical location of table should not affect application level Rule 9: Logical Data Independence Any modification in conceptual schema of table should not affect application level Example: Merging two tables into one Should not affect the application accessing it (difficult to achieve) Rule 10: Integrity Independence Integrity constraints modified at database level should not affect application level Rule 11: Distribution Independence Distribution of data over various locations should not be visible to end-users Rule 12: Non-subversion Low level access to data should not be able to bypass the integrity rule to change data","title":"Codd's Rules"},{"location":"database_system/relational_model#relation-keys","text":"Keys are used to identify a row in a table uniquely It also helps in setting relationship between various columns & tables Super Key: A set of any number of attributes that can identify a row uniquely Candidate Key: Minimal set of attributes that can identify a row uniquely Primary Key: One key chosen out of candidate keys to identify a row uniquely Composite Key: If a combination of attributes are used as the primary key Alternate Key: Candidate keys except the primary key Foreign Key A reference key that can identify a row uniquely in the related table It should be a primary key in the referenced table","title":"Relation Keys"},{"location":"database_system/relational_model#constraints","text":"While designing a relational model Conditions are defined that must hold true for the data, these are called constraints These constraints are checked before performing any operation in database Domain Constraints Attribute level constraints, attribute values must match the specified domain Example: age should be > 0 for Student relation Key Integrity (or Entity Integrity) Every relation should have at least one key to uniquely identify a row Primary key cannot have NULL values Referential Integrity When one attribute of a relation can only take values From another attribute of the same or another relation Foreign keys must match primary keys in the referenced table or be NULL Example: branch_code in Branch relation referenced in Student relation Referencing relation: Student (id, name, branch_code) Referenced relation: Branch (branch_code, branch_name)","title":"Constraints"},{"location":"database_system/relational_model#anomalies","text":"Insertion Referencing attribute cannot have a value that is not present in the referenced attribute Deletion Referenced attribute cannot be deleted if its present in a referencing attribute Updation Referenced attribute cannot be updated if its present in a referencing attribute Example: if branch_code is updated from 'CS' to 'CSE' in Branch Then it should be updated in Student table as well Solutions for Deletion/Updation Cascade Delete Cascade: Deletes the referencing rows if the referenced row is deleted Update Cascade: Updates the referencing rows if the referenced row is updated Set NULL in referencing rows Normalization can be used to minimize these anamolies","title":"Anomalies"},{"location":"database_system/relational_model#data-warehouse-modeling","text":"","title":"Data Warehouse Modeling"},{"location":"database_system/relational_model#star-schema","text":"Data is organized into a central fact table That contains metrics or measures that are of interest In a sales data warehouse Fact table might contain sales revenue, units sold, profit margins Each record in the fact table represents a specific event or transaction Like a sale or order Fact table is surrounded by dimension tables That describe the attributes of the measures These attributes are used to slice and dice the data in fact table This allows users to analyze the data from different perspectives In a sales data warehouse Dimension tables might include product, customer, time & location Each dimension table is joined to fact table through a foreign key relationship A user might want sales revenue by product category or region or time period It improves the data retrieval and is used by many OLAP systems","title":"Star Schema"},{"location":"database_system/relational_model#snowflake-schema","text":"Variant of star schema Where dimensions are present in a normalized form in multiple related tables The dimensions are detailed and highly structured having several levels of relationship The child tables might have multiple parent tables These tables are maintained in normalized form to reduce redundancy It makes them easy to maintain Though more joins are required that impact the performance","title":"Snowflake Schema"},{"location":"database_system/relational_model#relational-algebra","text":"Union: A U B Intersection: A \u2229 B Difference: A - B Cartesian Product: A X B Selection: \u03c3 condition (relation_name) Displays all attributes, works on rows Projection: \u03c0 (col1, col2) relation_name Works on columns, picks speciic columns Divide: A \u00f7 B Rename: \u03c1 (old_relation, new_relation)","title":"Relational Algebra"},{"location":"database_system/relational_model#joins","text":"Outer Joins Left: A \u27d5 B Right: A \u27d6 B Full: A \u27d7 B Inner Joins Conditional: A \u22c8 \u03b8 B , theta denotes conditions Equi: A \u22c8 [A.column1 = B.column2] (B) Special case of conditional join where only equality condition holds Natural: A \u22c8 B Special case of equijoin in which equality condition hold on all attributes Which have same name in relations If there is a common attribute with the same name & type Then that row will be joined Returns the similar attributes only once As their value will be the same in the resulting relation","title":"Joins"},{"location":"database_system/relational_model#nested-vs-join-queries","text":"Nested queries Only relevant info from each table can be extracted Can lead to bugs or poor performance, optimization depends on the developer Every constant subquery is evaluated as many times encountered Large subqueries may take time to execute Join queries Whole tables are fetched and a large table is created from which filtering happens Joins are universally understood, so no optimization issues can arise Foreign & primary keys are usually indexed So performs better than large subqueries","title":"Nested vs Join Queries"},{"location":"database_system/functional_dependency","text":"Functional Dependency A functional dependency A -> B in a relation holds if Two tuples having the same value of attribute A also have the same value for attribute B Examples student_id -> student_name , state -> country hold student_name -> state doesn't hold Advantages Reduces data redundancy Enhances data integrity and guarantees that data is consistent Simplifies adding, editing, & removing data Disadvantages Overly restrictive functional dependencies can slow query performance They don't take the semantic meaning of data into account May not reflect the true relationships between data elements Functional dependency set of a relation is the set of all FDs in that relation Trivial FD A FD X -> Y is trivial if Y is a subset or X That is, if the set of dependent attributes are included in the source attributes Example: {student_id, student_name} -> {student_id} Else it is called non-trivial FD Armstrong Axioms Axioms Reflexivity: If Y is a subset of X, then X -> Y Augmentation: If X -> Y, then XZ -> YZ Transitivity: If X -> Y and Y -> Z, then X -> Z Secondary Rules: Derived from the above axioms Union: If X -> Y and X -> Z, then X -> YZ Composition: If X -> Y and A -> B, then XA -> YB Decomposition: If X -> YZ, then X -> Y and X -> Z Pseudo Transitivity: If X -> Y and YA -> Z, then XA -> Z Self Determination: X -> X Extensivity If XA -> X and X -> Y, then XA -> Y If XY -> XYZ and XYZ -> YZ, then XY -> YZ Equivalence of FD Let F and G be two FD sets for a relation If F can be derived from G, then F is a subset of G If G can be derived from F, then G is a subset of F If both of the above are true, then F = G Attribute Closure Attribute closure of an attribute set Is the set of attributes that can be functionally determined from it If the set of attributes is A, then its attribute closure is represented as A+ Example: For a Student table (student_id)+ = {student_id, name, phone, state, country} If student_id is known, then the mentioned attributes can be determined from it (student_state)+ = {student_state, student_country} Advantages Identifies all attributes that can be derived from a given set of attributes And ensures data consistency Identifies relationships between attributes and tables Helpful to optimize query performance Disadvantages As the number of attributes & tables increase, it can become complex to manage They don't take the semantic meaning of data into account Finding Keys An attribute set will be a super key if The attribute closure of the set contains all attributes of relation This attribute set will also be a candidate key if No subset of the set can functionally determine all attributes of the relation Prime Attributes: Attributes that are parts of any candidate key of a relation Other attributes are called non-prime attributes Canonical Cover Managing a large set of functional dependencies can result in Unnecessary computational overhead This is where the canonical cover becomes useful A canonical cover of a set of FDs Is a simplified version of FDs that retains the same closure as the original set Ensuring no redundancy Extranious Attribute of FD If it can be removed from LHS without changing the closure of the set of FDs Advantages Essential for optimizing database management systems Simplifies and minimizes the dependencies while preserving their properties Reducing computational overhead, and improving efficiency By reducing, eliminating, and minimizing dependencies, canonical cover creates A minimal, unique, and accurate representation of the original set It helps to reduce data redundancy, improves query performance And makes database maintenance easier. Application Whenever a user updates the database The system must check if any of the FDs are getting violated If there are violations in the new database state, then the system must roll back Working with a huge set of FD can cause unnecessarily added computational time Useful to provide simplified set of FD to determine keys Finding Canonical Cover Reduction Remove redundant dependencies Combine dependencies that have common attributes on LHS Elimination: Eliminate extraneous attributes from LHS Minimization: Remove dependencies that are implied by other dependencies Example: A -> BC, B -> C, AB -> C Reduction: A -> B (A -> BC && B -> C), A -> C (AB -> C && B -> C) Elimination: A -> C (A -> B && B -> C) Minimization: Remove AB -> C since A -> C F Canonically Covers G Consider two sets of FD F = { A -> B, AB -> C, D -> AC, D -> E } G = { A -> BC, D -> AB } Create singleton RHS F = { A -> B, AB -> C, D -> A, D -> C, D -> E } G = { A -> B, A -> C, D -> A, D -> B} Remove extraneous attributes F = { A -> B, A -> C, D -> A, D -> C, D -> E } Remove B from AB -> C since A -> B && AB -> C G = { A -> B, A -> C, D -> A, D -> B} No changes since all LHS have single attributes Remove redundant FDs F = { A -> B, A -> C, D -> A, D -> E } D -> C can be derived from D -> A && A -> C G = { A -> B, A -> C, D -> A } D -> B can be derived from D -> A && A -> B All FDs of G are covered in F, so F covers G","title":"Functional Dependency"},{"location":"database_system/functional_dependency#functional-dependency","text":"A functional dependency A -> B in a relation holds if Two tuples having the same value of attribute A also have the same value for attribute B Examples student_id -> student_name , state -> country hold student_name -> state doesn't hold Advantages Reduces data redundancy Enhances data integrity and guarantees that data is consistent Simplifies adding, editing, & removing data Disadvantages Overly restrictive functional dependencies can slow query performance They don't take the semantic meaning of data into account May not reflect the true relationships between data elements Functional dependency set of a relation is the set of all FDs in that relation","title":"Functional Dependency"},{"location":"database_system/functional_dependency#trivial-fd","text":"A FD X -> Y is trivial if Y is a subset or X That is, if the set of dependent attributes are included in the source attributes Example: {student_id, student_name} -> {student_id} Else it is called non-trivial FD","title":"Trivial FD"},{"location":"database_system/functional_dependency#armstrong-axioms","text":"Axioms Reflexivity: If Y is a subset of X, then X -> Y Augmentation: If X -> Y, then XZ -> YZ Transitivity: If X -> Y and Y -> Z, then X -> Z Secondary Rules: Derived from the above axioms Union: If X -> Y and X -> Z, then X -> YZ Composition: If X -> Y and A -> B, then XA -> YB Decomposition: If X -> YZ, then X -> Y and X -> Z Pseudo Transitivity: If X -> Y and YA -> Z, then XA -> Z Self Determination: X -> X Extensivity If XA -> X and X -> Y, then XA -> Y If XY -> XYZ and XYZ -> YZ, then XY -> YZ","title":"Armstrong Axioms"},{"location":"database_system/functional_dependency#equivalence-of-fd","text":"Let F and G be two FD sets for a relation If F can be derived from G, then F is a subset of G If G can be derived from F, then G is a subset of F If both of the above are true, then F = G","title":"Equivalence of FD"},{"location":"database_system/functional_dependency#attribute-closure","text":"Attribute closure of an attribute set Is the set of attributes that can be functionally determined from it If the set of attributes is A, then its attribute closure is represented as A+ Example: For a Student table (student_id)+ = {student_id, name, phone, state, country} If student_id is known, then the mentioned attributes can be determined from it (student_state)+ = {student_state, student_country} Advantages Identifies all attributes that can be derived from a given set of attributes And ensures data consistency Identifies relationships between attributes and tables Helpful to optimize query performance Disadvantages As the number of attributes & tables increase, it can become complex to manage They don't take the semantic meaning of data into account","title":"Attribute Closure"},{"location":"database_system/functional_dependency#finding-keys","text":"An attribute set will be a super key if The attribute closure of the set contains all attributes of relation This attribute set will also be a candidate key if No subset of the set can functionally determine all attributes of the relation Prime Attributes: Attributes that are parts of any candidate key of a relation Other attributes are called non-prime attributes","title":"Finding Keys"},{"location":"database_system/functional_dependency#canonical-cover","text":"Managing a large set of functional dependencies can result in Unnecessary computational overhead This is where the canonical cover becomes useful A canonical cover of a set of FDs Is a simplified version of FDs that retains the same closure as the original set Ensuring no redundancy Extranious Attribute of FD If it can be removed from LHS without changing the closure of the set of FDs Advantages Essential for optimizing database management systems Simplifies and minimizes the dependencies while preserving their properties Reducing computational overhead, and improving efficiency By reducing, eliminating, and minimizing dependencies, canonical cover creates A minimal, unique, and accurate representation of the original set It helps to reduce data redundancy, improves query performance And makes database maintenance easier. Application Whenever a user updates the database The system must check if any of the FDs are getting violated If there are violations in the new database state, then the system must roll back Working with a huge set of FD can cause unnecessarily added computational time Useful to provide simplified set of FD to determine keys","title":"Canonical Cover"},{"location":"database_system/functional_dependency#finding-canonical-cover","text":"Reduction Remove redundant dependencies Combine dependencies that have common attributes on LHS Elimination: Eliminate extraneous attributes from LHS Minimization: Remove dependencies that are implied by other dependencies Example: A -> BC, B -> C, AB -> C Reduction: A -> B (A -> BC && B -> C), A -> C (AB -> C && B -> C) Elimination: A -> C (A -> B && B -> C) Minimization: Remove AB -> C since A -> C","title":"Finding Canonical Cover"},{"location":"database_system/functional_dependency#f-canonically-covers-g","text":"Consider two sets of FD F = { A -> B, AB -> C, D -> AC, D -> E } G = { A -> BC, D -> AB } Create singleton RHS F = { A -> B, AB -> C, D -> A, D -> C, D -> E } G = { A -> B, A -> C, D -> A, D -> B} Remove extraneous attributes F = { A -> B, A -> C, D -> A, D -> C, D -> E } Remove B from AB -> C since A -> B && AB -> C G = { A -> B, A -> C, D -> A, D -> B} No changes since all LHS have single attributes Remove redundant FDs F = { A -> B, A -> C, D -> A, D -> E } D -> C can be derived from D -> A && A -> C G = { A -> B, A -> C, D -> A } D -> B can be derived from D -> A && A -> B All FDs of G are covered in F, so F covers G","title":"F Canonically Covers G"},{"location":"database_system/normalization","text":"Normalization Process of organizing attributes to reduce data redundancy Data redundancy Advantages Data is readily accessible Enhances query performance since less joins are required Disadvantages Increased storage size Inconsistency problems or anamolies during insert, update, delete operations Data consistency: Keeps data consistent at all places Data integrity: Ensures data accuracy and protects against data loss & leaks Simplifies data management by breaking down complex tables Normal Forms The default requirement for a normal form is to satify all the previous normal forms First (1NF) No composite or multi-valued attributes in the relation Helps eliminate duplicate data and simplifies queries Example: Student (id: 1, phone: [1234, 5678]) Student is not in 1NF because phone has 2 values Break the row into 2 rows to make it 1NF Student (id: 1, phone: 1234) Student (id: 1, phone: 5678) Second (2NF) Relation is in 2NF if any one of the following holds true Candidate key is single valued Candidate key is multi valued, but there is no partial dependency in the relation Any non-prime attribute should not be dependent on any proper subset of any candidate key Reduces redundant data Student (id, course_id, course_fee) If 100 students are taking the same course, no need to store its fee 100 times Consider X -> Y & A -> Y Let's say X is a composite candidate key {A, B} It is a partial dependency because Y is non-prime and depends only on A And A is a proper subset of the candidate key {A, B} If A -> Y was not present, it will be in 2NF If the candidate key X was single valued (say B -> Y) Then also it will be in 2NF Proper subset A proper subset is a set that contains some but not all elements of another set E.g. {1} is proper subset of {1, 2}, but {1, 2} is subset (not proper) of {1, 2} Example: StudentCourse (id, course_id, course_fee) It is not in 2NF because Candidate key here is {id, course_id} But course_id -> course_fee course_id is a proper subset of a candidate key course_fee is a non-prime attribute It cannot identify a row uniquely even if combined with other attributes It is a partial dependency and so this relation is not in 2NF Break the table into 2 tables to make it 2NF StudentCourse (id, course_id) Course (id, course_fee) Third (3NF) No transitive dependency for non-prime attributes on any candidate key If A -> B and B -> C, then A -> C is called transitive dependency Ensures that FD is preserved and lossless Alternatively, we can say that for a non-trivial FD X -> Y Atleast one of the following conditions should hold true X is a super key Y is a prime attribute 3NF is considered adequate for normal RDBMS Because most of the 3NF tables are free of anomalies Example: Student (id, name, state, country) It is not in 3NF because id -> state and state -> country Country is a non-prime attribute since the candidate key is {id} But it depends transitively on id (which is candidate key) Alternatively, country is non-prime and state is not super key But state -> country Break the table into 2 tables to make it 3NF Student (id, name, state) StateCountry (state, country) Example 2: StudentCourse (id, course, instructor, instructor_email) {id, course} -> instructor (a course can have multiple instructors) instructor -> course (an instructor teaches only one course) instructor -> instructor_email {id, instructor} -> course (course can be determined through id & instructor) Candidate keys {id, course}, since a student can have multiple courses {id, instructor}, since an instructor teaches only one course Hence, {id, course} -> instructor -> instructor_email Which is transitive dependency and hence not in 3NF Alternatively, instructor_email is non-prime and instructor is not super key Solution Student (id, course, instructor) Instructor (instructor, instructor_email) BCNF In a FD X -> Y, X must be a super key Advanced form for 3NF This is the last practiced form Forms beyond like 4NF & 5NF are used only for theoritical purposes Example: Student (id, course, branch) Student (id: 1, course: 'DSA', branch: 'CSE') Student (id: 1, course: 'OS', branch: 'CSE') Student (id: 1, course: 'Networks', branch: 'CSE') For id -> branch, id is not a super key Since there can be multiple values with same id For course -> branch, course is not a super key Since multiple courses can have same branch Break the table into 3 tables to make it BCNF Student (id, branch) StudentCourse (student_id, course_id) Course (id, branch) Example 2: StudentCourse (id, course, instructor) {id, course} -> instructor (a course can have multiple instructors) instructor -> course (an instructor teaches only one course) {id, instructor} -> course (course can be determined through id & instructor) Candidate keys {id, course}, since a student can have multiple courses {id, instructor}, since an instructor teaches only one course Here, in instructor -> course, instructor is not a super key Hence it is not in BCNF Solution StudentInstructor (id, instructor) InstructorCourse (instructor, course) Fourth (4NF) No non-trivial multi-valued dependency except candidate key Multi-valued dependency (MVD) If two attributes are independent of one another but both depend on a third attribute Example: Student (id, name, course_name) MVD: name & course_name are independent but id -> name, id -> course_name Solution Student (id, name) StudentCourse (student_id, course_name) Fifth (5NF) Also called projection-join normal form (PJNF) No join dependency except candidate keys A relation decomposed into two relations must be lossless Lossless Decompositionwhich If relation R (A, B, C) is decomposed into R1 (A, B) & R2 (B, C) It is lossless if the join of R1 & R2 over B should be equal to R It is lossy if the number of joined tuples are more or less than R It is dependency preserving if all the FD are preserved in R1 & R2 Example: Course (name, faculty, semester) Course (name: 'DSA', faculty: 'F1', semester: 1) Course (name: 'DBMS', faculty: 'F1', semester: 2) R1 Course (name: 'DSA', faculty: 'F1') Course (name: 'DBMS', faculty: 'F1') R2 Course (faculty: 'F1', semester: 1) Course (faculty: 'F1', semester: 2) Join (R1, R2) Course (name: 'DSA', faculty: 'F1', semester: 1) Course (name: 'DSA', faculty: 'F1', semester: 2) Course (name: 'DBMS', faculty: 'F1', semester: 1) Course (name: 'DBMS', faculty: 'F1', semester: 2) The join is introducing wrong data (loss of data) A row requires all the 3 attributes to be known (name, faculty, semester) Hence there is a join dependency and it is not in 5NF Solution R1 (name, faculty) R2 (name, semester) R3 (faculty, semester) Finding Normal Forms Find all the candidate keys (C) using attribute closure Divide all attributes as prime and non-prime Example 1 R (A, B, C, D, E) with FD = { A -> D, B -> A, BC -> D, AC -> BE } Candidate keys = { AC, BC } AC is a candidate key since (AC)+ = { A, C, D, B, E } BC is a candidate key since B -> A Prime attributes = { A, B, C } 1NF: Yes, no composite attributes 2NF: No, D is dependent on A (A -> D) Where A is proper subset of candidate key AC Example 2 R (A, B, C, D, E) with FD = { BC -> D, AC -> BE, B -> E } Candidate keys = { AC } AC is a candidate key since (AC)+ = { A, C, B, E, D } Prime attributes = { A, C } 1NF: Yes, no composite attributes 2NF: Yes, LHS (BC, AC, B) doesn't have any proper subset of candidate keys 3NF: No BC -> D: BC is not a super key, nor D is prime attribute B -> E: B is not a super key, nor E is prime attribute Example 3 R (A, B, C, D, E) with FD = { B -> A, A -> C, BC -> D, AC -> BE} Candidate keys = { A, B } B is a candidate key since (B)+ = { B, A, C, D, E } A is a candidate key since (A)+ = { A, C, B, E, D } Prime attributes = { A, B } 1NF: Yes, no composite attributes 2NF: Yes, LHS (B, A, BC, AC) doesn't have any proper subset of candidate keys 3NF: Yes, All LHS have super key, so no need to check prime attribute in RHS BCNF: Yes, All LHS have super key Denormalization Adding redundant data to tables to optimize performance and avoid costly joins Does not mean reversing normalization but adding redundancy after normalization This can make inserts & updates more expensive, but increases accessibility","title":"Normalization"},{"location":"database_system/normalization#normalization","text":"Process of organizing attributes to reduce data redundancy Data redundancy Advantages Data is readily accessible Enhances query performance since less joins are required Disadvantages Increased storage size Inconsistency problems or anamolies during insert, update, delete operations Data consistency: Keeps data consistent at all places Data integrity: Ensures data accuracy and protects against data loss & leaks Simplifies data management by breaking down complex tables","title":"Normalization"},{"location":"database_system/normalization#normal-forms","text":"The default requirement for a normal form is to satify all the previous normal forms","title":"Normal Forms"},{"location":"database_system/normalization#first-1nf","text":"No composite or multi-valued attributes in the relation Helps eliminate duplicate data and simplifies queries Example: Student (id: 1, phone: [1234, 5678]) Student is not in 1NF because phone has 2 values Break the row into 2 rows to make it 1NF Student (id: 1, phone: 1234) Student (id: 1, phone: 5678)","title":"First (1NF)"},{"location":"database_system/normalization#second-2nf","text":"Relation is in 2NF if any one of the following holds true Candidate key is single valued Candidate key is multi valued, but there is no partial dependency in the relation Any non-prime attribute should not be dependent on any proper subset of any candidate key Reduces redundant data Student (id, course_id, course_fee) If 100 students are taking the same course, no need to store its fee 100 times Consider X -> Y & A -> Y Let's say X is a composite candidate key {A, B} It is a partial dependency because Y is non-prime and depends only on A And A is a proper subset of the candidate key {A, B} If A -> Y was not present, it will be in 2NF If the candidate key X was single valued (say B -> Y) Then also it will be in 2NF Proper subset A proper subset is a set that contains some but not all elements of another set E.g. {1} is proper subset of {1, 2}, but {1, 2} is subset (not proper) of {1, 2} Example: StudentCourse (id, course_id, course_fee) It is not in 2NF because Candidate key here is {id, course_id} But course_id -> course_fee course_id is a proper subset of a candidate key course_fee is a non-prime attribute It cannot identify a row uniquely even if combined with other attributes It is a partial dependency and so this relation is not in 2NF Break the table into 2 tables to make it 2NF StudentCourse (id, course_id) Course (id, course_fee)","title":"Second (2NF)"},{"location":"database_system/normalization#third-3nf","text":"No transitive dependency for non-prime attributes on any candidate key If A -> B and B -> C, then A -> C is called transitive dependency Ensures that FD is preserved and lossless Alternatively, we can say that for a non-trivial FD X -> Y Atleast one of the following conditions should hold true X is a super key Y is a prime attribute 3NF is considered adequate for normal RDBMS Because most of the 3NF tables are free of anomalies Example: Student (id, name, state, country) It is not in 3NF because id -> state and state -> country Country is a non-prime attribute since the candidate key is {id} But it depends transitively on id (which is candidate key) Alternatively, country is non-prime and state is not super key But state -> country Break the table into 2 tables to make it 3NF Student (id, name, state) StateCountry (state, country) Example 2: StudentCourse (id, course, instructor, instructor_email) {id, course} -> instructor (a course can have multiple instructors) instructor -> course (an instructor teaches only one course) instructor -> instructor_email {id, instructor} -> course (course can be determined through id & instructor) Candidate keys {id, course}, since a student can have multiple courses {id, instructor}, since an instructor teaches only one course Hence, {id, course} -> instructor -> instructor_email Which is transitive dependency and hence not in 3NF Alternatively, instructor_email is non-prime and instructor is not super key Solution Student (id, course, instructor) Instructor (instructor, instructor_email)","title":"Third (3NF)"},{"location":"database_system/normalization#bcnf","text":"In a FD X -> Y, X must be a super key Advanced form for 3NF This is the last practiced form Forms beyond like 4NF & 5NF are used only for theoritical purposes Example: Student (id, course, branch) Student (id: 1, course: 'DSA', branch: 'CSE') Student (id: 1, course: 'OS', branch: 'CSE') Student (id: 1, course: 'Networks', branch: 'CSE') For id -> branch, id is not a super key Since there can be multiple values with same id For course -> branch, course is not a super key Since multiple courses can have same branch Break the table into 3 tables to make it BCNF Student (id, branch) StudentCourse (student_id, course_id) Course (id, branch) Example 2: StudentCourse (id, course, instructor) {id, course} -> instructor (a course can have multiple instructors) instructor -> course (an instructor teaches only one course) {id, instructor} -> course (course can be determined through id & instructor) Candidate keys {id, course}, since a student can have multiple courses {id, instructor}, since an instructor teaches only one course Here, in instructor -> course, instructor is not a super key Hence it is not in BCNF Solution StudentInstructor (id, instructor) InstructorCourse (instructor, course)","title":"BCNF"},{"location":"database_system/normalization#fourth-4nf","text":"No non-trivial multi-valued dependency except candidate key Multi-valued dependency (MVD) If two attributes are independent of one another but both depend on a third attribute Example: Student (id, name, course_name) MVD: name & course_name are independent but id -> name, id -> course_name Solution Student (id, name) StudentCourse (student_id, course_name)","title":"Fourth (4NF)"},{"location":"database_system/normalization#fifth-5nf","text":"Also called projection-join normal form (PJNF) No join dependency except candidate keys A relation decomposed into two relations must be lossless Lossless Decompositionwhich If relation R (A, B, C) is decomposed into R1 (A, B) & R2 (B, C) It is lossless if the join of R1 & R2 over B should be equal to R It is lossy if the number of joined tuples are more or less than R It is dependency preserving if all the FD are preserved in R1 & R2 Example: Course (name, faculty, semester) Course (name: 'DSA', faculty: 'F1', semester: 1) Course (name: 'DBMS', faculty: 'F1', semester: 2) R1 Course (name: 'DSA', faculty: 'F1') Course (name: 'DBMS', faculty: 'F1') R2 Course (faculty: 'F1', semester: 1) Course (faculty: 'F1', semester: 2) Join (R1, R2) Course (name: 'DSA', faculty: 'F1', semester: 1) Course (name: 'DSA', faculty: 'F1', semester: 2) Course (name: 'DBMS', faculty: 'F1', semester: 1) Course (name: 'DBMS', faculty: 'F1', semester: 2) The join is introducing wrong data (loss of data) A row requires all the 3 attributes to be known (name, faculty, semester) Hence there is a join dependency and it is not in 5NF Solution R1 (name, faculty) R2 (name, semester) R3 (faculty, semester)","title":"Fifth (5NF)"},{"location":"database_system/normalization#finding-normal-forms","text":"Find all the candidate keys (C) using attribute closure Divide all attributes as prime and non-prime","title":"Finding Normal Forms"},{"location":"database_system/normalization#example-1","text":"R (A, B, C, D, E) with FD = { A -> D, B -> A, BC -> D, AC -> BE } Candidate keys = { AC, BC } AC is a candidate key since (AC)+ = { A, C, D, B, E } BC is a candidate key since B -> A Prime attributes = { A, B, C } 1NF: Yes, no composite attributes 2NF: No, D is dependent on A (A -> D) Where A is proper subset of candidate key AC","title":"Example 1"},{"location":"database_system/normalization#example-2","text":"R (A, B, C, D, E) with FD = { BC -> D, AC -> BE, B -> E } Candidate keys = { AC } AC is a candidate key since (AC)+ = { A, C, B, E, D } Prime attributes = { A, C } 1NF: Yes, no composite attributes 2NF: Yes, LHS (BC, AC, B) doesn't have any proper subset of candidate keys 3NF: No BC -> D: BC is not a super key, nor D is prime attribute B -> E: B is not a super key, nor E is prime attribute","title":"Example 2"},{"location":"database_system/normalization#example-3","text":"R (A, B, C, D, E) with FD = { B -> A, A -> C, BC -> D, AC -> BE} Candidate keys = { A, B } B is a candidate key since (B)+ = { B, A, C, D, E } A is a candidate key since (A)+ = { A, C, B, E, D } Prime attributes = { A, B } 1NF: Yes, no composite attributes 2NF: Yes, LHS (B, A, BC, AC) doesn't have any proper subset of candidate keys 3NF: Yes, All LHS have super key, so no need to check prime attribute in RHS BCNF: Yes, All LHS have super key","title":"Example 3"},{"location":"database_system/normalization#denormalization","text":"Adding redundant data to tables to optimize performance and avoid costly joins Does not mean reversing normalization but adding redundancy after normalization This can make inserts & updates more expensive, but increases accessibility","title":"Denormalization"},{"location":"database_system/transactions_and_schedules","text":"Transaction and Schedules Transaction Transaction Collection of operations that performs a single logical function in database Operations: Read, Write, Commit, Rollback, Abort Transaction properties Atomicity Either all operations should execute or none No partial transactions Consistency Data should be consistent everywhere Debit, credit, sender, receiver, total, remaining, before, after Any transaction should take the database from one consistent state to another Maintaining the rules and constraints defined for the data Isolation Operation permission should be granted to one transaction only No two writes or one read & write should happen simultaneously Ensures that multiple transactions can occur concurrently and independently Without interference and without leading to inconsistency of database state Durable Once committed, changes should be permanent even if a system failure occurs Account updates shouldn't be lost Multiple copies of the database should be stored at different locations Schedule Series of operations from one or more transactions Types Serial Concurrent Serializable Conflict Serializable View Serializable Non-Serializable Recoverable Cascading Cascadeless Strict Non-Recoverable Serial Schedule When one transaction executes completely before starting another transaction It is always consistent Has low throughput and less resource utilization Concurrent Schedule When operations of a transaction are interleaved With operations of other transactions of a schedule Can lead to inconsistency Serializable Schedules Used to verify whether the scheduling will lead to any inconsistency These are non-serial transactions that produce an equal outcome when executed serially Conflict Serializable If the schedule can be transformed into serial schedule By swapping non-conflicting operations Conflicting Operations They belong to separate transactions Both operate on the same data item At least one of them is write operation Examples Example 1: S: R1(A), W1(A), R2(A), W2(A), R1(B), W1(B), R2(B), W2(B) Swapping non-conflicting operations S1: R1(A), W1(A), R1(B), W1(B), R2(A), W2(A), R2(B), W2(B) This can be represented as T1 -> T2 It can also be rearranged as T2 -> T1 Example 2: S: R2(A), W2(A), R1(A), W1(A), R1(B), W1(B), R2(B), W2(B) A needs to be written by T2 first & then needs to be read by T1 B needs to be written by T1 first & then needs to be read by T2 Hence, it cannot be rearranged as T1 -> T2 or T2 -> T1 So it is not conflict serializable Conflict Equivalent Two schedules are conflict equivalent If one can be transformed to another by swapping non-conflicting operations In example 1, S & S1 are conflict equivalent View Serializable A schedule is view serializable if it is view equivalent to a serial schedule Serial Schedule Transactions are executed one after another without interleaving View Equivalent If two schedules produce the same final state of the database And ensure the same read/write behavior for all transactions There are no overlapping transactions Schedules that are conflict serializable are always view serializale Conditions in both the schedules Read of initial value and write of final value must be same for a data item W -> R conflict must be the same View Equivalence Two schedules are view equivalent If they produce the same set of results when executed against the same state Order of any two conflicting operations in S1 should be same in S2 Conditions Initial Read If T1 reads the data item A in S1 Then T1 should also read A in S2 Updated Read If T1 reads A written by T2 in S1 Then T1 should also read A written by T2 in S2 Final Write If T1 performs the final write on A in S1 Then T1 should also perform the final write on A in S2 Recoverable Schedules Transactions commit only after all the transactions whose changes were read are committed It allows the system to return the database to a consistent state Example: T1 reads A, modifies and writes A T2 reads A, modifies and writes A T1 is committed T2 is committed (Committed after T1, A read by T2 was modified by T1) Cascading Schedule If a transaction fails, all other dependent transactions rolled back or aborted Cascadeless Schedule Transactions read values only after All the transactions whose changes are to be read are committed Avoids a series of transaction rollbacks due to abort of a single transaction Strict Schedule A transaction can read or write updated value of another transaction Only after it is commited or aborted Non Recoverable Schedules If a transaction T2 reads and commits changes made by another transaction T1 But later if that transaction T1 is aborted, the value read by T2 will be wrong Since T2 already committed, the schedule is non-recoverable","title":"Transactions And Schedules"},{"location":"database_system/transactions_and_schedules#transaction-and-schedules","text":"","title":"Transaction and Schedules"},{"location":"database_system/transactions_and_schedules#transaction","text":"Transaction Collection of operations that performs a single logical function in database Operations: Read, Write, Commit, Rollback, Abort","title":"Transaction"},{"location":"database_system/transactions_and_schedules#transaction-properties","text":"Atomicity Either all operations should execute or none No partial transactions Consistency Data should be consistent everywhere Debit, credit, sender, receiver, total, remaining, before, after Any transaction should take the database from one consistent state to another Maintaining the rules and constraints defined for the data Isolation Operation permission should be granted to one transaction only No two writes or one read & write should happen simultaneously Ensures that multiple transactions can occur concurrently and independently Without interference and without leading to inconsistency of database state Durable Once committed, changes should be permanent even if a system failure occurs Account updates shouldn't be lost Multiple copies of the database should be stored at different locations","title":"Transaction properties"},{"location":"database_system/transactions_and_schedules#schedule","text":"Series of operations from one or more transactions Types Serial Concurrent Serializable Conflict Serializable View Serializable Non-Serializable Recoverable Cascading Cascadeless Strict Non-Recoverable","title":"Schedule"},{"location":"database_system/transactions_and_schedules#serial-schedule","text":"When one transaction executes completely before starting another transaction It is always consistent Has low throughput and less resource utilization","title":"Serial Schedule"},{"location":"database_system/transactions_and_schedules#concurrent-schedule","text":"When operations of a transaction are interleaved With operations of other transactions of a schedule Can lead to inconsistency Serializable Schedules Used to verify whether the scheduling will lead to any inconsistency These are non-serial transactions that produce an equal outcome when executed serially","title":"Concurrent Schedule"},{"location":"database_system/transactions_and_schedules#conflict-serializable","text":"If the schedule can be transformed into serial schedule By swapping non-conflicting operations","title":"Conflict Serializable"},{"location":"database_system/transactions_and_schedules#conflicting-operations","text":"They belong to separate transactions Both operate on the same data item At least one of them is write operation","title":"Conflicting Operations"},{"location":"database_system/transactions_and_schedules#examples","text":"Example 1: S: R1(A), W1(A), R2(A), W2(A), R1(B), W1(B), R2(B), W2(B) Swapping non-conflicting operations S1: R1(A), W1(A), R1(B), W1(B), R2(A), W2(A), R2(B), W2(B) This can be represented as T1 -> T2 It can also be rearranged as T2 -> T1 Example 2: S: R2(A), W2(A), R1(A), W1(A), R1(B), W1(B), R2(B), W2(B) A needs to be written by T2 first & then needs to be read by T1 B needs to be written by T1 first & then needs to be read by T2 Hence, it cannot be rearranged as T1 -> T2 or T2 -> T1 So it is not conflict serializable","title":"Examples"},{"location":"database_system/transactions_and_schedules#conflict-equivalent","text":"Two schedules are conflict equivalent If one can be transformed to another by swapping non-conflicting operations In example 1, S & S1 are conflict equivalent","title":"Conflict Equivalent"},{"location":"database_system/transactions_and_schedules#view-serializable","text":"A schedule is view serializable if it is view equivalent to a serial schedule Serial Schedule Transactions are executed one after another without interleaving View Equivalent If two schedules produce the same final state of the database And ensure the same read/write behavior for all transactions There are no overlapping transactions Schedules that are conflict serializable are always view serializale Conditions in both the schedules Read of initial value and write of final value must be same for a data item W -> R conflict must be the same","title":"View Serializable"},{"location":"database_system/transactions_and_schedules#view-equivalence","text":"Two schedules are view equivalent If they produce the same set of results when executed against the same state Order of any two conflicting operations in S1 should be same in S2 Conditions Initial Read If T1 reads the data item A in S1 Then T1 should also read A in S2 Updated Read If T1 reads A written by T2 in S1 Then T1 should also read A written by T2 in S2 Final Write If T1 performs the final write on A in S1 Then T1 should also perform the final write on A in S2","title":"View Equivalence"},{"location":"database_system/transactions_and_schedules#recoverable-schedules","text":"Transactions commit only after all the transactions whose changes were read are committed It allows the system to return the database to a consistent state Example: T1 reads A, modifies and writes A T2 reads A, modifies and writes A T1 is committed T2 is committed (Committed after T1, A read by T2 was modified by T1) Cascading Schedule If a transaction fails, all other dependent transactions rolled back or aborted Cascadeless Schedule Transactions read values only after All the transactions whose changes are to be read are committed Avoids a series of transaction rollbacks due to abort of a single transaction Strict Schedule A transaction can read or write updated value of another transaction Only after it is commited or aborted","title":"Recoverable Schedules"},{"location":"database_system/transactions_and_schedules#non-recoverable-schedules","text":"If a transaction T2 reads and commits changes made by another transaction T1 But later if that transaction T1 is aborted, the value read by T2 will be wrong Since T2 already committed, the schedule is non-recoverable","title":"Non Recoverable Schedules"},{"location":"database_system/concurrency_control","text":"Concurrency Control To increase throughput and efficiency of the system Concurrent schedules & transactions are used Concurrency Control Protocols Set of rules maintained to solve the concurrency control problems Ensures that schedules are serializable, recoverable and maybe cascadeless Categories of protocols Lock Based Graph Based Timestamp Ordering Multiple Granularity Multi-version Concurrency Problems Dirty Read Problem (Write Read Conflict) When one transaction updates an item but it fails to commit later Meanwhile, another transaction reads the updated value, creating an inconsistency Example T1 modifies database without committing the changes T2 reads the uncommitted data by T1 T1 performs rollback To prevent them, SQL provides transaction isolation levels as discussed below Lost Update Problem When two or more transactions modify the same data resulting in overwritten or lost updated data Example T1 reads value of an item from the database T2 starts and reads the same database item T1 updates the value and performs a commit T2 updates the same item based on the initial read and performs a commit Update committed by T1 gets overwritten by T2 Non-repeatable Read When a transaction reads the same row twice and gets a different value each time This happens if another transaction updates the value between the two reads Phantom Read When a transaction executes a query twice but it retrieves different rows This happens if another transaction adds new rows that match the search criteria Isolation Levels These specify how transactions should be isolated from one another Prevents the concurrency problems The choice of isolation level depends on specific requirements Higher isolation offers stronger data consistency But longer lock times and increased contention Leading to decreased concurrency and perrformance Read Uncommitted Allows to read uncommitted data from other transactions Can lead to dirty reads, non-repeatable reads, phantom reads Read Committed Allows to read only committed data (prevents dirty reads) Transaction holds a lock on the current row And prevents operations from other transactions Repeatable Read Ensures that a transaction always reads the same data for a given query Even if other transactions modify the data in the meantime Prevents dirty reads and non-repeatable reads Transaction holds read locks on the referencing rows And write locks on the referenced rows Serializable Ensures that transactions are executed serially Provides highest level of isolation Prevents dirty reads, non-repeatable reads, phantom reads Starvation When transaction is not able to get the required resources And is continuously delayed or blocked This happens when other transactions are given priority Causes Waiting scheme for locked items is unfair (maybe priority queue) The same transaction is selected as victim repeatedly Resource leak Denial of service attack Solutions Increasing priority Modify victim selection algorithm First come first serve Wait die and wound wait schemes Timeout the waiting transaction after a certain amount of time Resource Reservation: Start execution only when all resources are allocated Preemption Dynamic lock allocation by analyzing the lock requests Parallelism Deadlock When two or more transactions are waiting for each other to release resources Both transactions require the lock being hold by the other and none can proceed Conditions Mutual exclusion Hold and wait No preemption Circular wait Avoidance Suitable for smaller database Aquire locks in the same order, wait for the previous transaction Detection Draw a wait for graph and check if there is a cycle Prevention Suitable for larger databases Wait die Wound wait Discussed in detail in timestamp ordering protocol","title":"Concurrency Control"},{"location":"database_system/concurrency_control#concurrency-control","text":"To increase throughput and efficiency of the system Concurrent schedules & transactions are used Concurrency Control Protocols Set of rules maintained to solve the concurrency control problems Ensures that schedules are serializable, recoverable and maybe cascadeless Categories of protocols Lock Based Graph Based Timestamp Ordering Multiple Granularity Multi-version","title":"Concurrency Control"},{"location":"database_system/concurrency_control#concurrency-problems","text":"","title":"Concurrency Problems"},{"location":"database_system/concurrency_control#dirty-read-problem-write-read-conflict","text":"When one transaction updates an item but it fails to commit later Meanwhile, another transaction reads the updated value, creating an inconsistency Example T1 modifies database without committing the changes T2 reads the uncommitted data by T1 T1 performs rollback To prevent them, SQL provides transaction isolation levels as discussed below","title":"Dirty Read Problem (Write Read Conflict)"},{"location":"database_system/concurrency_control#lost-update-problem","text":"When two or more transactions modify the same data resulting in overwritten or lost updated data Example T1 reads value of an item from the database T2 starts and reads the same database item T1 updates the value and performs a commit T2 updates the same item based on the initial read and performs a commit Update committed by T1 gets overwritten by T2","title":"Lost Update Problem"},{"location":"database_system/concurrency_control#non-repeatable-read","text":"When a transaction reads the same row twice and gets a different value each time This happens if another transaction updates the value between the two reads","title":"Non-repeatable Read"},{"location":"database_system/concurrency_control#phantom-read","text":"When a transaction executes a query twice but it retrieves different rows This happens if another transaction adds new rows that match the search criteria","title":"Phantom Read"},{"location":"database_system/concurrency_control#isolation-levels","text":"These specify how transactions should be isolated from one another Prevents the concurrency problems The choice of isolation level depends on specific requirements Higher isolation offers stronger data consistency But longer lock times and increased contention Leading to decreased concurrency and perrformance Read Uncommitted Allows to read uncommitted data from other transactions Can lead to dirty reads, non-repeatable reads, phantom reads Read Committed Allows to read only committed data (prevents dirty reads) Transaction holds a lock on the current row And prevents operations from other transactions Repeatable Read Ensures that a transaction always reads the same data for a given query Even if other transactions modify the data in the meantime Prevents dirty reads and non-repeatable reads Transaction holds read locks on the referencing rows And write locks on the referenced rows Serializable Ensures that transactions are executed serially Provides highest level of isolation Prevents dirty reads, non-repeatable reads, phantom reads","title":"Isolation Levels"},{"location":"database_system/concurrency_control#starvation","text":"When transaction is not able to get the required resources And is continuously delayed or blocked This happens when other transactions are given priority Causes Waiting scheme for locked items is unfair (maybe priority queue) The same transaction is selected as victim repeatedly Resource leak Denial of service attack Solutions Increasing priority Modify victim selection algorithm First come first serve Wait die and wound wait schemes Timeout the waiting transaction after a certain amount of time Resource Reservation: Start execution only when all resources are allocated Preemption Dynamic lock allocation by analyzing the lock requests Parallelism","title":"Starvation"},{"location":"database_system/concurrency_control#deadlock","text":"When two or more transactions are waiting for each other to release resources Both transactions require the lock being hold by the other and none can proceed Conditions Mutual exclusion Hold and wait No preemption Circular wait Avoidance Suitable for smaller database Aquire locks in the same order, wait for the previous transaction Detection Draw a wait for graph and check if there is a cycle Prevention Suitable for larger databases Wait die Wound wait Discussed in detail in timestamp ordering protocol","title":"Deadlock"},{"location":"database_system/concurrency_control_protocols","text":"Concurrency Control Protocols Lock Based Protocols Each transaction needs to acquire locks before accessing or modifying the data items Shared Lock Read lock, no modification allowed Allows multiple transactions to read the data simultaneously Exclusive Locks Write lock, allows updation Only one transaction can hold this lock on a data item at a time A transaction is allowed to upgrade or downgrade a lock if the conditions are met Simple lock based protocal (binary locking) don't guarantee serializability Additional protocols for positioning of locking & unlocking operations are required Which gives rise to two phase locking protocol Starvation and deadlocks are possible Locking Lock manager manages the locking requests made by transactions It relies on the process of message passing between transactions and lock manager Lock table Hash table where names of data items are used as hashing index Every locked data item has a linked list associated with it Every node in the list represents a transaction that requested lock Mode of lock requested (mutual/exclusive) Current status of the request (granted/waiting) Collisions are handled by separate chaining A node is deleted after unlock or abort Two-Phase Locking Protocol Phases Growing The transaction starts acquiring locks before performing any modification to data items Once a lock is acquired, it cannot be released until the end of the execution Upgrading is allowed in growing phase only Shrinking The transaction releases all the acquired locks after all the modifications Once it starts releasing the locks, it cannot acquire any locks further Downgrading is allowed in shrinking phase only Lock Point The point at which the growing phase ends That is, when a transaction takes the final lock Cascading Rollback is possible if the dependent transaction's commit fails To claim an exclusive (write) lock Transaction must acquire a shared (read) lock first And then upgrade it to an exclusive lock Problems Deadlock Example: L1(A), L2(B), L1(B), L2(A) T1 granted A, T2 granted B T1 waiting for B, T2 waiting for A Starvation Does not ensure recoverability Strict 2PL Protocol In 2PL, transactions can release any lock before committing In strict 2PL, transactions can release exclusive locks only after they commit Recoverable, Cascadeless Deadlocks are possible Most popular version of 2PL Rigorous 2PL Protocol Transactions can release a shared or exclusive lock only after they commit Recoverable, Cascadeless Deadlocks are possible Conservative or Static 2PL Protocol The transaction should lock all the items before starting execution By predeclaring its read-set and write-set If any of the predeclared items cannot be locked Then the transaction should not lock any of the items And wait till all the items are available for locking Locks can be released at any time Not cascadeless, so does not ensure a strict schedule Deadlock free, since one deadlock condition (hold & wait) is nullified Difficult to use in practice because predeclaration is not possible in many situations Graph Based Protocols Transactions are represented as nodes in a graph And the conflicts between them as edges If a transaction tries to acquire an exclusive lock on an item And if that is already locked by another transaction Then a conflict edge is added between their nodes When the transaction is completed, its edges are removed Before granting a lock, graph is checked for any cycles If a cycle exists, there is a conflict And one of the transactions needs to be rolled back to break the cycle It can handle complex transactions better than two-phase locking But it's computationally expensive And may not scale well for large databases Tree Based Protocol Simple implementation of graph based protocol Data item A can be locked by T1 only if the parent of A is currently locked by T1 Data items can be unlocked at any time Multiple Granularity Locking Various concurrency control protocols perform synchronization on individual data items If a transaction need to access the entire database It will need to lock each item individually This is inefficient and it would be simpler if a single lock can lock the entire database But if another transaction needs to access a few data items, it should be able to do that Locking the entire database in that case will result in loss of concurrency Granularity is the size of the data item allowed to lock Multiple granularity means hierarchically breaking up the database into blocks That can be locked and can be tracked what needs to be locked & in what fashion How does the system determine if the root node can be locked If it searches the entire tree, it will nullify the whole purpose of this locking scheme A more efficient way is to introduce a new lock mode (intention lock) Representation It can be represented graphically as a tree. Example: Root: Entire database 1st Level: Areas within the database 2nd Level: Files within each area (each file can have only one area) 3rd Level: Records within each file Each node can be locked (shared or exclusive) individually When a node is locked, it implicitly locks all the descendants in the same mode Intention Locks In addition to Shared (S) & Exclusive (X) locks, multiple granularity has 3 additional locks This ensures serializability Intention-Shared (IS) Intention-Exclusive (IX) Shared & Intention-Exclusive (SIX) Procedure for transaction to acquire lock Check the lock compatiblity Lock the root of the tree first in any mode Follows 2PL, so deadlocks are possible Locks are acquired top-down (root to leaf) and released bottom-up (leaf to root) Lock can be acquired only If the parent is locked If none of the children is locked Node can be locked in S, IS if the parent is in IX, IS X, IX, SIX if the parent is in IX, SIX Timestamp Based Protocols Each transaction has a timestamp attached to it The timestamps are usually assigned in the order of submission The conflicting pairs of operations can be resolved by their timestamps TS(T) \u2013 Timestamp of transaction T when submitted TS(W(X)): Latest timestamp when any transaction executed W(X) successfully TS(R(X)): Latest timestamp when any transaction executed R(X) successfully Deadlock Prevention Wait Die An older transaction should wait for a younger transaction If a younger transaction waiting for an older transaction Younger transaction should be aborted and restarted with the same timestamp Non-preemptive technique Wound Wait A younger transaction should wait for an older transaction If an older transaction is waiting for a younger transaction Younger transaction should be aborted and restarted with the same timestamp Preemptive technique In both cases, younger transaction is aborted Based on the assumption that it will waste less processing effort Timstamp Ordering Protocol Ensures that the conflicting operations do not violate the ordering If R(X) and W(X) are conflicting operations Then R(X) is processed before W(X) if and only if TS(T1) < TS(T2) If a schedule doesn't follow a timestamp serializability, reject and rollback the transaction Each transaction is assigned a unique timestamp when it enters the system Ensuring that all operations follow a specific order Making the schedule conflict serializable and deadlock free Cascading rollbacks are possible If T2 occurs before T1 Allowed Operations R1(X), R2(X) Not Allowed Operations R1(X), W2(X) W1(X), R2(X) W1(X), W2(X) Strict Timestamp Ordering A variation where the read or write operation is delayed Until the transaction that wrote the value of the data item is committed or aborted Working If a transaction Ti issues a read(X) operation If TS(T) < TS(W(X)): Abort and rollback If TS(T) >= TS(W(X)): Execute W(X) and set TS(W(X)) to TS(T) All data-item timestamps updated If a transaction Ti issues a write(X) operation If TS(Ti) < RTS(X): Operation rejected If TS(Ti) < WTS(X): Operation rejected and Ti rolled back Else: Operation executed Thomas Write Rule (Write Ahead Logging Protocol) Any modification to a database must be written to disk Before the control is returned to a user This ensures that database remains consistent and durable Modification of the basic timestamp ordering protocol Does not enforce conflict serializability But rejects fewer write operations by modifying the check operations for W(X) If T2 occurs before T1 Allowed Operations W1(X), W2(X) R1(X), R2(X) Not Allowed Operations R1(X), W2(X) W1(X), R2(X) Working If TS(R(X)) > TS(T): Abort and rollback T If TS(W(X)) > TS(T): Skip the write operation and continue Case of outdated of obsolete writes A transaction has already updated the value of X TO protocol aborts such a transaction Example Schedule: T2(R(X)), T1(W(X)), T2(W(X)) but T1 already wrote X Else: Execute W(X) and set TS(W(X)) to TS(T)","title":"Concurrency Control Protocols"},{"location":"database_system/concurrency_control_protocols#concurrency-control-protocols","text":"","title":"Concurrency Control Protocols"},{"location":"database_system/concurrency_control_protocols#lock-based-protocols","text":"Each transaction needs to acquire locks before accessing or modifying the data items Shared Lock Read lock, no modification allowed Allows multiple transactions to read the data simultaneously Exclusive Locks Write lock, allows updation Only one transaction can hold this lock on a data item at a time A transaction is allowed to upgrade or downgrade a lock if the conditions are met Simple lock based protocal (binary locking) don't guarantee serializability Additional protocols for positioning of locking & unlocking operations are required Which gives rise to two phase locking protocol Starvation and deadlocks are possible","title":"Lock Based Protocols"},{"location":"database_system/concurrency_control_protocols#locking","text":"Lock manager manages the locking requests made by transactions It relies on the process of message passing between transactions and lock manager Lock table Hash table where names of data items are used as hashing index Every locked data item has a linked list associated with it Every node in the list represents a transaction that requested lock Mode of lock requested (mutual/exclusive) Current status of the request (granted/waiting) Collisions are handled by separate chaining A node is deleted after unlock or abort","title":"Locking"},{"location":"database_system/concurrency_control_protocols#two-phase-locking-protocol","text":"Phases Growing The transaction starts acquiring locks before performing any modification to data items Once a lock is acquired, it cannot be released until the end of the execution Upgrading is allowed in growing phase only Shrinking The transaction releases all the acquired locks after all the modifications Once it starts releasing the locks, it cannot acquire any locks further Downgrading is allowed in shrinking phase only Lock Point The point at which the growing phase ends That is, when a transaction takes the final lock Cascading Rollback is possible if the dependent transaction's commit fails To claim an exclusive (write) lock Transaction must acquire a shared (read) lock first And then upgrade it to an exclusive lock Problems Deadlock Example: L1(A), L2(B), L1(B), L2(A) T1 granted A, T2 granted B T1 waiting for B, T2 waiting for A Starvation Does not ensure recoverability","title":"Two-Phase Locking Protocol"},{"location":"database_system/concurrency_control_protocols#strict-2pl-protocol","text":"In 2PL, transactions can release any lock before committing In strict 2PL, transactions can release exclusive locks only after they commit Recoverable, Cascadeless Deadlocks are possible Most popular version of 2PL","title":"Strict 2PL Protocol"},{"location":"database_system/concurrency_control_protocols#rigorous-2pl-protocol","text":"Transactions can release a shared or exclusive lock only after they commit Recoverable, Cascadeless Deadlocks are possible","title":"Rigorous 2PL Protocol"},{"location":"database_system/concurrency_control_protocols#conservative-or-static-2pl-protocol","text":"The transaction should lock all the items before starting execution By predeclaring its read-set and write-set If any of the predeclared items cannot be locked Then the transaction should not lock any of the items And wait till all the items are available for locking Locks can be released at any time Not cascadeless, so does not ensure a strict schedule Deadlock free, since one deadlock condition (hold & wait) is nullified Difficult to use in practice because predeclaration is not possible in many situations","title":"Conservative or Static 2PL Protocol"},{"location":"database_system/concurrency_control_protocols#graph-based-protocols","text":"Transactions are represented as nodes in a graph And the conflicts between them as edges If a transaction tries to acquire an exclusive lock on an item And if that is already locked by another transaction Then a conflict edge is added between their nodes When the transaction is completed, its edges are removed Before granting a lock, graph is checked for any cycles If a cycle exists, there is a conflict And one of the transactions needs to be rolled back to break the cycle It can handle complex transactions better than two-phase locking But it's computationally expensive And may not scale well for large databases Tree Based Protocol Simple implementation of graph based protocol Data item A can be locked by T1 only if the parent of A is currently locked by T1 Data items can be unlocked at any time","title":"Graph Based Protocols"},{"location":"database_system/concurrency_control_protocols#multiple-granularity-locking","text":"Various concurrency control protocols perform synchronization on individual data items If a transaction need to access the entire database It will need to lock each item individually This is inefficient and it would be simpler if a single lock can lock the entire database But if another transaction needs to access a few data items, it should be able to do that Locking the entire database in that case will result in loss of concurrency Granularity is the size of the data item allowed to lock Multiple granularity means hierarchically breaking up the database into blocks That can be locked and can be tracked what needs to be locked & in what fashion How does the system determine if the root node can be locked If it searches the entire tree, it will nullify the whole purpose of this locking scheme A more efficient way is to introduce a new lock mode (intention lock)","title":"Multiple Granularity Locking"},{"location":"database_system/concurrency_control_protocols#representation","text":"It can be represented graphically as a tree. Example: Root: Entire database 1st Level: Areas within the database 2nd Level: Files within each area (each file can have only one area) 3rd Level: Records within each file Each node can be locked (shared or exclusive) individually When a node is locked, it implicitly locks all the descendants in the same mode","title":"Representation"},{"location":"database_system/concurrency_control_protocols#intention-locks","text":"In addition to Shared (S) & Exclusive (X) locks, multiple granularity has 3 additional locks This ensures serializability Intention-Shared (IS) Intention-Exclusive (IX) Shared & Intention-Exclusive (SIX)","title":"Intention Locks"},{"location":"database_system/concurrency_control_protocols#procedure-for-transaction-to-acquire-lock","text":"Check the lock compatiblity Lock the root of the tree first in any mode Follows 2PL, so deadlocks are possible Locks are acquired top-down (root to leaf) and released bottom-up (leaf to root) Lock can be acquired only If the parent is locked If none of the children is locked Node can be locked in S, IS if the parent is in IX, IS X, IX, SIX if the parent is in IX, SIX","title":"Procedure for transaction to acquire lock"},{"location":"database_system/concurrency_control_protocols#timestamp-based-protocols","text":"Each transaction has a timestamp attached to it The timestamps are usually assigned in the order of submission The conflicting pairs of operations can be resolved by their timestamps TS(T) \u2013 Timestamp of transaction T when submitted TS(W(X)): Latest timestamp when any transaction executed W(X) successfully TS(R(X)): Latest timestamp when any transaction executed R(X) successfully","title":"Timestamp Based Protocols"},{"location":"database_system/concurrency_control_protocols#deadlock-prevention","text":"Wait Die An older transaction should wait for a younger transaction If a younger transaction waiting for an older transaction Younger transaction should be aborted and restarted with the same timestamp Non-preemptive technique Wound Wait A younger transaction should wait for an older transaction If an older transaction is waiting for a younger transaction Younger transaction should be aborted and restarted with the same timestamp Preemptive technique In both cases, younger transaction is aborted Based on the assumption that it will waste less processing effort","title":"Deadlock Prevention"},{"location":"database_system/concurrency_control_protocols#timstamp-ordering-protocol","text":"Ensures that the conflicting operations do not violate the ordering If R(X) and W(X) are conflicting operations Then R(X) is processed before W(X) if and only if TS(T1) < TS(T2) If a schedule doesn't follow a timestamp serializability, reject and rollback the transaction Each transaction is assigned a unique timestamp when it enters the system Ensuring that all operations follow a specific order Making the schedule conflict serializable and deadlock free Cascading rollbacks are possible If T2 occurs before T1 Allowed Operations R1(X), R2(X) Not Allowed Operations R1(X), W2(X) W1(X), R2(X) W1(X), W2(X) Strict Timestamp Ordering A variation where the read or write operation is delayed Until the transaction that wrote the value of the data item is committed or aborted","title":"Timstamp Ordering Protocol"},{"location":"database_system/concurrency_control_protocols#working","text":"If a transaction Ti issues a read(X) operation If TS(T) < TS(W(X)): Abort and rollback If TS(T) >= TS(W(X)): Execute W(X) and set TS(W(X)) to TS(T) All data-item timestamps updated If a transaction Ti issues a write(X) operation If TS(Ti) < RTS(X): Operation rejected If TS(Ti) < WTS(X): Operation rejected and Ti rolled back Else: Operation executed","title":"Working"},{"location":"database_system/concurrency_control_protocols#thomas-write-rule-write-ahead-logging-protocol","text":"Any modification to a database must be written to disk Before the control is returned to a user This ensures that database remains consistent and durable Modification of the basic timestamp ordering protocol Does not enforce conflict serializability But rejects fewer write operations by modifying the check operations for W(X) If T2 occurs before T1 Allowed Operations W1(X), W2(X) R1(X), R2(X) Not Allowed Operations R1(X), W2(X) W1(X), R2(X)","title":"Thomas Write Rule (Write Ahead Logging Protocol)"},{"location":"database_system/concurrency_control_protocols#working_1","text":"If TS(R(X)) > TS(T): Abort and rollback T If TS(W(X)) > TS(T): Skip the write operation and continue Case of outdated of obsolete writes A transaction has already updated the value of X TO protocol aborts such a transaction Example Schedule: T2(R(X)), T1(W(X)), T2(W(X)) but T1 already wrote X Else: Execute W(X) and set TS(W(X)) to TS(T)","title":"Working"},{"location":"database_system/recoverability_and_processing","text":"Recoverability and Processing Recoverability Data can be lost or transactions can fail due to Transaction errors Transaction irregularities or no longer acceptable May be aborted due to serializability violation or deadlock System error (logical programming errors) Incorrect command execution, security breaches System crashes, network failures, disk failures, data corruption, viruses Catastrophic failures: fire, theft, overwriting by mistake Recovery techniques are heavily dependent upon a special file called system log It contains info about start and end of each transaction Keeps track of all operations that affect database values Logging Record all the activities and transactions in the database Fields Transaction identifier Data item Old value New value Log based on operations T(i) start: Stores info when a transaction starts T(i) commit: Stores info when a transaction commits T(i) abort: Stores info when a transaction aborts Undo & Redo All modifications must precede by the creation of a log record The system should be able to Undo the operation and set the data item to the old value Redo the operation and set the data item to the new value Redo operations should be idempotent (give the same result when performed again) Should not lead to creating duplicate entities After a system crash Undo the transaction if T-start is present but not T-commit or T-abort Redo the transaction if T-start and T-commit or T-abort is present Checkpoints Checkpoint logs keep track of the list of transactions active at the time of the checkpoint Any modifications by the transactions is written either prior or as part of the checkpoint After a crash, undo or redo needs to be applied only to the transactions in and after the checkpoint Modification Techniques Deferred Update Transaction doesn't modify the database until partially committed Undo is not needed since the transaction won't have changed anything Redo maybe required for operations recorded in the local transaction workspace Immediate Update Transaction can modify the database while still in execution Both undo & redo are required Caching/Buffering Disk pages that include data items that are to be updated are cached into main memory buffers Then are updated in memory before being written back to disk A collection of in-memory buffers called DBMS cache is kept under the control of DBMS A directory is used to keep track of the database items that are in buffer A dirty bit is associated with each buffer (1 if buffer is modified else 0) Shadow Paging When a transaction begins executing, the current directory is copied into a shadow directory When a page is to be modified, a shadow page is allocated in which changes are made When it is ready to become durable All pages that refer to the original are updated to refer new replacement page Backup Techniques Full Database Backup Differential Backup Stores only the data changes that have occurred since the last full database backup For this, first a full database backup needs to be restored Transaction Log Backup Through this, the database can be recovered to a specific point in time OLAP (Online Analytical Processing) OLAP systems can analyze database information of multiple systems at the current time The primary goal is data analysis and not data processing Online query management system that consists of historical data Any type of data warehouse system is an OLAP system Tables are not normalized Relatively slow due to large amount of data Applications Used for data mining, analytics, decision making, big data Spotify analyzing songs to come up with personalized homepage and playlists Movie recommendation system in netflix Benefits Store planning, analysis, budgeting for business analytics within one platform Helps in handling large volumes of data Which helps in enterprise-level business applications Helps in applying security restrictions for data protection Provides multi-dimensional view of data Challenges Requires professionals to handle data due to complex modeling procedure Expensive to implement and maintain for large datasets Requires extraction and transformation of data for analysis which delays the system Updated on periodic basis and not real time Types of OLAP Servers Relational Data is stored in relational database Based on the premise that Data need not be stored multi-dimensionally to be viewed multi-dimensionally Multidimensional Data is stored on disks in a specialized multi-dimensional array structure Has advanced indexing and hashing to locate data and handle sparse arrays Fast data retrieval, optimal for slicing & dicing, perform complex calculations Hybrid of Relational & Multi-dimensional Transparent: Work with existing RDBMS without transfering data to a separate OLAP system OLTP (Online Transaction Processing) OLTP systems administer day to day transactions in any organization The primary goal is data processing and not data analysis Online data modifying system that consists of operational current data Handles ACID properties during data transactions Tables are normalized Fast as the queries operate on 5% of data Example: ATM center, sending text message, online banking & ticket booking & shopping Benefits Allows users to read, write and delete data operations quickly Helps in increasing users & transactions which helps in real-time access to data Helps in applying multiple security features Helps in making better decisions by providing accurate data or current data Provides data integrity, consistency, and high availability to data Challenges Limited analysis and reporting capability High maintenance costs because of frequent maintenance, backups & recovery Some issues like duplicate or inconsistent data can occur","title":"Recoverability And Processing"},{"location":"database_system/recoverability_and_processing#recoverability-and-processing","text":"","title":"Recoverability and Processing"},{"location":"database_system/recoverability_and_processing#recoverability","text":"Data can be lost or transactions can fail due to Transaction errors Transaction irregularities or no longer acceptable May be aborted due to serializability violation or deadlock System error (logical programming errors) Incorrect command execution, security breaches System crashes, network failures, disk failures, data corruption, viruses Catastrophic failures: fire, theft, overwriting by mistake Recovery techniques are heavily dependent upon a special file called system log It contains info about start and end of each transaction Keeps track of all operations that affect database values","title":"Recoverability"},{"location":"database_system/recoverability_and_processing#logging","text":"Record all the activities and transactions in the database Fields Transaction identifier Data item Old value New value Log based on operations T(i) start: Stores info when a transaction starts T(i) commit: Stores info when a transaction commits T(i) abort: Stores info when a transaction aborts","title":"Logging"},{"location":"database_system/recoverability_and_processing#undo-redo","text":"All modifications must precede by the creation of a log record The system should be able to Undo the operation and set the data item to the old value Redo the operation and set the data item to the new value Redo operations should be idempotent (give the same result when performed again) Should not lead to creating duplicate entities After a system crash Undo the transaction if T-start is present but not T-commit or T-abort Redo the transaction if T-start and T-commit or T-abort is present","title":"Undo &amp; Redo"},{"location":"database_system/recoverability_and_processing#checkpoints","text":"Checkpoint logs keep track of the list of transactions active at the time of the checkpoint Any modifications by the transactions is written either prior or as part of the checkpoint After a crash, undo or redo needs to be applied only to the transactions in and after the checkpoint","title":"Checkpoints"},{"location":"database_system/recoverability_and_processing#modification-techniques","text":"Deferred Update Transaction doesn't modify the database until partially committed Undo is not needed since the transaction won't have changed anything Redo maybe required for operations recorded in the local transaction workspace Immediate Update Transaction can modify the database while still in execution Both undo & redo are required Caching/Buffering Disk pages that include data items that are to be updated are cached into main memory buffers Then are updated in memory before being written back to disk A collection of in-memory buffers called DBMS cache is kept under the control of DBMS A directory is used to keep track of the database items that are in buffer A dirty bit is associated with each buffer (1 if buffer is modified else 0) Shadow Paging When a transaction begins executing, the current directory is copied into a shadow directory When a page is to be modified, a shadow page is allocated in which changes are made When it is ready to become durable All pages that refer to the original are updated to refer new replacement page","title":"Modification Techniques"},{"location":"database_system/recoverability_and_processing#backup-techniques","text":"Full Database Backup Differential Backup Stores only the data changes that have occurred since the last full database backup For this, first a full database backup needs to be restored Transaction Log Backup Through this, the database can be recovered to a specific point in time","title":"Backup Techniques"},{"location":"database_system/recoverability_and_processing#olap-online-analytical-processing","text":"OLAP systems can analyze database information of multiple systems at the current time The primary goal is data analysis and not data processing Online query management system that consists of historical data Any type of data warehouse system is an OLAP system Tables are not normalized Relatively slow due to large amount of data Applications Used for data mining, analytics, decision making, big data Spotify analyzing songs to come up with personalized homepage and playlists Movie recommendation system in netflix Benefits Store planning, analysis, budgeting for business analytics within one platform Helps in handling large volumes of data Which helps in enterprise-level business applications Helps in applying security restrictions for data protection Provides multi-dimensional view of data Challenges Requires professionals to handle data due to complex modeling procedure Expensive to implement and maintain for large datasets Requires extraction and transformation of data for analysis which delays the system Updated on periodic basis and not real time","title":"OLAP (Online Analytical Processing)"},{"location":"database_system/recoverability_and_processing#types-of-olap-servers","text":"Relational Data is stored in relational database Based on the premise that Data need not be stored multi-dimensionally to be viewed multi-dimensionally Multidimensional Data is stored on disks in a specialized multi-dimensional array structure Has advanced indexing and hashing to locate data and handle sparse arrays Fast data retrieval, optimal for slicing & dicing, perform complex calculations Hybrid of Relational & Multi-dimensional Transparent: Work with existing RDBMS without transfering data to a separate OLAP system","title":"Types of OLAP Servers"},{"location":"database_system/recoverability_and_processing#oltp-online-transaction-processing","text":"OLTP systems administer day to day transactions in any organization The primary goal is data processing and not data analysis Online data modifying system that consists of operational current data Handles ACID properties during data transactions Tables are normalized Fast as the queries operate on 5% of data Example: ATM center, sending text message, online banking & ticket booking & shopping Benefits Allows users to read, write and delete data operations quickly Helps in increasing users & transactions which helps in real-time access to data Helps in applying multiple security features Helps in making better decisions by providing accurate data or current data Provides data integrity, consistency, and high availability to data Challenges Limited analysis and reporting capability High maintenance costs because of frequent maintenance, backups & recovery Some issues like duplicate or inconsistent data can occur","title":"OLTP (Online Transaction Processing)"},{"location":"database_system/indexing","text":"Indexing Data structure technique to quickly locate and access data Minimizes disk accesses required for a query An index entry consists of the search key with value as the data reference Complex columns should not be indexed, it might decrease the performance instead Columns with large datasets but small classification should not be indexed For example, boolean columns since there will be large data for a single key Indexing 10K rows into true & false can deplete performance Indexing Mechanisms File organization mechanisms followed by indexing methods to store data Sequential File Organization (Or Ordered Index File) Dense index For every search key in the data file, there is an index record The record contains the search key and the reference to the first data record Sparse index The index record is present for only a few items in the data file The reference in each record points to a block To locate a record We find the record with the largest search-key value less than or equal to the target After jumping to the reference pointer The file is searched sequentially for the target record Number of accesses required = log(n) + 1, where n is the number of blocks Hash File Organization Indices are based on the values distributed uniformly across a range of buckets A hash function determines the bucket to which a value is assigned Clustered or Primary Index Similar records are grouped and indexes are created for these groups In some cases, index is created on non-primary key columns which may not be unique In such cases, two or more columns are grouped to get unique values Non-clustered or Secondary Index Nested index through virtual pointers Data is not physically stored in the order of the index Data is present in the leaf nodes Requires more time than clustered index to extract the data by following pointers Multilevel Index As database size grows, indices also grow As the index is stored in main memory, a single level index might become too large It segregates the main block into various smaller blocks Which ultimately point to the data blocks B and B+ trees B-Tree For storing and searching large amounts of data Traditional binary search trees can become impractical Due to their poor performance and high memory usage Balanced Tree (B-Tree) is a type of self-balancing tree It maintains balance by ensuring that each node has a minimum number of keys This balance guarantees the time complexity of O(log(n)) Regardless of the initial shape of the tree This is true for operations like insertion, deletion, and searching Can store a large number of keys in a single node This allows the tree to have a larger branching factor and shallower height This shallow height leads to less disk I/O and faster search & insertion Node size is kept equal to disk block It's particularly well suited for storage systems with slow & bulky data access Like hard drives, flash memory When number of keys is high, data is read from disk in form of blocks Example: (100) (35, 65) (130, 180) (10, 20) (40, 50) (70, 80, 90) (110, 120) (140, 160) (190, 240, 260) Properties All leaves are at the same level It's defined by the term minimum degree 't', which depends on disk block size All keys of a node are sorted in ascending order Number of keys in nodes Root: (1) to (2t - 1) Others: (t - 1) to (2t - 1) Number of children: Number of keys + 1 Child between two keys k1 & k2 contains all keys from k1 to k2 Grows and shrinks from root unlike BST BSTs grow downward & also shrink from downward Time Complexity for insert, delete, search = O(height) = O(log(n)) Insertion only happens at leaf node Insertion Start from the root and traverse down till we reach a leaf node While traversing, keeping check if the next node has space If there's no space Split the leaf node into two and separate the mid Move the mid to the parent node (That's why B-tree grows up) Repeat this process for every iteration if there's no space Add the key in the leaf node Example: We need to insert 52 and we have: (40, 60) -> (45, 50, 55) Shift 50 to parent & insert 52: (40, 50, 60) -> (45, 52, 55) Deletion Deletion is more complicated than insertion because a key can be deleted from any node When a key is deleted from an internal node, the node's children needs to be rearranged A node should not get too small during deletion Case 1: Key is in a leaf node -> Delete the key Case 2: Key is in an internal node If the parent has at least t keys Delete the predecessor of the key from parent node Replace the key with the predecessor in the current node If the parent has fewer than t keys and the child has at least t keys Then delete the successor of the key from the child node Replace the key with the successor in the current node If both the parent and the child node has (t - 1) keys Merge the current and the child node into the parent node The parent node will contain (2t - 1) keys Delete the key from the parent node Case 3: Key is not in the current node Find the child that may contain the key If the child has only (t - 1) keys but has an immediate sibling with at least t keys Move a key from the current node to the child Move a key from the child's sibling to the current node If the child and its immediate siblings have (t - 1) keys Merge the child with one sibling Move a key from the current node to the merged node as a median B+ tree Variation of B-tree where data pointers are stored only at the leaf node The leaf nodes Have an entry for every value of the search field Have a data pointer to the record (or the block that contains the record) Are linked together to provide ordered access to the search field to the records The internal nodes Are only used to guide the search and don't store any data pointer As a result, more key values can be stored in a node Hence, they have a different order than leaf nodes Some search field values from the leaf nodes are repeated in the internal nodes Hence takes more storage B tree stores the data pointers along with the key values in the internal nodes This reduces the number of entries that can be packed into a node And increases the number of levels which increases the search time B+ tree is very useful for range queries and bulk data retrieval Bitmap Indexing Used to improve performance of read-only queries that involve large datasets Used for a most frequently used column with low cardinality Each distinct value in a column is assigned a bit vector The vector contains a bit for each row and represents the presence or absence of the value Inverted Index Used in information retrieval systems to efficiently retrieve documents or web pages Containing a specific term or set of terms Index is organized by terms (words) pointing to a list of documents Types Record level: Contains a list of references to documents for each word Word level: Also contains the positions of each word within a document","title":"Indexing"},{"location":"database_system/indexing#indexing","text":"Data structure technique to quickly locate and access data Minimizes disk accesses required for a query An index entry consists of the search key with value as the data reference Complex columns should not be indexed, it might decrease the performance instead Columns with large datasets but small classification should not be indexed For example, boolean columns since there will be large data for a single key Indexing 10K rows into true & false can deplete performance","title":"Indexing"},{"location":"database_system/indexing#indexing-mechanisms","text":"File organization mechanisms followed by indexing methods to store data","title":"Indexing Mechanisms"},{"location":"database_system/indexing#sequential-file-organization-or-ordered-index-file","text":"Dense index For every search key in the data file, there is an index record The record contains the search key and the reference to the first data record Sparse index The index record is present for only a few items in the data file The reference in each record points to a block To locate a record We find the record with the largest search-key value less than or equal to the target After jumping to the reference pointer The file is searched sequentially for the target record Number of accesses required = log(n) + 1, where n is the number of blocks","title":"Sequential File Organization (Or Ordered Index File)"},{"location":"database_system/indexing#hash-file-organization","text":"Indices are based on the values distributed uniformly across a range of buckets A hash function determines the bucket to which a value is assigned Clustered or Primary Index Similar records are grouped and indexes are created for these groups In some cases, index is created on non-primary key columns which may not be unique In such cases, two or more columns are grouped to get unique values Non-clustered or Secondary Index Nested index through virtual pointers Data is not physically stored in the order of the index Data is present in the leaf nodes Requires more time than clustered index to extract the data by following pointers Multilevel Index As database size grows, indices also grow As the index is stored in main memory, a single level index might become too large It segregates the main block into various smaller blocks Which ultimately point to the data blocks B and B+ trees","title":"Hash File Organization"},{"location":"database_system/indexing#b-tree","text":"For storing and searching large amounts of data Traditional binary search trees can become impractical Due to their poor performance and high memory usage Balanced Tree (B-Tree) is a type of self-balancing tree It maintains balance by ensuring that each node has a minimum number of keys This balance guarantees the time complexity of O(log(n)) Regardless of the initial shape of the tree This is true for operations like insertion, deletion, and searching Can store a large number of keys in a single node This allows the tree to have a larger branching factor and shallower height This shallow height leads to less disk I/O and faster search & insertion Node size is kept equal to disk block It's particularly well suited for storage systems with slow & bulky data access Like hard drives, flash memory When number of keys is high, data is read from disk in form of blocks Example: (100) (35, 65) (130, 180) (10, 20) (40, 50) (70, 80, 90) (110, 120) (140, 160) (190, 240, 260)","title":"B-Tree"},{"location":"database_system/indexing#properties","text":"All leaves are at the same level It's defined by the term minimum degree 't', which depends on disk block size All keys of a node are sorted in ascending order Number of keys in nodes Root: (1) to (2t - 1) Others: (t - 1) to (2t - 1) Number of children: Number of keys + 1 Child between two keys k1 & k2 contains all keys from k1 to k2 Grows and shrinks from root unlike BST BSTs grow downward & also shrink from downward Time Complexity for insert, delete, search = O(height) = O(log(n)) Insertion only happens at leaf node","title":"Properties"},{"location":"database_system/indexing#insertion","text":"Start from the root and traverse down till we reach a leaf node While traversing, keeping check if the next node has space If there's no space Split the leaf node into two and separate the mid Move the mid to the parent node (That's why B-tree grows up) Repeat this process for every iteration if there's no space Add the key in the leaf node Example: We need to insert 52 and we have: (40, 60) -> (45, 50, 55) Shift 50 to parent & insert 52: (40, 50, 60) -> (45, 52, 55)","title":"Insertion"},{"location":"database_system/indexing#deletion","text":"Deletion is more complicated than insertion because a key can be deleted from any node When a key is deleted from an internal node, the node's children needs to be rearranged A node should not get too small during deletion Case 1: Key is in a leaf node -> Delete the key Case 2: Key is in an internal node If the parent has at least t keys Delete the predecessor of the key from parent node Replace the key with the predecessor in the current node If the parent has fewer than t keys and the child has at least t keys Then delete the successor of the key from the child node Replace the key with the successor in the current node If both the parent and the child node has (t - 1) keys Merge the current and the child node into the parent node The parent node will contain (2t - 1) keys Delete the key from the parent node Case 3: Key is not in the current node Find the child that may contain the key If the child has only (t - 1) keys but has an immediate sibling with at least t keys Move a key from the current node to the child Move a key from the child's sibling to the current node If the child and its immediate siblings have (t - 1) keys Merge the child with one sibling Move a key from the current node to the merged node as a median","title":"Deletion"},{"location":"database_system/indexing#b-tree_1","text":"Variation of B-tree where data pointers are stored only at the leaf node The leaf nodes Have an entry for every value of the search field Have a data pointer to the record (or the block that contains the record) Are linked together to provide ordered access to the search field to the records The internal nodes Are only used to guide the search and don't store any data pointer As a result, more key values can be stored in a node Hence, they have a different order than leaf nodes Some search field values from the leaf nodes are repeated in the internal nodes Hence takes more storage B tree stores the data pointers along with the key values in the internal nodes This reduces the number of entries that can be packed into a node And increases the number of levels which increases the search time B+ tree is very useful for range queries and bulk data retrieval","title":"B+ tree"},{"location":"database_system/indexing#bitmap-indexing","text":"Used to improve performance of read-only queries that involve large datasets Used for a most frequently used column with low cardinality Each distinct value in a column is assigned a bit vector The vector contains a bit for each row and represents the presence or absence of the value","title":"Bitmap Indexing"},{"location":"database_system/indexing#inverted-index","text":"Used in information retrieval systems to efficiently retrieve documents or web pages Containing a specific term or set of terms Index is organized by terms (words) pointing to a list of documents Types Record level: Contains a list of references to documents for each word Word level: Also contains the positions of each word within a document","title":"Inverted Index"},{"location":"database_system/file_organization","text":"File Organization Data is stored in the form of tables in the database But in physical memory it is stored in the form of files File organization refers to logical relationships among various records that constitute the file Particularly with respect to identification and access to any specific record Types of File Organization Sequential File Organization Pile File Method: Records are stored sequentially in the order of insertion in tables Sorted File Method: Records are inserted in a sorted sequence based on primary or any other key We cannot jump on a particular record, but have to move in a sequential manner Heap File Organization Records are inserted at the end as data blocks If a data block is full, the new record is stored in some other block in the memory It may leave unused memory blocks B/B+ Tree File Organization Cluster File Organization Related tables or records are stored within the same file known as clusters Indexed clusters group records based on the cluster key And hash clusters group on hash values of a key These tables can be combined easily using join operation in the cluster file Low performance in large databases Indexed Sequential Access Method Data is stored sequentially but an index is maintained for faster access Not as efficient as fully indexed methods for random access Index maintainance can add overhead in insert & update operation Hashing File Organization For larger databases with thousands & millions of records, indexing becomes inefficient Because searching a specific record consumes more time Hashing can directly reach the location of a record without searching through indices Hash Table Its size is determined by the total volume of data records in database Each memory location in a hash table is called bucket Each bucket stores a disk block that contains multiple records Hash Function Mathematical function that computes the index or location within hash table for a specified record It determines the speed of fetching data If the hash index is already occupied, it's called collision Collision resolution techniques Chaining Records are stored as an array or linked list within an index May result in bucket skew If the hash function keeps generating the same index large number of times The remanining data buckets will store minimal data Open Addressing or Closed Hashing Store the data in the next available sloto Techniques like linear probing, quadratic probing, double hashing can be used to find it Types of Hashing in DBMS Static Hashing Records are directly mapped to a bucket's address Dynamic Hashing Records are first mapped to a directory and then mapped to the buckets Data buckets can be added and removed on demand dynamically The buckets grow & shrink according the size of data records Example: If depth is 2, consider 2 LSB as the directory If hash index is 1100110, the directory will be 10 RAID (Redundant Arrays of Independent Disks) Combination of multiple disks for increased performance and data redundancy In case of disk failure, we can retrieve the data backed up on another disk Key evaluation points for RAID system Reliability: How many disk faults can it tolerate Availability: What fraction of session time is the system in uptime mode Performance: How good is response time & throughput Capacity: How much useful capacity is available to user given a set of disks To the host system, it appears as a single big disk of linear array of blocks This allows older technologies to be replaced by RAID Levels 0: Stripping 1: Mirroring 2: Bit level stripping with dedicated parity 3: Byte level stripping with dedicated parity 4: Block level stripping with dedicated parity 5: Block level stripping with distributed parity 6: Block level stripping with two parity bits","title":"File Organization"},{"location":"database_system/file_organization#file-organization","text":"Data is stored in the form of tables in the database But in physical memory it is stored in the form of files File organization refers to logical relationships among various records that constitute the file Particularly with respect to identification and access to any specific record","title":"File Organization"},{"location":"database_system/file_organization#types-of-file-organization","text":"Sequential File Organization Pile File Method: Records are stored sequentially in the order of insertion in tables Sorted File Method: Records are inserted in a sorted sequence based on primary or any other key We cannot jump on a particular record, but have to move in a sequential manner Heap File Organization Records are inserted at the end as data blocks If a data block is full, the new record is stored in some other block in the memory It may leave unused memory blocks B/B+ Tree File Organization Cluster File Organization Related tables or records are stored within the same file known as clusters Indexed clusters group records based on the cluster key And hash clusters group on hash values of a key These tables can be combined easily using join operation in the cluster file Low performance in large databases Indexed Sequential Access Method Data is stored sequentially but an index is maintained for faster access Not as efficient as fully indexed methods for random access Index maintainance can add overhead in insert & update operation","title":"Types of File Organization"},{"location":"database_system/file_organization#hashing-file-organization","text":"For larger databases with thousands & millions of records, indexing becomes inefficient Because searching a specific record consumes more time Hashing can directly reach the location of a record without searching through indices Hash Table Its size is determined by the total volume of data records in database Each memory location in a hash table is called bucket Each bucket stores a disk block that contains multiple records Hash Function Mathematical function that computes the index or location within hash table for a specified record It determines the speed of fetching data If the hash index is already occupied, it's called collision Collision resolution techniques Chaining Records are stored as an array or linked list within an index May result in bucket skew If the hash function keeps generating the same index large number of times The remanining data buckets will store minimal data Open Addressing or Closed Hashing Store the data in the next available sloto Techniques like linear probing, quadratic probing, double hashing can be used to find it Types of Hashing in DBMS Static Hashing Records are directly mapped to a bucket's address Dynamic Hashing Records are first mapped to a directory and then mapped to the buckets Data buckets can be added and removed on demand dynamically The buckets grow & shrink according the size of data records Example: If depth is 2, consider 2 LSB as the directory If hash index is 1100110, the directory will be 10","title":"Hashing File Organization"},{"location":"database_system/file_organization#raid-redundant-arrays-of-independent-disks","text":"Combination of multiple disks for increased performance and data redundancy In case of disk failure, we can retrieve the data backed up on another disk Key evaluation points for RAID system Reliability: How many disk faults can it tolerate Availability: What fraction of session time is the system in uptime mode Performance: How good is response time & throughput Capacity: How much useful capacity is available to user given a set of disks To the host system, it appears as a single big disk of linear array of blocks This allows older technologies to be replaced by RAID Levels 0: Stripping 1: Mirroring 2: Bit level stripping with dedicated parity 3: Byte level stripping with dedicated parity 4: Block level stripping with dedicated parity 5: Block level stripping with distributed parity 6: Block level stripping with two parity bits","title":"RAID (Redundant Arrays of Independent Disks)"},{"location":"object_oriented_programming/index","text":"Object Oriented Programming Introduction","title":"Index"},{"location":"object_oriented_programming/index#object-oriented-programming","text":"Introduction","title":"Object Oriented Programming"},{"location":"object_oriented_programming/introduction","text":"Introduction Break down requirements into classes, functionalities, behaviour Make projects more manageable and predictable Modularization and reusability Static: Belongs to class rather than instance Memory efficient Make common/fixed member static Can be invoked without creating instance/object Building Blocks Class Represents a concept or logical entity Template or blueprint to create objects Non primitive data type Members Objects, methods, instance variables, constructors Access modifiers (public, private, protected, etc.) Object Instance of a class with allocated memory An entity with identity (unique name), state (data) and behaviour (methods) Can be physical or logical Attribute When objects are instantiated, individual objects contain data that is stored in attributes The state of an object is defined by the data in the object's attributes Method Represents behaviors and performs actions Promotes reusability and keeps functionality encapsulated inside an object Manipulates object data or attributes Principles Encapsulation Integration of data and operations in a class Hiding functional details from object Providing mechanics without the overhead of understanding Abstraction Incomplete class with described but unimplemented operations Implements functionality from abstract class Has-a relationship Interface \u2013 blueprint of class Inheritance Generalizing entities Parent-child relationship or Is-a relationship Inherits attributes and methods of the parent class Extends functionality of the parent class Adds additional attributes & behaviors Polymorphism Multiple definitions of the same method Method Overloading: Differentiating behavior using number of arguments or data type Method Overriding: Modifying behavior in child class","title":"Introduction"},{"location":"object_oriented_programming/introduction#introduction","text":"Break down requirements into classes, functionalities, behaviour Make projects more manageable and predictable Modularization and reusability Static: Belongs to class rather than instance Memory efficient Make common/fixed member static Can be invoked without creating instance/object","title":"Introduction"},{"location":"object_oriented_programming/introduction#building-blocks","text":"","title":"Building Blocks"},{"location":"object_oriented_programming/introduction#class","text":"Represents a concept or logical entity Template or blueprint to create objects Non primitive data type Members Objects, methods, instance variables, constructors Access modifiers (public, private, protected, etc.)","title":"Class"},{"location":"object_oriented_programming/introduction#object","text":"Instance of a class with allocated memory An entity with identity (unique name), state (data) and behaviour (methods) Can be physical or logical","title":"Object"},{"location":"object_oriented_programming/introduction#attribute","text":"When objects are instantiated, individual objects contain data that is stored in attributes The state of an object is defined by the data in the object's attributes","title":"Attribute"},{"location":"object_oriented_programming/introduction#method","text":"Represents behaviors and performs actions Promotes reusability and keeps functionality encapsulated inside an object Manipulates object data or attributes","title":"Method"},{"location":"object_oriented_programming/introduction#principles","text":"","title":"Principles"},{"location":"object_oriented_programming/introduction#encapsulation","text":"Integration of data and operations in a class Hiding functional details from object Providing mechanics without the overhead of understanding","title":"Encapsulation"},{"location":"object_oriented_programming/introduction#abstraction","text":"Incomplete class with described but unimplemented operations Implements functionality from abstract class Has-a relationship Interface \u2013 blueprint of class","title":"Abstraction"},{"location":"object_oriented_programming/introduction#inheritance","text":"Generalizing entities Parent-child relationship or Is-a relationship Inherits attributes and methods of the parent class Extends functionality of the parent class Adds additional attributes & behaviors","title":"Inheritance"},{"location":"object_oriented_programming/introduction#polymorphism","text":"Multiple definitions of the same method Method Overloading: Differentiating behavior using number of arguments or data type Method Overriding: Modifying behavior in child class","title":"Polymorphism"},{"location":"operating_system/index","text":"Operating System Introduction System Structure Process Management Process Scheduling Process Synchronization Process Synchronization Solutions Process Synchronization Application Thread Management Resource Allocation Memory Memory Management Virtual Memory Storage Management","title":"Index"},{"location":"operating_system/index#operating-system","text":"Introduction System Structure Process Management Process Scheduling Process Synchronization Process Synchronization Solutions Process Synchronization Application Thread Management Resource Allocation Memory Memory Management Virtual Memory Storage Management","title":"Operating System"},{"location":"operating_system/introduction","text":"Introduction Interface between users and hardware Provides an environment to execute programs in a convenient and efficient manner Prevents interfering with proper operation of a system A program running at all times (kernel), with all else being application programs Provides convenience, efficiency (of using resource), throughput (tasks per unit time) Supports developing new system functions without interfering with the system Responsibilities Execution of processes (management, scheduling, synchronization) Allocation of resources & services (memory, processors, devices, data) Management of resources (CPU, memory, files) Characteristics Device Management: Tracks all devices, and decides which process gets access, when & for how much time Processor Management: Allocates processor to process and de-allocates when no longer required or job is done Memory Management: Tracks & allocates primary memory Storage Management: Stores data in various tracks of hard drive File Management: Allocates & de-allocates resources System Performance: Records delays between requests of a service and the system Job Accounting: Tracks time & resources used by various jobs Error Detection & Debugging: Dumps, traces, error messages, etc. Security management: Prevents unauthorized access by applications & users Compiles & translates high level language to machine language Provides loader to move compiled code to memory for execution Provide routines that handles details of I/O programming Computer System User Interface: Users, application programs System: Utilities, system programs (compilers, loaders, editors), OS Extended Machine: Context save, dispatching, swapping, I/O initiation Hardware: Machine language, micro-programming, CPU, memory, devices Drivers for Hardware I/O I/O traffic controller keeps track of status of devices Each device has a handler that resides in a separate process associated with that device It has memory management that includes buffering, caching, spooling and a device driver interface Assemblers Converts an assembly code to object/machine code & instructions required by loader Compiler Converts all the given high level code to machine code and then executes Examples: C, C++, Rust, Go Interpreter Converts high level code to machine code line by line and simultaneously executes it Examples: Python, Ruby Loader A routine that loads an object/machine program in memory and prepares for execution Components of OS Shell Outermost layer that handles user interaction Kernel Core component that provides services to other components Primary interface between OS & hardware that manages system resources Addresses low level functions I/O management, device drivers, memory management, application management System calls, process & cpu scheduling Types of OS Batch Groups jobs into batches based on similar requirements For example, payroll & bank systems Single Tasking Multi Programming Can execute multiple programs in main memory Multi Tasking Mult-programming OS having round robin scheduling Preemptive: OS can interrupt and switch to another process Cooperative: OS never interrupts to switch to another process Multi Processing Multiple CPUs are used for execution Time Sharing Each task is given some time to execute Processor's time is shared among multiple users Switching jobs is very fast Distributed Multiple computers connected via high-speed buses and share resources Centralized OS over multiple networks that uses single communication channel Network Independent systems connected over a single network and share resources Real Time Processes data and events that have critically defined time contraints Provides ultra-fast performance Memory Primary Memory: RAM & ROM RAM (Random Access Memory) Main memory or read-write memory Temporarily stores the data that's currently being used or processed Volatile Memory: Data is lost when power is turned off Faster than ROM & Consumes less power than secondary memory Data can be accessed and edited quickly ROM (Read Only Memory) Permanently stored memory Non-Volatile Memory Data cannot be modified easily Used to stored: BIOS (Basic Input/Output System), firmwares for hardware devices Used in embedded systems, calculators, peripheral devices Consumes less power than secondary memory Secondary Memory: Hard-drive, SSD, USB CPU Registers A CPU register stores memory addresses, which is how a processor accesses data from RAM One bit in a register can reference an individual byte in memory Based on how much memory can be accessed by a CPU register, there are 32-bit & 64-bit processors 32-bit Can access 2^32 memory addresses (4 GB of RAM or physical memory) For more than 4 GB of RAM, the system should be 64-bit 64-bit Can access 2^64 memory addresses (17 * 10^9 GB of RAM or physical memory) System Startup BIOS (Basic Input Output System) Initialization BIOS is loaded from ROM and initialises POST POST (Power On Self Test) Initializes hardware devices, runs checks and handles bootable device Bootloader BIOS searches for Master Boot Record (MBR) in 1st sector. MBR contains the code that loads OS called bootloader (LILO, GRUB in Linux) Bootloader is pulled into memory and started Bootloader loads OS in memory Kernel OS starts running and initializes hardware drivers, and then launches kernel Kernel starts the init system Init Determines the run-level of the system (single user, multi user with network, without network, etc) Starts services daemons that support networking, display, devices (keyboard, mouse) UEFI (Unified Extensible Firmware Interface) Initialization Doesn't look for MBR Maintains a list of valid boot volumes called EFI service partitions POST UEFI scans all of the bootable storage devices for GUID Partition Table (GPT) GPT is an improvement over MBR GPT Doesn't contain boot loader UEFI scans GPT for EFI service partition to boot from Directly loads OS from the right partition If it fails, goes to BIOS type booting called legacy boot (backward compatible) BIOS vs UEFI BIOS runs in 16-bit mode, UEFI runs in 32-bit & 64-bit mode BIOS only supports drives less than 2TB, UEFI has much higher limit UEFI comes with improved boot times, efficient power management, and support for larger hard drives & partitions BIOS is stored in ROM, UEFI is stored in non-volatile memory on motherboard BIOS loads OS from bootloader, UEFI directly loads OS from hard drive","title":"Introduction"},{"location":"operating_system/introduction#introduction","text":"Interface between users and hardware Provides an environment to execute programs in a convenient and efficient manner Prevents interfering with proper operation of a system A program running at all times (kernel), with all else being application programs Provides convenience, efficiency (of using resource), throughput (tasks per unit time) Supports developing new system functions without interfering with the system","title":"Introduction"},{"location":"operating_system/introduction#responsibilities","text":"Execution of processes (management, scheduling, synchronization) Allocation of resources & services (memory, processors, devices, data) Management of resources (CPU, memory, files)","title":"Responsibilities"},{"location":"operating_system/introduction#characteristics","text":"Device Management: Tracks all devices, and decides which process gets access, when & for how much time Processor Management: Allocates processor to process and de-allocates when no longer required or job is done Memory Management: Tracks & allocates primary memory Storage Management: Stores data in various tracks of hard drive File Management: Allocates & de-allocates resources System Performance: Records delays between requests of a service and the system Job Accounting: Tracks time & resources used by various jobs Error Detection & Debugging: Dumps, traces, error messages, etc. Security management: Prevents unauthorized access by applications & users Compiles & translates high level language to machine language Provides loader to move compiled code to memory for execution Provide routines that handles details of I/O programming","title":"Characteristics"},{"location":"operating_system/introduction#computer-system","text":"User Interface: Users, application programs System: Utilities, system programs (compilers, loaders, editors), OS Extended Machine: Context save, dispatching, swapping, I/O initiation Hardware: Machine language, micro-programming, CPU, memory, devices","title":"Computer System"},{"location":"operating_system/introduction#drivers-for-hardware","text":"I/O I/O traffic controller keeps track of status of devices Each device has a handler that resides in a separate process associated with that device It has memory management that includes buffering, caching, spooling and a device driver interface Assemblers Converts an assembly code to object/machine code & instructions required by loader Compiler Converts all the given high level code to machine code and then executes Examples: C, C++, Rust, Go Interpreter Converts high level code to machine code line by line and simultaneously executes it Examples: Python, Ruby Loader A routine that loads an object/machine program in memory and prepares for execution","title":"Drivers for Hardware"},{"location":"operating_system/introduction#components-of-os","text":"Shell Outermost layer that handles user interaction Kernel Core component that provides services to other components Primary interface between OS & hardware that manages system resources Addresses low level functions I/O management, device drivers, memory management, application management System calls, process & cpu scheduling","title":"Components of OS"},{"location":"operating_system/introduction#types-of-os","text":"Batch Groups jobs into batches based on similar requirements For example, payroll & bank systems Single Tasking Multi Programming Can execute multiple programs in main memory Multi Tasking Mult-programming OS having round robin scheduling Preemptive: OS can interrupt and switch to another process Cooperative: OS never interrupts to switch to another process Multi Processing Multiple CPUs are used for execution Time Sharing Each task is given some time to execute Processor's time is shared among multiple users Switching jobs is very fast Distributed Multiple computers connected via high-speed buses and share resources Centralized OS over multiple networks that uses single communication channel Network Independent systems connected over a single network and share resources Real Time Processes data and events that have critically defined time contraints Provides ultra-fast performance","title":"Types of OS"},{"location":"operating_system/introduction#memory","text":"","title":"Memory"},{"location":"operating_system/introduction#primary-memory-ram-rom","text":"RAM (Random Access Memory) Main memory or read-write memory Temporarily stores the data that's currently being used or processed Volatile Memory: Data is lost when power is turned off Faster than ROM & Consumes less power than secondary memory Data can be accessed and edited quickly ROM (Read Only Memory) Permanently stored memory Non-Volatile Memory Data cannot be modified easily Used to stored: BIOS (Basic Input/Output System), firmwares for hardware devices Used in embedded systems, calculators, peripheral devices Consumes less power than secondary memory","title":"Primary Memory: RAM &amp; ROM"},{"location":"operating_system/introduction#secondary-memory-hard-drive-ssd-usb","text":"","title":"Secondary Memory: Hard-drive, SSD, USB"},{"location":"operating_system/introduction#cpu-registers","text":"A CPU register stores memory addresses, which is how a processor accesses data from RAM One bit in a register can reference an individual byte in memory Based on how much memory can be accessed by a CPU register, there are 32-bit & 64-bit processors 32-bit Can access 2^32 memory addresses (4 GB of RAM or physical memory) For more than 4 GB of RAM, the system should be 64-bit 64-bit Can access 2^64 memory addresses (17 * 10^9 GB of RAM or physical memory)","title":"CPU Registers"},{"location":"operating_system/introduction#system-startup","text":"","title":"System Startup"},{"location":"operating_system/introduction#bios-basic-input-output-system","text":"Initialization BIOS is loaded from ROM and initialises POST POST (Power On Self Test) Initializes hardware devices, runs checks and handles bootable device Bootloader BIOS searches for Master Boot Record (MBR) in 1st sector. MBR contains the code that loads OS called bootloader (LILO, GRUB in Linux) Bootloader is pulled into memory and started Bootloader loads OS in memory Kernel OS starts running and initializes hardware drivers, and then launches kernel Kernel starts the init system Init Determines the run-level of the system (single user, multi user with network, without network, etc) Starts services daemons that support networking, display, devices (keyboard, mouse)","title":"BIOS (Basic Input Output System)"},{"location":"operating_system/introduction#uefi-unified-extensible-firmware-interface","text":"Initialization Doesn't look for MBR Maintains a list of valid boot volumes called EFI service partitions POST UEFI scans all of the bootable storage devices for GUID Partition Table (GPT) GPT is an improvement over MBR GPT Doesn't contain boot loader UEFI scans GPT for EFI service partition to boot from Directly loads OS from the right partition If it fails, goes to BIOS type booting called legacy boot (backward compatible)","title":"UEFI (Unified Extensible Firmware Interface)"},{"location":"operating_system/introduction#bios-vs-uefi","text":"BIOS runs in 16-bit mode, UEFI runs in 32-bit & 64-bit mode BIOS only supports drives less than 2TB, UEFI has much higher limit UEFI comes with improved boot times, efficient power management, and support for larger hard drives & partitions BIOS is stored in ROM, UEFI is stored in non-volatile memory on motherboard BIOS loads OS from bootloader, UEFI directly loads OS from hard drive","title":"BIOS vs UEFI"},{"location":"operating_system/system_structure","text":"System Structure Kernel Operations Kernel mode (mode bit 0) CPU can execute certain instructions only in kernel mode (privilege instructions) Privilege instructions usually peform operations that required direct access to hardware or privileged resources Example: setting up memory mapping, accessing I/O devices, remove a process from memory Context Switch User mode (mode bit 1) Prevents user program from interfering with OS program Non privileged instructions Performing computations, accessing user-level resources like files & memory, managing process control Concept of modes can be extended beyond two Requires more than a single bit mode CPU that support virtualization One of these extra bits is used to indicate when virtual machine manager (VMM) is in control VMM has more privileges than user program but not so many as full kernel System call Programmatic way for a program to request a service from kernel Program is temporarily switched from user mode to kernel mode Implemented in the form of software interrupts Which causes hardware's interrupt handler to transfer control to an appropriate interrupt handler (part of OS) And switches the bit mode to kernel mode Interrupt handler Checks which interrupt was generated and additional parameters (passed through registers) Then calls appropriate kernel service routine to handle the service requested by service call Illegal instuctions are trapped and control is transferred to OS to issue error message & log Monolithic Kernel All OS services run in kernel space and share the same memory space Faster than micro-kernel due to direct calls & same memory space If any service fails, it leads to entire system failure Structure Application (Outside Kernel) VFS, System calls IPC, File System Scheduler, Virtual Memory Device driver, Dispatcher Hardware (Outside Kernel) Micro-Kernel Provides only the most basic services (memory management, process scheduling) Reduces the attack surface making it more secure & stable Other services (device drivers, file systems) are implemented as user level processes They communicate with kernel using message passing rather than shared memory Easier to add or remove services making it more modular & flexible but can increase complexity Message passing can be slower than direct system calls in monolithic kernel Kernel I/O Subsystem Services provided: scheduling, caching, spooling, device reservation, error handling I/O Scheduling Each device has a wait queue for requests When an application issues a blocking I/O system call, it's placed in the queue of the device I/O scheduler rearranges the order to improve the efficiency Buffering Memory area that stores data being transferred between devices or a device & an application Copes with speed mismatch between producer & consumer Provides adaptation for data with different data-transfer sizes Supports copy semantic for the application I/O Copy semantic If an application wants to write data from buffer to a disc It calls write() system call providing pointer to the buffer And an integer specifying number of bytes to write Caching Fast memory that holds a copy of data for faster access Spooling A buffer that holds the output of a device that cannot accept interleaved data streams For example, a printer where several applications send output concurrently Without mixing their outputs","title":"System Structure"},{"location":"operating_system/system_structure#system-structure","text":"","title":"System Structure"},{"location":"operating_system/system_structure#kernel-operations","text":"Kernel mode (mode bit 0) CPU can execute certain instructions only in kernel mode (privilege instructions) Privilege instructions usually peform operations that required direct access to hardware or privileged resources Example: setting up memory mapping, accessing I/O devices, remove a process from memory Context Switch User mode (mode bit 1) Prevents user program from interfering with OS program Non privileged instructions Performing computations, accessing user-level resources like files & memory, managing process control Concept of modes can be extended beyond two Requires more than a single bit mode CPU that support virtualization One of these extra bits is used to indicate when virtual machine manager (VMM) is in control VMM has more privileges than user program but not so many as full kernel","title":"Kernel Operations"},{"location":"operating_system/system_structure#system-call","text":"Programmatic way for a program to request a service from kernel Program is temporarily switched from user mode to kernel mode Implemented in the form of software interrupts Which causes hardware's interrupt handler to transfer control to an appropriate interrupt handler (part of OS) And switches the bit mode to kernel mode Interrupt handler Checks which interrupt was generated and additional parameters (passed through registers) Then calls appropriate kernel service routine to handle the service requested by service call Illegal instuctions are trapped and control is transferred to OS to issue error message & log","title":"System call"},{"location":"operating_system/system_structure#monolithic-kernel","text":"All OS services run in kernel space and share the same memory space Faster than micro-kernel due to direct calls & same memory space If any service fails, it leads to entire system failure Structure Application (Outside Kernel) VFS, System calls IPC, File System Scheduler, Virtual Memory Device driver, Dispatcher Hardware (Outside Kernel)","title":"Monolithic Kernel"},{"location":"operating_system/system_structure#micro-kernel","text":"Provides only the most basic services (memory management, process scheduling) Reduces the attack surface making it more secure & stable Other services (device drivers, file systems) are implemented as user level processes They communicate with kernel using message passing rather than shared memory Easier to add or remove services making it more modular & flexible but can increase complexity Message passing can be slower than direct system calls in monolithic kernel","title":"Micro-Kernel"},{"location":"operating_system/system_structure#kernel-io-subsystem","text":"Services provided: scheduling, caching, spooling, device reservation, error handling I/O Scheduling Each device has a wait queue for requests When an application issues a blocking I/O system call, it's placed in the queue of the device I/O scheduler rearranges the order to improve the efficiency Buffering Memory area that stores data being transferred between devices or a device & an application Copes with speed mismatch between producer & consumer Provides adaptation for data with different data-transfer sizes Supports copy semantic for the application I/O Copy semantic If an application wants to write data from buffer to a disc It calls write() system call providing pointer to the buffer And an integer specifying number of bytes to write Caching Fast memory that holds a copy of data for faster access Spooling A buffer that holds the output of a device that cannot accept interleaved data streams For example, a printer where several applications send output concurrently Without mixing their outputs","title":"Kernel I/O Subsystem"},{"location":"operating_system/process_management","text":"Process Management Program: Collection of instructions that performs a specific task when executed by a computer Process Program in execution with allocated time and resources Can have multiple dynamic instances of the program in execution Process sections Stack: Temporary data like function parameters, return addresses, local variables Heap: Dynamically alloted memory to process during its run time, stores functions Text: Current activity represented by program counter, contents of processor registers Data: Global and static variables Process groups: parent, children, fork, exec, merge Process States OS maintains separate queue of PCB for each state New: Process being created in secondary memory Ready: After creation, process is loaded in main memory and marked ready for execution Run: Currently running in CPU Wait (or Block): Requesting access for I/O or critical region Complete (or Terminated): Execution completed and PCB deleted, allocated resources will be released Suspended Ready: Ready process swapped out of main memory, usually when ready queue is full Suspended Wait: Wait process swapped out of main memory, usually when wait queue is full States for Systems Single Tasking Systems: not running, running Multi-programming Systems: ready, running, wait 5-States Model (general): new, ready, running, wait, terminated 7-States Model: new, ready, running, wait, terminated, suspend ready, suspend wait Context Switching Saving context of one process into PCB and loading context of another process Unloaded process is marked from running to ready It happens when High priority task comes to ready state Interrupt occurs Sometimes when user & kernel mode switch If another process carries out privileged instructions Preemptive CPU scheduling CPU vs I/O Bound CPU bound process: Requires more CPU time (spends more time in running state) I/O bound process: Requires more I/O time (spends more time in waiting state) Process Control Block (PCB) Pointer: Retains current position when switched from one state to another Process state PID PC (Program counter): Pointer to next instruction CPU registers: Current working variables CPU scheduling info: Privileges, priority Memory management info: Page table, memory limits, segment table Accounting info: CPU usage, time limits, execution ID IO status","title":"Process Management"},{"location":"operating_system/process_management#process-management","text":"Program: Collection of instructions that performs a specific task when executed by a computer Process Program in execution with allocated time and resources Can have multiple dynamic instances of the program in execution Process sections Stack: Temporary data like function parameters, return addresses, local variables Heap: Dynamically alloted memory to process during its run time, stores functions Text: Current activity represented by program counter, contents of processor registers Data: Global and static variables Process groups: parent, children, fork, exec, merge","title":"Process Management"},{"location":"operating_system/process_management#process-states","text":"OS maintains separate queue of PCB for each state New: Process being created in secondary memory Ready: After creation, process is loaded in main memory and marked ready for execution Run: Currently running in CPU Wait (or Block): Requesting access for I/O or critical region Complete (or Terminated): Execution completed and PCB deleted, allocated resources will be released Suspended Ready: Ready process swapped out of main memory, usually when ready queue is full Suspended Wait: Wait process swapped out of main memory, usually when wait queue is full","title":"Process States"},{"location":"operating_system/process_management#states-for-systems","text":"Single Tasking Systems: not running, running Multi-programming Systems: ready, running, wait 5-States Model (general): new, ready, running, wait, terminated 7-States Model: new, ready, running, wait, terminated, suspend ready, suspend wait","title":"States for Systems"},{"location":"operating_system/process_management#context-switching","text":"Saving context of one process into PCB and loading context of another process Unloaded process is marked from running to ready It happens when High priority task comes to ready state Interrupt occurs Sometimes when user & kernel mode switch If another process carries out privileged instructions Preemptive CPU scheduling","title":"Context Switching"},{"location":"operating_system/process_management#cpu-vs-io-bound","text":"CPU bound process: Requires more CPU time (spends more time in running state) I/O bound process: Requires more I/O time (spends more time in waiting state)","title":"CPU vs I/O Bound"},{"location":"operating_system/process_management#process-control-block-pcb","text":"Pointer: Retains current position when switched from one state to another Process state PID PC (Program counter): Pointer to next instruction CPU registers: Current working variables CPU scheduling info: Privileges, priority Memory management info: Page table, memory limits, segment table Accounting info: CPU usage, time limits, execution ID IO status","title":"Process Control Block (PCB)"},{"location":"operating_system/process_scheduling","text":"Process Scheduling Timings Arrival Time: At which arrives in ready queue Completion Time: At which execution is completed Burst Time: Required for CPU execution Turnaround time: Arrival to Completion Waiting time: Time spent in ready queue waiting (Turnaround - Burst) Response time: Submission to first response Throughput: Number of processes that complete execution per unit time Objectives Maximum utilization of CPU (percentage in use) Fair allocation of CPU Maximum throughput Minimum turnaround time Minimum waiting time and avoid starvation Minimum response time Categories Non-preemptive Process is removed from CPU only when it has finished execution or switches to wait state High throughput rate Bugs can freeze up the system Wastes CPU time while the process is interacting with I/O Preemptive Process runs for a limited amount of time in CPU and then switched Better average response time Avoids starvation Overhead of more context switching Schedulers Long Term (Job Scheduler) Which process should be brought in ready queue How many processes should be kept in ready state (decides degree of multi-programming) Maintains balance between CPU bound & I/O bound processes Once a decision is taken, it lasts for a long time Short Term (CPU Scheduler) Which process should be executed next (scheduling algorithms are used) Calls dispatcher Runs frequently Medium Term (Swapping Scheduler) Used for swapping (moving process from main to secondary memory & vice versa) Reduces degree of multiprogramming Dispatcher Module that gives control of CPU to the process selected by scheduler Responsible for moving process from ready to run state & vice versa Takes care of switching context, switching to user mode, jumping to proper location in user pogram Convoy Effect Few slow processes slow down the entire system Solution: preemptive algorithms Example I/O bound process runs in CPU and moves to I/O CPU bound process runs in CPU I/O bound process moves to CPU & waits for CPU bound process CPU bound process runs to I/O I/O bound process moves to I/O & waits for CPU bound process Priority Inversion Happens when a high priority task ends up waiting for a low priority task Example We have 3 tasks defined by priority: L (Low), M (Medium), H (High) H is waiting on L for I/O So M will run first, then L, and then finally H Priority Inheritance Process holding the shared resource inherits the priority of highest priority process waiting for it This is done only till the lock is released So L will run first, then H, and then finally M Algorithms First Come First Serve (FCFS) Also known as First In First out (FIFO) Waiting time is high Convoy effect can happen (Few slow processes slow down the entire system) Used by other algorithms in case of conflict Shortest Job First (SJF) Burst time can't be known in advance but can be approximated Process size Process type OS process: compiler, program manager User process: editors, utility software Interactive process: which have high I/O frequency Can approximate by averaging last run-times Minimum waiting time among all algorithms Starvation can happen if short jobs keep coming Starvation can be solved using ageing, but defining ageing rate can be challenging Preemptive version: Shortest Remaining Time First (SRTF) Longest Job First (LJF) May lead to convoy effect due to high average waiting time & average turnaround time Preemptive version: Longest Remaining Job First (LRJF) Priority Scheduling If a higher priority process comes, current process is suspended May lead to starvation (Can be solved using ageing or dynamic priority) Priority inversion can happen (Low priority process holds a resource required by high priority process) Inversion avoidance techniques (priority inheritance, priority ceiling protocals) can make it more complicated Round Robin (RR) Preemptive version of FCFS Fixed time slots/quantum/slice over all the processes in a circular fashion High response time for high time quantum High context switch overhead for low time quantum High wait time and reduced throughput depending on time quantum Deciding perfect time quantum is a task Selfish Round Robin (SRR) Round robin that give better service to existing processes than the new ones Processes in ready list are partitioned into: New and Accepted Priority of new processes increases at rate 'a' and that of accepted processes increases at rate 'b' When priority of a new process reaches that of an accepted process, it becomes an accepted process Poor response time and priority handling High Response Ratio Next (HRRN) Modification of SJF to reduce starvation Response Ratio = (Waiting Time + Burst Time) / Burst Time Multilevel Queue Divides the ready queue into several separate queues (having their own priority) Different types of processes are queued based on their priority Each queue uses its own scheduling algorithm Starvation may happen Example: System Processes: CPU itself has its processes Interactive Processes: Processes with the same type of interaction Batch Processes: Collecting similar programs in a batch before executing Multilevel Queue Scheduling with Feedback Allows processes to move between queues More CPU overhead and complexity Useful because burst time approximation may become more accurate later","title":"Process Scheduling"},{"location":"operating_system/process_scheduling#process-scheduling","text":"","title":"Process Scheduling"},{"location":"operating_system/process_scheduling#timings","text":"Arrival Time: At which arrives in ready queue Completion Time: At which execution is completed Burst Time: Required for CPU execution Turnaround time: Arrival to Completion Waiting time: Time spent in ready queue waiting (Turnaround - Burst) Response time: Submission to first response Throughput: Number of processes that complete execution per unit time","title":"Timings"},{"location":"operating_system/process_scheduling#objectives","text":"Maximum utilization of CPU (percentage in use) Fair allocation of CPU Maximum throughput Minimum turnaround time Minimum waiting time and avoid starvation Minimum response time","title":"Objectives"},{"location":"operating_system/process_scheduling#categories","text":"Non-preemptive Process is removed from CPU only when it has finished execution or switches to wait state High throughput rate Bugs can freeze up the system Wastes CPU time while the process is interacting with I/O Preemptive Process runs for a limited amount of time in CPU and then switched Better average response time Avoids starvation Overhead of more context switching","title":"Categories"},{"location":"operating_system/process_scheduling#schedulers","text":"Long Term (Job Scheduler) Which process should be brought in ready queue How many processes should be kept in ready state (decides degree of multi-programming) Maintains balance between CPU bound & I/O bound processes Once a decision is taken, it lasts for a long time Short Term (CPU Scheduler) Which process should be executed next (scheduling algorithms are used) Calls dispatcher Runs frequently Medium Term (Swapping Scheduler) Used for swapping (moving process from main to secondary memory & vice versa) Reduces degree of multiprogramming","title":"Schedulers"},{"location":"operating_system/process_scheduling#dispatcher","text":"Module that gives control of CPU to the process selected by scheduler Responsible for moving process from ready to run state & vice versa Takes care of switching context, switching to user mode, jumping to proper location in user pogram","title":"Dispatcher"},{"location":"operating_system/process_scheduling#convoy-effect","text":"Few slow processes slow down the entire system Solution: preemptive algorithms Example I/O bound process runs in CPU and moves to I/O CPU bound process runs in CPU I/O bound process moves to CPU & waits for CPU bound process CPU bound process runs to I/O I/O bound process moves to I/O & waits for CPU bound process","title":"Convoy Effect"},{"location":"operating_system/process_scheduling#priority-inversion","text":"Happens when a high priority task ends up waiting for a low priority task Example We have 3 tasks defined by priority: L (Low), M (Medium), H (High) H is waiting on L for I/O So M will run first, then L, and then finally H Priority Inheritance Process holding the shared resource inherits the priority of highest priority process waiting for it This is done only till the lock is released So L will run first, then H, and then finally M","title":"Priority Inversion"},{"location":"operating_system/process_scheduling#algorithms","text":"","title":"Algorithms"},{"location":"operating_system/process_scheduling#first-come-first-serve-fcfs","text":"Also known as First In First out (FIFO) Waiting time is high Convoy effect can happen (Few slow processes slow down the entire system) Used by other algorithms in case of conflict","title":"First Come First Serve (FCFS)"},{"location":"operating_system/process_scheduling#shortest-job-first-sjf","text":"Burst time can't be known in advance but can be approximated Process size Process type OS process: compiler, program manager User process: editors, utility software Interactive process: which have high I/O frequency Can approximate by averaging last run-times Minimum waiting time among all algorithms Starvation can happen if short jobs keep coming Starvation can be solved using ageing, but defining ageing rate can be challenging Preemptive version: Shortest Remaining Time First (SRTF)","title":"Shortest Job First (SJF)"},{"location":"operating_system/process_scheduling#longest-job-first-ljf","text":"May lead to convoy effect due to high average waiting time & average turnaround time Preemptive version: Longest Remaining Job First (LRJF)","title":"Longest Job First (LJF)"},{"location":"operating_system/process_scheduling#priority-scheduling","text":"If a higher priority process comes, current process is suspended May lead to starvation (Can be solved using ageing or dynamic priority) Priority inversion can happen (Low priority process holds a resource required by high priority process) Inversion avoidance techniques (priority inheritance, priority ceiling protocals) can make it more complicated","title":"Priority Scheduling"},{"location":"operating_system/process_scheduling#round-robin-rr","text":"Preemptive version of FCFS Fixed time slots/quantum/slice over all the processes in a circular fashion High response time for high time quantum High context switch overhead for low time quantum High wait time and reduced throughput depending on time quantum Deciding perfect time quantum is a task","title":"Round Robin (RR)"},{"location":"operating_system/process_scheduling#selfish-round-robin-srr","text":"Round robin that give better service to existing processes than the new ones Processes in ready list are partitioned into: New and Accepted Priority of new processes increases at rate 'a' and that of accepted processes increases at rate 'b' When priority of a new process reaches that of an accepted process, it becomes an accepted process Poor response time and priority handling","title":"Selfish Round Robin (SRR)"},{"location":"operating_system/process_scheduling#high-response-ratio-next-hrrn","text":"Modification of SJF to reduce starvation Response Ratio = (Waiting Time + Burst Time) / Burst Time","title":"High Response Ratio Next (HRRN)"},{"location":"operating_system/process_scheduling#multilevel-queue","text":"Divides the ready queue into several separate queues (having their own priority) Different types of processes are queued based on their priority Each queue uses its own scheduling algorithm Starvation may happen Example: System Processes: CPU itself has its processes Interactive Processes: Processes with the same type of interaction Batch Processes: Collecting similar programs in a batch before executing","title":"Multilevel Queue"},{"location":"operating_system/process_scheduling#multilevel-queue-scheduling-with-feedback","text":"Allows processes to move between queues More CPU overhead and complexity Useful because burst time approximation may become more accurate later","title":"Multilevel Queue Scheduling with Feedback"},{"location":"operating_system/process_synchronization","text":"Process Synchronization Communication/Coordination/Concurrency control Coordination of execution of multiple processes that use shared resources Ensures that shared resources are accessed in a controlled and predictable manner Resolves the problem of race condition, inconsistency, deadlocks Process types based on synchronization Independent: Execution does not affect other processes Cooperative: Execution affects other processes Goals Avoid race conditions Achieve rules for critical section Performance IPC (Inter Process Communication) Mechanism through which processes can communicate with each other and synchronize their actions Communication mediums: Shared memory, Message passing Communication Methods Pipes Unidirectional (similar to keyboard) Data is usually buffered till it's processed by receiver Message Queuing Used to send & receive messages between processes Messages are coordinated via API Semaphores Controls access to shared resource and avoids race condition Shared memory Interchange of data through a defined area of memory Sockets Network communication between processes running on different hosts Allows for system independent connection Each endpoint of a communication is a socket Concatenation of IP address and port Remote Procedural Calls (RPC) Used for distributed computing Allows processes on different hosts to call procedures on each other Program allows a procedure to execute on different address space Primary client-server is implied Remote process maintains a server component Client processes send messages and get the output When making a RPC call The calling environment is suspended and procedure parameters are transferred across the network Procedure is executed on the target environment After execution, the results are transferred back to the calling environment Execution resumes in the calling environment as if returning from a regular procedure call Shared Memory A process generates info and keeps it as a record in shared memory Other processes can check this record and use the info Example: Producer-Consumer problem where producer puts items in a common buffer and consumer picks them up Message Passing Establish a communication link and exchange messages using basic primitives At least two primitives are required: send & receive Message size can be fixed (easy for OS designer) or variable (easy for programmer) Message structure Header Message type & length Source & destination Control info: priority, sequence number, instructions if it runs out of buffer space Body Example: Producer-Consumer problem where producer sends item as message to consumer Communication Link Capacity: Maximum number of messages that can reside in the queue Can be zero, bounded, unbounded Direct Link A specific process identifier is used for communication It is hard to identify the sender ahead of time Indirect Link A shared mailbox/port is used which consists of queue Sender puts the message in the mailbox and reciever picks them up Multiple communication links with different types can be established between any two processes Communication Types Synchronous/Blocking passing where the message is processed right away Asynchronous/Non-blocking passing where the message kept in wait & processed when the process becomes free For a sender Async passing is preferred so that it doesn't have to wait and can carry out other tasks However, an acknowledgement from receiver is necessary in case it fails For a receiver Sync passing is preferred so that it can send the return data or error message right away Messages can keep failing if the error is not communicated to the sender Race Condition When multiple processes try to access a shared resource (same code, same memory, same variable) They are racing each other to access the resource The output of the shared resource can be wrong for these processes due to lack of clarity The order of these processes may be important to get the final output Program sections Entry Section: Decides the entry of a particular process Critical Section: Only one process is allowed to enter and access or modify shared variable Exit Section: Allows other processes waiting in entry section to enter CS Remainder Section: Everything else Critical Section Regions of program that access shared resources and may cause race condition It must be executed as an atomic operation Rules Mutual Exclusion Only one process is allowed to run in CS at a time Progress If no process is running in CS Processes not in their remainder section should decide which process will enter its CS next This should happen in a finite time and other processes should not wait indefinitely Bounded Waiting After a process has made a request, there must be a limit for other processes to enter CS A process shouldn't wait endlessly for access Problems Deadlock: When multiple processes wait for each other to release CS Starvation: When a process or thread is prevented repeatedly from entering CS Overhead: Acquiring & releasing locks or semaphores Impacts Scalability: CS becomes a bottleneck for scalability since access to shared resource is restricted Solutions Three important criterias Correctness Maximum concurrency No busy waits: Prefer blocking over busy waits Hardware Approach Software Approach Hardware Solutions Disabling Interrupts When interrupts are disabled, no process is allowed to perform context switch As a result, it will allow only one process to enter CS Nothing can stop the process from doing its work As OS only switches processes when it gets an interrupt from the clock The CS can't be split between time slices Problems Catastrophic if a process fails to enable its interrupts again Effectively halting the CPU to let the program do everything Ineffective in a multiprocessor system Where disabling interrupts only seizes the processor that executes the instructions Test and Set Lock operation (TSL) Boolean value which is atomic in nature, i.e. no other interrupt is allowed to access Single instruction to load value of lock in register and set it to 1 Provides mutual exclusion and progress but not bounded waiting Priority inversion If process gets pre-empted from CS and leaves the lock, no other process can enter (spin lock) Busy Waiting Compare and swap operation Similar to test & set, but matches the passed value with the expected value","title":"Process Synchronization"},{"location":"operating_system/process_synchronization#process-synchronization","text":"Communication/Coordination/Concurrency control Coordination of execution of multiple processes that use shared resources Ensures that shared resources are accessed in a controlled and predictable manner Resolves the problem of race condition, inconsistency, deadlocks Process types based on synchronization Independent: Execution does not affect other processes Cooperative: Execution affects other processes Goals Avoid race conditions Achieve rules for critical section Performance","title":"Process Synchronization"},{"location":"operating_system/process_synchronization#ipc-inter-process-communication","text":"Mechanism through which processes can communicate with each other and synchronize their actions Communication mediums: Shared memory, Message passing","title":"IPC (Inter Process Communication)"},{"location":"operating_system/process_synchronization#communication-methods","text":"Pipes Unidirectional (similar to keyboard) Data is usually buffered till it's processed by receiver Message Queuing Used to send & receive messages between processes Messages are coordinated via API Semaphores Controls access to shared resource and avoids race condition Shared memory Interchange of data through a defined area of memory Sockets Network communication between processes running on different hosts Allows for system independent connection Each endpoint of a communication is a socket Concatenation of IP address and port Remote Procedural Calls (RPC) Used for distributed computing Allows processes on different hosts to call procedures on each other Program allows a procedure to execute on different address space Primary client-server is implied Remote process maintains a server component Client processes send messages and get the output When making a RPC call The calling environment is suspended and procedure parameters are transferred across the network Procedure is executed on the target environment After execution, the results are transferred back to the calling environment Execution resumes in the calling environment as if returning from a regular procedure call","title":"Communication Methods"},{"location":"operating_system/process_synchronization#shared-memory","text":"A process generates info and keeps it as a record in shared memory Other processes can check this record and use the info Example: Producer-Consumer problem where producer puts items in a common buffer and consumer picks them up","title":"Shared Memory"},{"location":"operating_system/process_synchronization#message-passing","text":"Establish a communication link and exchange messages using basic primitives At least two primitives are required: send & receive Message size can be fixed (easy for OS designer) or variable (easy for programmer) Message structure Header Message type & length Source & destination Control info: priority, sequence number, instructions if it runs out of buffer space Body Example: Producer-Consumer problem where producer sends item as message to consumer","title":"Message Passing"},{"location":"operating_system/process_synchronization#communication-link","text":"Capacity: Maximum number of messages that can reside in the queue Can be zero, bounded, unbounded Direct Link A specific process identifier is used for communication It is hard to identify the sender ahead of time Indirect Link A shared mailbox/port is used which consists of queue Sender puts the message in the mailbox and reciever picks them up Multiple communication links with different types can be established between any two processes","title":"Communication Link"},{"location":"operating_system/process_synchronization#communication-types","text":"Synchronous/Blocking passing where the message is processed right away Asynchronous/Non-blocking passing where the message kept in wait & processed when the process becomes free For a sender Async passing is preferred so that it doesn't have to wait and can carry out other tasks However, an acknowledgement from receiver is necessary in case it fails For a receiver Sync passing is preferred so that it can send the return data or error message right away Messages can keep failing if the error is not communicated to the sender","title":"Communication Types"},{"location":"operating_system/process_synchronization#race-condition","text":"When multiple processes try to access a shared resource (same code, same memory, same variable) They are racing each other to access the resource The output of the shared resource can be wrong for these processes due to lack of clarity The order of these processes may be important to get the final output","title":"Race Condition"},{"location":"operating_system/process_synchronization#program-sections","text":"Entry Section: Decides the entry of a particular process Critical Section: Only one process is allowed to enter and access or modify shared variable Exit Section: Allows other processes waiting in entry section to enter CS Remainder Section: Everything else","title":"Program sections"},{"location":"operating_system/process_synchronization#critical-section","text":"Regions of program that access shared resources and may cause race condition It must be executed as an atomic operation","title":"Critical Section"},{"location":"operating_system/process_synchronization#rules","text":"Mutual Exclusion Only one process is allowed to run in CS at a time Progress If no process is running in CS Processes not in their remainder section should decide which process will enter its CS next This should happen in a finite time and other processes should not wait indefinitely Bounded Waiting After a process has made a request, there must be a limit for other processes to enter CS A process shouldn't wait endlessly for access","title":"Rules"},{"location":"operating_system/process_synchronization#problems","text":"Deadlock: When multiple processes wait for each other to release CS Starvation: When a process or thread is prevented repeatedly from entering CS Overhead: Acquiring & releasing locks or semaphores Impacts Scalability: CS becomes a bottleneck for scalability since access to shared resource is restricted","title":"Problems"},{"location":"operating_system/process_synchronization#solutions","text":"Three important criterias Correctness Maximum concurrency No busy waits: Prefer blocking over busy waits Hardware Approach Software Approach","title":"Solutions"},{"location":"operating_system/process_synchronization#hardware-solutions","text":"","title":"Hardware Solutions"},{"location":"operating_system/process_synchronization#disabling-interrupts","text":"When interrupts are disabled, no process is allowed to perform context switch As a result, it will allow only one process to enter CS Nothing can stop the process from doing its work As OS only switches processes when it gets an interrupt from the clock The CS can't be split between time slices Problems Catastrophic if a process fails to enable its interrupts again Effectively halting the CPU to let the program do everything Ineffective in a multiprocessor system Where disabling interrupts only seizes the processor that executes the instructions","title":"Disabling Interrupts"},{"location":"operating_system/process_synchronization#test-and-set-lock-operation-tsl","text":"Boolean value which is atomic in nature, i.e. no other interrupt is allowed to access Single instruction to load value of lock in register and set it to 1 Provides mutual exclusion and progress but not bounded waiting Priority inversion If process gets pre-empted from CS and leaves the lock, no other process can enter (spin lock) Busy Waiting","title":"Test and Set Lock operation (TSL)"},{"location":"operating_system/process_synchronization#compare-and-swap-operation","text":"Similar to test & set, but matches the passed value with the expected value","title":"Compare and swap operation"},{"location":"operating_system/process_synchronization_solutions","text":"Process Synchronization Solutions Lock variable 0 means CS is vacant Process entering CS sets it 1 Doesn't provide mutual exclusion in some cases Busy Waiting while lock != 0: continue lock = 1 # Critical Section lock = 0 Peterson's Solution Have 2 shared variables bool flag[2]: Which processes wants to enter CS int turn: Whose turn is to enter CS Satisfies all CS conditions Involves busy waiting (Pi waiting for Pj): not preferred because it wastes CPU cycles Limited to 2 processes at a time Cannot be used in modern architecture with multiple CPUs while (True): # Pi wants to enter CS flag[i] = True # Give preference to Pj to avoid conflicts turn = j # Wait if Pj is executing while (flat[j] && turn == j): continue # Critical Section flag[i] = False # Remainder Section Dekker's Solution One of the first mutual exclusion algorithms. The latest revision satisfies all 3 conditions of CS. Uses shared memory for communication Have 2 shared variables bool flag[2]: Which processes wants to enter CS int turn: Whose turn is to enter CS Involves busy waiting (Pi waiting for Pj) Limited to 2 processes at a time Cannot be used in modern architecture with multiple CPUs while (True): # Pi wants to enter CS flag[i] = True # Wait if Pj is executing while flat[j]: if turn == j: flag[i] = False while turn == j: continue flag[i] = True # Critical Section turn = j flag[i] = False # Remainder Section Bakery Algorithm Follows first come first serve Each process is assigned a number (ticket) in lexicographical order The process with the smallest ticket enters CS If the ticket number is same, then lower PID is given preference No deadlock, no starvation Not scalable (overhead increases with number of processes) High time complexity, Memory overhead, Busy waiting while True: choosing_number[i] = True number[i] = max(number) + 1 choosing_number[i] = False for j in range(0, n): while choosing_number[j]: continue while number[j] != 0 and [number[j], j] < [number[i], i]: continue # Critical Section number[i] = 0 # Remainder Section Semaphore Signaling mechanism: A process waiting on a semaphore will be signaled by another process Stores available resources in a variable Types: Counting semaphore, Binary semaphore Uses two atomic operations Wait Decrements the value for semaphore The caller process will be blocked until another process performs a signal operation Signal Increments the value of semaphore Any process can release a resource by calling signal Limitations Priority inversion Deadlock Busy waiting: To solve maintain a waiting queue int semaphore = S # Maximum number of processes that can enter CS at this time def wait(semaphore): while semaphore <= 0: continue # Wait till CS is available semaphore -= 1 def signal(sempahore): semaphore += 1 # Process P wait(semaphore) # Critical Section signal(semaphore) # Remainder Section Mutex Mutual Exclusion Object Locking or ownership mechanism Unlike semaphore, it is not a variable but an object Operations Lock Unlock Only the process that has the lock can unlock the resource Can be used as Binary semaphore, but vice-versa is not true Priority inversion is solved by priority inheritance def lock(): while not available: continue available = False def unlock(): available = True # Process P lock() # Critical Section unlock() # Remainder Section Monitors A module that encapsulates a shared resource and provides access through a set of procedures Used to simplify implementation of concurrent programs by providing high level abstraction Provides mutual exclusion There are condition variables (with their own queues) on which wait and signal are performed Waiting processes are suspended and put in the queue of the condition variable Processes outside the monitor can't access internal variables but can call its procedures Eliminates the need for complex synchronization primitives like semaphores & mutex, but can be less efficient","title":"Process Synchronization Solutions"},{"location":"operating_system/process_synchronization_solutions#process-synchronization-solutions","text":"","title":"Process Synchronization Solutions"},{"location":"operating_system/process_synchronization_solutions#lock-variable","text":"0 means CS is vacant Process entering CS sets it 1 Doesn't provide mutual exclusion in some cases Busy Waiting while lock != 0: continue lock = 1 # Critical Section lock = 0","title":"Lock variable"},{"location":"operating_system/process_synchronization_solutions#petersons-solution","text":"Have 2 shared variables bool flag[2]: Which processes wants to enter CS int turn: Whose turn is to enter CS Satisfies all CS conditions Involves busy waiting (Pi waiting for Pj): not preferred because it wastes CPU cycles Limited to 2 processes at a time Cannot be used in modern architecture with multiple CPUs while (True): # Pi wants to enter CS flag[i] = True # Give preference to Pj to avoid conflicts turn = j # Wait if Pj is executing while (flat[j] && turn == j): continue # Critical Section flag[i] = False # Remainder Section","title":"Peterson's Solution"},{"location":"operating_system/process_synchronization_solutions#dekkers-solution","text":"One of the first mutual exclusion algorithms. The latest revision satisfies all 3 conditions of CS. Uses shared memory for communication Have 2 shared variables bool flag[2]: Which processes wants to enter CS int turn: Whose turn is to enter CS Involves busy waiting (Pi waiting for Pj) Limited to 2 processes at a time Cannot be used in modern architecture with multiple CPUs while (True): # Pi wants to enter CS flag[i] = True # Wait if Pj is executing while flat[j]: if turn == j: flag[i] = False while turn == j: continue flag[i] = True # Critical Section turn = j flag[i] = False # Remainder Section","title":"Dekker's Solution"},{"location":"operating_system/process_synchronization_solutions#bakery-algorithm","text":"Follows first come first serve Each process is assigned a number (ticket) in lexicographical order The process with the smallest ticket enters CS If the ticket number is same, then lower PID is given preference No deadlock, no starvation Not scalable (overhead increases with number of processes) High time complexity, Memory overhead, Busy waiting while True: choosing_number[i] = True number[i] = max(number) + 1 choosing_number[i] = False for j in range(0, n): while choosing_number[j]: continue while number[j] != 0 and [number[j], j] < [number[i], i]: continue # Critical Section number[i] = 0 # Remainder Section","title":"Bakery Algorithm"},{"location":"operating_system/process_synchronization_solutions#semaphore","text":"Signaling mechanism: A process waiting on a semaphore will be signaled by another process Stores available resources in a variable Types: Counting semaphore, Binary semaphore Uses two atomic operations Wait Decrements the value for semaphore The caller process will be blocked until another process performs a signal operation Signal Increments the value of semaphore Any process can release a resource by calling signal Limitations Priority inversion Deadlock Busy waiting: To solve maintain a waiting queue int semaphore = S # Maximum number of processes that can enter CS at this time def wait(semaphore): while semaphore <= 0: continue # Wait till CS is available semaphore -= 1 def signal(sempahore): semaphore += 1 # Process P wait(semaphore) # Critical Section signal(semaphore) # Remainder Section","title":"Semaphore"},{"location":"operating_system/process_synchronization_solutions#mutex","text":"Mutual Exclusion Object Locking or ownership mechanism Unlike semaphore, it is not a variable but an object Operations Lock Unlock Only the process that has the lock can unlock the resource Can be used as Binary semaphore, but vice-versa is not true Priority inversion is solved by priority inheritance def lock(): while not available: continue available = False def unlock(): available = True # Process P lock() # Critical Section unlock() # Remainder Section","title":"Mutex"},{"location":"operating_system/process_synchronization_solutions#monitors","text":"A module that encapsulates a shared resource and provides access through a set of procedures Used to simplify implementation of concurrent programs by providing high level abstraction Provides mutual exclusion There are condition variables (with their own queues) on which wait and signal are performed Waiting processes are suspended and put in the queue of the condition variable Processes outside the monitor can't access internal variables but can call its procedures Eliminates the need for complex synchronization primitives like semaphores & mutex, but can be less efficient","title":"Monitors"},{"location":"operating_system/process_synchronization_application","text":"Process Synchronization Application Producer Consumer Also known as Bounded Buffer Problem Details We have a buffer of fixed size Producer produces an item and puts it in the buffer Consumer consumes an item by picking up from the buffer Problems Both processes may try to update the buffer at the same time Which can lead to data loss & inconsistency Consumer might consume faster, so it might have to wait Producer might produce faster which can lead to buffer overflow There may be multiple producers & consumers, and same item may be processed multiple times Solution Use a mutex for locking & unlocking the buffer Use a semaphore for empty slots Use a semaphore for occupied slots Variations Unbounded buffer Sleep and wake Producer sleeps if consumer is not consuming Consumer sleeps if producer is not producing Each wake up the other when process starts Problem Producer starts when consumer was about to sleep Consumer will sleep and afterwards producer as consumer is not consuming def producer(): while True: wait(empty_slots) lock(buffer) # Put in buffer unlock(buffer) signal(occupied_slots) def consumer(): while True: wait(full_slots) lock(buffer) # Consume from buffer unlock(buffer) signal(occupied_slots) Dining Philosophers There is one chopstick/fork between two philosophers A philosopher can eat only if he picks up two chopsticks Deadlock will happen if all philosophers pick their left chopstick simultaneously. Solutions: Odd philosophers pick left chopstick first & even ones pick right chopstick first Both chopsticks should be available before picking up Solution Mutex to ensure that only one philosopher attempts to pick up a fork at a time One semaphore per philosopher One state per philosopher (thinking, hungry, or eating) def philosopher(index): while True: think(index) take_forks(index) eat(index) put_forks(index) def check(index): if state[index] == 'hungry' and state[left] != 'eating' and state[right] != 'eating': philosopher_semaphore[index].wait() state[index] = 'eating' def take_forks(index): mutex.lock() state[index] = 'hungry' check(index) mutex.unlock() def put_forks(index) mutex.lock() state[index] = 'thinking' check(left) check(right) mutex.unlock() philosopher_semaphore[index].signal() def think(index): time.sleep(random.randint(1, 5)) def eat(index): time.sleep(random.randint(1, 3)) Readers Writers A resource (e.g. file) shared between multiple users or processes Reading: Any number of readers can read the write_semaphore No one is allowed to write because the changes won't be visible to readers Writing: Only the writer is allowed access No one else can write or read because the changes won't be visible to others Solution Semaphore Semaphore to control write action to the write_semaphore Variable to track reader count Mutex to control edits to reader count Monitor Gives equal chance to both readers & writers If writer is active, readers queue up If readers are active, writers queue up Types: Reader is given preference, Writer is given preference, Both have equal preference def writer(): while True: wait(write_semaphore) # Write signal(write_semaphore) def reader(): while True: # Reader wants to enter wait(read_mutex) read_count += 1 # Disable writer access, readers are being preferred if read_count == 1: wait(write_semaphore) signal(read_mutex) # Reading # Reader wants to exit wait(read_mutex) read_count -= 1 # Enable writer access if read_count == 0: signal(write_semaphore) signal(read_mutex) Sleeping Barber Details There is one barber and a number of chairs for waiting customers Customers arrive at random times and take a chair if available to wait If no chairs are available, the customer leaves When the barber is finished with a customer, he picks up the next customer If there are no customers, the barber goes to sleep Solution Semaphore for the barber's chair Semaphore for the waiting chairs Mutex to update waiting chairs It can become complex if multiple barbers are employed def barber(): while True: barber_semaphore.wait() mutex.lock() if len(waiting_customers) > 0 customer = waiting_customers.pop(0) mutex.unlock() cut_hair() customer_semaphore.signal() else: mutex.unlock() def customer(index): mutex.lock() if len(waiting_customers) < number_of_chairs: waiting_customers.append(index) mutex.unlock() barber_semaphore.signal() customer_semaphore.wait() get_haircut() else: mutex.unlock()","title":"Process Synchronization Application"},{"location":"operating_system/process_synchronization_application#process-synchronization-application","text":"","title":"Process Synchronization Application"},{"location":"operating_system/process_synchronization_application#producer-consumer","text":"Also known as Bounded Buffer Problem Details We have a buffer of fixed size Producer produces an item and puts it in the buffer Consumer consumes an item by picking up from the buffer Problems Both processes may try to update the buffer at the same time Which can lead to data loss & inconsistency Consumer might consume faster, so it might have to wait Producer might produce faster which can lead to buffer overflow There may be multiple producers & consumers, and same item may be processed multiple times Solution Use a mutex for locking & unlocking the buffer Use a semaphore for empty slots Use a semaphore for occupied slots Variations Unbounded buffer Sleep and wake Producer sleeps if consumer is not consuming Consumer sleeps if producer is not producing Each wake up the other when process starts Problem Producer starts when consumer was about to sleep Consumer will sleep and afterwards producer as consumer is not consuming def producer(): while True: wait(empty_slots) lock(buffer) # Put in buffer unlock(buffer) signal(occupied_slots) def consumer(): while True: wait(full_slots) lock(buffer) # Consume from buffer unlock(buffer) signal(occupied_slots)","title":"Producer Consumer"},{"location":"operating_system/process_synchronization_application#dining-philosophers","text":"There is one chopstick/fork between two philosophers A philosopher can eat only if he picks up two chopsticks Deadlock will happen if all philosophers pick their left chopstick simultaneously. Solutions: Odd philosophers pick left chopstick first & even ones pick right chopstick first Both chopsticks should be available before picking up Solution Mutex to ensure that only one philosopher attempts to pick up a fork at a time One semaphore per philosopher One state per philosopher (thinking, hungry, or eating) def philosopher(index): while True: think(index) take_forks(index) eat(index) put_forks(index) def check(index): if state[index] == 'hungry' and state[left] != 'eating' and state[right] != 'eating': philosopher_semaphore[index].wait() state[index] = 'eating' def take_forks(index): mutex.lock() state[index] = 'hungry' check(index) mutex.unlock() def put_forks(index) mutex.lock() state[index] = 'thinking' check(left) check(right) mutex.unlock() philosopher_semaphore[index].signal() def think(index): time.sleep(random.randint(1, 5)) def eat(index): time.sleep(random.randint(1, 3))","title":"Dining Philosophers"},{"location":"operating_system/process_synchronization_application#readers-writers","text":"A resource (e.g. file) shared between multiple users or processes Reading: Any number of readers can read the write_semaphore No one is allowed to write because the changes won't be visible to readers Writing: Only the writer is allowed access No one else can write or read because the changes won't be visible to others Solution Semaphore Semaphore to control write action to the write_semaphore Variable to track reader count Mutex to control edits to reader count Monitor Gives equal chance to both readers & writers If writer is active, readers queue up If readers are active, writers queue up Types: Reader is given preference, Writer is given preference, Both have equal preference def writer(): while True: wait(write_semaphore) # Write signal(write_semaphore) def reader(): while True: # Reader wants to enter wait(read_mutex) read_count += 1 # Disable writer access, readers are being preferred if read_count == 1: wait(write_semaphore) signal(read_mutex) # Reading # Reader wants to exit wait(read_mutex) read_count -= 1 # Enable writer access if read_count == 0: signal(write_semaphore) signal(read_mutex)","title":"Readers Writers"},{"location":"operating_system/process_synchronization_application#sleeping-barber","text":"Details There is one barber and a number of chairs for waiting customers Customers arrive at random times and take a chair if available to wait If no chairs are available, the customer leaves When the barber is finished with a customer, he picks up the next customer If there are no customers, the barber goes to sleep Solution Semaphore for the barber's chair Semaphore for the waiting chairs Mutex to update waiting chairs It can become complex if multiple barbers are employed def barber(): while True: barber_semaphore.wait() mutex.lock() if len(waiting_customers) > 0 customer = waiting_customers.pop(0) mutex.unlock() cut_hair() customer_semaphore.signal() else: mutex.unlock() def customer(index): mutex.lock() if len(waiting_customers) < number_of_chairs: waiting_customers.append(index) mutex.unlock() barber_semaphore.signal() customer_semaphore.wait() get_haircut() else: mutex.unlock()","title":"Sleeping Barber"},{"location":"operating_system/thread_management","text":"Thread Management Thread Basic unit of CPU utilization Flow of execution through the process code Execution unit in a process Process has its own memory space and resources Threads operate within the same process with shared memory space and resources Separate flow of control with parallelism/concurrency Enables multiple threads to collaborate and work efficiently within a single program Fast communication due to shared memory Threads are most effective in multi-processors, otherwise context switch can be an overhead Each thread has Thread Control Block (TCB) and can be assigned priority Shares with peer threads: Code segment, Data segment, Open files Have its own: Program Counter (PC), System Registers, Stack Advantages Communication and Response Fast Context Switch Resource Sharing Enhanced Throughput Daemon Disk and Execution Monitor It is a long running background process that acts on request Types User level Not created using system calls and kernel does not manage them More efficient than kernel-level, context switch time is less, easier implementation If one thread causes a page fault, the entire process blocks Cannot benefit from multiprocessing Application dependent and OS independent Kernel level Have their own thread table to keep track and kernel helps in their management Slower than user-level, context switch time is more, complex implementation Can schedule multiple threads of the same process on different processors OS dependent Threading Issues Fork and Exec calls fork(): Does the new process duplicate all the threads or keep it single threaded exec(): The program specified as parameter will replace the entire process including all the threads Signal Handling Signal is used to notify a process that a particular event has happened Every signal has a default signal handler that the kernel runs when handling the signal This default action can be overriden by a user defined signal handler Thread Cancellation A browser often loads a web page using several threads (each image is loaded in a separate thread) When stop button is pressed, all threads loading the page are cancelled Cancellation may occur in 2 different scenarios Async: One thread immediately terminates the target thread Deferred: Target thread continuously checks whether it should terminate Thread Local Storage In some circumstances, a thread might need its own copy of data (e.g. in transaction processing) Scheduler Activations One scheme of communication between user level thread and kernel Kernel provides an application with a set of virtual processors The application can schedule user threads onto an available virtual processor Multi-tasking Multi-tasking OS gives the perception of running multiple processes simultaneously By dividing system resources and switching very fast between them Process based multi-tasking Process is the smallest unit Example: listening music and browsing internet at the same time Thread based multi-tasking Thread is the smallest unit Example: In a browser, navigating through a webpage and downloading a file at the same time Zombie Process Once a process is executed or terminated, its process descriptor stays in memory It sends a signal (SIGCHILD in linux) to its parent and enters into zombie state (EXIT_ZOMBIE in linux) The parent process then executes wait() system call to read the dead process's information After wait() is called, the zombie process is completely removed from memory This normally happens very quickly, so zombie processes are not accumulated in the system If zombie processes accumulate, they will take space in process table The process table has finite size and the system won't be able to generate new processes","title":"Thread Management"},{"location":"operating_system/thread_management#thread-management","text":"","title":"Thread Management"},{"location":"operating_system/thread_management#thread","text":"Basic unit of CPU utilization Flow of execution through the process code Execution unit in a process Process has its own memory space and resources Threads operate within the same process with shared memory space and resources Separate flow of control with parallelism/concurrency Enables multiple threads to collaborate and work efficiently within a single program Fast communication due to shared memory Threads are most effective in multi-processors, otherwise context switch can be an overhead Each thread has Thread Control Block (TCB) and can be assigned priority Shares with peer threads: Code segment, Data segment, Open files Have its own: Program Counter (PC), System Registers, Stack Advantages Communication and Response Fast Context Switch Resource Sharing Enhanced Throughput Daemon Disk and Execution Monitor It is a long running background process that acts on request","title":"Thread"},{"location":"operating_system/thread_management#types","text":"User level Not created using system calls and kernel does not manage them More efficient than kernel-level, context switch time is less, easier implementation If one thread causes a page fault, the entire process blocks Cannot benefit from multiprocessing Application dependent and OS independent Kernel level Have their own thread table to keep track and kernel helps in their management Slower than user-level, context switch time is more, complex implementation Can schedule multiple threads of the same process on different processors OS dependent","title":"Types"},{"location":"operating_system/thread_management#threading-issues","text":"Fork and Exec calls fork(): Does the new process duplicate all the threads or keep it single threaded exec(): The program specified as parameter will replace the entire process including all the threads Signal Handling Signal is used to notify a process that a particular event has happened Every signal has a default signal handler that the kernel runs when handling the signal This default action can be overriden by a user defined signal handler Thread Cancellation A browser often loads a web page using several threads (each image is loaded in a separate thread) When stop button is pressed, all threads loading the page are cancelled Cancellation may occur in 2 different scenarios Async: One thread immediately terminates the target thread Deferred: Target thread continuously checks whether it should terminate Thread Local Storage In some circumstances, a thread might need its own copy of data (e.g. in transaction processing) Scheduler Activations One scheme of communication between user level thread and kernel Kernel provides an application with a set of virtual processors The application can schedule user threads onto an available virtual processor","title":"Threading Issues"},{"location":"operating_system/thread_management#multi-tasking","text":"Multi-tasking OS gives the perception of running multiple processes simultaneously By dividing system resources and switching very fast between them Process based multi-tasking Process is the smallest unit Example: listening music and browsing internet at the same time Thread based multi-tasking Thread is the smallest unit Example: In a browser, navigating through a webpage and downloading a file at the same time","title":"Multi-tasking"},{"location":"operating_system/thread_management#zombie-process","text":"Once a process is executed or terminated, its process descriptor stays in memory It sends a signal (SIGCHILD in linux) to its parent and enters into zombie state (EXIT_ZOMBIE in linux) The parent process then executes wait() system call to read the dead process's information After wait() is called, the zombie process is completely removed from memory This normally happens very quickly, so zombie processes are not accumulated in the system If zombie processes accumulate, they will take space in process table The process table has finite size and the system won't be able to generate new processes","title":"Zombie Process"},{"location":"operating_system/resource_allocation","text":"Resource Allocation Deadlock Situation where a set of processes are blocked because Each process is holding a resource And waiting for another resource acquired by some other process Example: P1 has R1 & waiting for R2 and P2 has R2 & waiting for R1 Safe State: In which deadlock doesn't occur Deadlock Conditions: all four occur simultaneously Mutual Exclusion: Two or more resources are non-shareable (only one process can use at a time) Hold and Wait: A process is holding at least one resource and waiting for other resources at the same time No Preemption: A resource cannot be taken away from a process unless the process releases it Circular Wait: A set of processes waiting on each other in circular form Deadlock Handling Mechanisms Prevention Avoidance Detection and Recovery Ignorance Livelock When two or more processes continually repeat the same interaction In response to changes in other processes without doing any useful work All processes in livelock are running concurrently while in deadlock they are in waiting state Deadlock Prevention Achieved by solving or avoiding one of the four conditions Mutual Exclusion May not be possible since some resources are inherently non-shareable (like printer) Hold and Wait Allocate all resources at the start and release at the end of the process Will lead to low utilization since other processes can't use it May lead to starvation Preemption Preempt the resources when required by high priority process Circular wait Assign priority number to each resource Process can't request a lesser priority resource, i.e. a resource being used by other process Deadlock Avoidance Checking if system is in safe state at every step Request for resource will be granted only for safe state If it is in unsafe state, OS will backtrack one step Ensure that all information about resources is known before the execution (Resource allocation state) Available and allocated resources Maximum resources demanded by the processes Limitation: Process may not use all the resources demanded initially Achieves correctness of data but decreases performance Banker's algorithm is used Resource Allocation Graph (RAG) Process: circles Resources: rectangles, number of instances are denoted by dots Requesting: arrow from P to R Allocated: arrow from R to P It's a deadlock if a cycle forms If a resource has multiple instances, there must be that many cycles for deadlock Banker's algorithm Used in banking system to check if a loan can be sanctioned to a person Resource allocation and deadlock avoidance Input for resources: Maximum requirement, Allocated, Available, Requested Allows a request only if there's a safe state Requested resources <= Max required resources Requested resources <= Available resources Timeouts can be implemented to avoid deadlocks Example There are 4 resources: [A B C D] Total: [2 6 3 4] Available: [1 3 1 0] Allocated: [1 3 2 4] P1 = [1 2 1 2] P2 = [0 1 3 2] Max: P1 = [2 2 2 3] P2 = [0 1 5 3] Needed: Max - Allocated P1 = [1 0 1 1] P2 = [0 0 2 1] Deadlock Detection and Recovery Periodically check if deadlock occurred Detect deadlock Resource Allocation Graph (complicated for multiple instanced resources) Banker's Algorithm System Modeling: Mathematical model of the system and states Timestamping: If any process is waiting for a resource held by a process with lower timestamp Manual Intervention Inform the operator and let them handle manually Automatic Recovery Preempt the resources Rollback to previous safe state Abort all the processes: Computations may be lost Abort one process at at time: The process can be selected based on Priority, progress, process type, resources consumed, resources required Only one process should not be targeted repeateadly which may cause starvation Deadlock Ignorance If deadlock is very rare, let it happen and reboot the system For normal users, windows, linux Performance will decrease if it uses deadlock mechanism Resource Allocation Techniques Resource Pool There is a common pool of resources Resource Partitioning OS decides beforehand about what resources should be allocated to which process Divides resources to many resource partitions which are allocated as such A resource table records the partition and its current allocation status If a partition contains more resources than required, then they are wasted Deadlock in Distributed Systems In distributed systems, deadlock can neither be prevented or avoided Only deadlock detection can be implemented Approaches Centralized: Only one responsible node to detect deadlock But can lead to excessive workload on one node and single point of failure Distributed: Different nodes work together to detect deadlock Hierarchical: Most advantageous with combination of centralized and distributed approaches Selected nodes are responsible for deadlock detection which are controlled by a single node","title":"Resource Allocation"},{"location":"operating_system/resource_allocation#resource-allocation","text":"","title":"Resource Allocation"},{"location":"operating_system/resource_allocation#deadlock","text":"Situation where a set of processes are blocked because Each process is holding a resource And waiting for another resource acquired by some other process Example: P1 has R1 & waiting for R2 and P2 has R2 & waiting for R1 Safe State: In which deadlock doesn't occur Deadlock Conditions: all four occur simultaneously Mutual Exclusion: Two or more resources are non-shareable (only one process can use at a time) Hold and Wait: A process is holding at least one resource and waiting for other resources at the same time No Preemption: A resource cannot be taken away from a process unless the process releases it Circular Wait: A set of processes waiting on each other in circular form Deadlock Handling Mechanisms Prevention Avoidance Detection and Recovery Ignorance","title":"Deadlock"},{"location":"operating_system/resource_allocation#livelock","text":"When two or more processes continually repeat the same interaction In response to changes in other processes without doing any useful work All processes in livelock are running concurrently while in deadlock they are in waiting state","title":"Livelock"},{"location":"operating_system/resource_allocation#deadlock-prevention","text":"Achieved by solving or avoiding one of the four conditions Mutual Exclusion May not be possible since some resources are inherently non-shareable (like printer) Hold and Wait Allocate all resources at the start and release at the end of the process Will lead to low utilization since other processes can't use it May lead to starvation Preemption Preempt the resources when required by high priority process Circular wait Assign priority number to each resource Process can't request a lesser priority resource, i.e. a resource being used by other process","title":"Deadlock Prevention"},{"location":"operating_system/resource_allocation#deadlock-avoidance","text":"Checking if system is in safe state at every step Request for resource will be granted only for safe state If it is in unsafe state, OS will backtrack one step Ensure that all information about resources is known before the execution (Resource allocation state) Available and allocated resources Maximum resources demanded by the processes Limitation: Process may not use all the resources demanded initially Achieves correctness of data but decreases performance Banker's algorithm is used","title":"Deadlock Avoidance"},{"location":"operating_system/resource_allocation#resource-allocation-graph-rag","text":"Process: circles Resources: rectangles, number of instances are denoted by dots Requesting: arrow from P to R Allocated: arrow from R to P It's a deadlock if a cycle forms If a resource has multiple instances, there must be that many cycles for deadlock","title":"Resource Allocation Graph (RAG)"},{"location":"operating_system/resource_allocation#bankers-algorithm","text":"Used in banking system to check if a loan can be sanctioned to a person Resource allocation and deadlock avoidance Input for resources: Maximum requirement, Allocated, Available, Requested Allows a request only if there's a safe state Requested resources <= Max required resources Requested resources <= Available resources Timeouts can be implemented to avoid deadlocks Example There are 4 resources: [A B C D] Total: [2 6 3 4] Available: [1 3 1 0] Allocated: [1 3 2 4] P1 = [1 2 1 2] P2 = [0 1 3 2] Max: P1 = [2 2 2 3] P2 = [0 1 5 3] Needed: Max - Allocated P1 = [1 0 1 1] P2 = [0 0 2 1]","title":"Banker's algorithm"},{"location":"operating_system/resource_allocation#deadlock-detection-and-recovery","text":"Periodically check if deadlock occurred Detect deadlock Resource Allocation Graph (complicated for multiple instanced resources) Banker's Algorithm System Modeling: Mathematical model of the system and states Timestamping: If any process is waiting for a resource held by a process with lower timestamp Manual Intervention Inform the operator and let them handle manually Automatic Recovery Preempt the resources Rollback to previous safe state Abort all the processes: Computations may be lost Abort one process at at time: The process can be selected based on Priority, progress, process type, resources consumed, resources required Only one process should not be targeted repeateadly which may cause starvation","title":"Deadlock Detection and Recovery"},{"location":"operating_system/resource_allocation#deadlock-ignorance","text":"If deadlock is very rare, let it happen and reboot the system For normal users, windows, linux Performance will decrease if it uses deadlock mechanism","title":"Deadlock Ignorance"},{"location":"operating_system/resource_allocation#resource-allocation-techniques","text":"Resource Pool There is a common pool of resources Resource Partitioning OS decides beforehand about what resources should be allocated to which process Divides resources to many resource partitions which are allocated as such A resource table records the partition and its current allocation status If a partition contains more resources than required, then they are wasted","title":"Resource Allocation Techniques"},{"location":"operating_system/resource_allocation#deadlock-in-distributed-systems","text":"In distributed systems, deadlock can neither be prevented or avoided Only deadlock detection can be implemented Approaches Centralized: Only one responsible node to detect deadlock But can lead to excessive workload on one node and single point of failure Distributed: Different nodes work together to detect deadlock Hierarchical: Most advantageous with combination of centralized and distributed approaches Selected nodes are responsible for deadlock detection which are controlled by a single node","title":"Deadlock in Distributed Systems"},{"location":"operating_system/memory","text":"Memory Required to save data and instructions either temporarily or permanently Divided into cells or registers having an unique location or address Each register stores one bit of data Every data is converted to binary before storing Word Group of bits where a memory unit stores binary information Group of 8 bits is called a byte Memory Unit Data lines: Provide the info to be stored Control inputs: Specify the direction of transfer Address selection lines: Specify the word chosen, 2^k words can be accessed using k address lines Units of Memory Bit: Smallest unit that stores binary value (0 or 1) Byte: 8 bits, can represent 2^8 = 256 values KiloByte: 1024 Bytes MegaByte: 1024 KB GigaByte, TeraByte, PetaByte Memory Heirarchy Enhancement to organize the memory such that access time is minimized Based on program behavior known as locality of references Locality of references: Tendency of a processor to access the same set of memory locations Repetitively over a short period of time Some types of memory like cache and main memory are faster than others But have less size and are more expensive Types Internal or Primary Memory Directly accessible by the processor Main memory, cache, CPU registers External or Secondary Peripheral storage devices accessible by the processor via an I/O module Magnetic disk, optical disk, magnetic tape Hierarchy Design Registers Small high-speed memory units located in CPU that stores most frequently used data and instructions Have fastest access time and smallest storage capacity (16 to 64 bits) Cache Small fast memory unit located close to CPU That stores recently accessed data from the main memory Minimizes access time for CPU by storing temporary data Or acting as a middleware between CPU & original location Typically integrated directly into CPU chip Or placed on a separate chip with a bus interconnect with CPU Main Memory Primary memory of a computer system, has larger capacity than cache memory but is slower RAM Read write memory that is volatile and stores data & instructions currently in use by CPU Writing data is faster Static RAM Stores binary info in flip flops and requires constant power supply Faster access time and used to implememt cache memory but expensive than DRAM Complex internal circuitry and less capacity than DRAM Dynamic RAM Stores binary info as a charge in capacitor Requires refreshing circuitry to maintain the charge after a few milliseconds Contains more memory cells per unit area compared to SRAM ROM Read only memory that is non-volatile and stores important info used to operate the system Writing data is slower Masked ROM: Hard wired devices with a pre-programmed collection of data, were the first ROMs Programmable ROM: Modifiable once by the user, initially blank and can't be erased once written Erasable PROM: Extension of PROM that can be erased using UV rays Electrically Erasable PROM: Can erase (using electric field) and reprogramme upto 10,000 times Secondary Storage Non volatile memory that has a large storage capacity and stores data not currently in use by CPU Has the slowest access time and typically least expensive type of memory Example: Hard disk drive (HDD), Solid state drive (SSD) Virtual Memory: Using secondary memory as if it was a part of the main memory if there's a shortage Magnetic storage devices use magnetic fields to store and retrieve data Solid state storage devices use semiconductor based memory chips to store data Magnetic Disk Circular plates fabricated with metal or plastic or magnetized material Works at high speed inside computer and frequently used Magnetic Tape Magnetic recording device covered with plastic film, generally used for backup of data Access time is slower and requires some time for accessing the strip","title":"Memory"},{"location":"operating_system/memory#memory","text":"Required to save data and instructions either temporarily or permanently Divided into cells or registers having an unique location or address Each register stores one bit of data Every data is converted to binary before storing Word Group of bits where a memory unit stores binary information Group of 8 bits is called a byte Memory Unit Data lines: Provide the info to be stored Control inputs: Specify the direction of transfer Address selection lines: Specify the word chosen, 2^k words can be accessed using k address lines Units of Memory Bit: Smallest unit that stores binary value (0 or 1) Byte: 8 bits, can represent 2^8 = 256 values KiloByte: 1024 Bytes MegaByte: 1024 KB GigaByte, TeraByte, PetaByte","title":"Memory"},{"location":"operating_system/memory#memory-heirarchy","text":"Enhancement to organize the memory such that access time is minimized Based on program behavior known as locality of references Locality of references: Tendency of a processor to access the same set of memory locations Repetitively over a short period of time Some types of memory like cache and main memory are faster than others But have less size and are more expensive Types Internal or Primary Memory Directly accessible by the processor Main memory, cache, CPU registers External or Secondary Peripheral storage devices accessible by the processor via an I/O module Magnetic disk, optical disk, magnetic tape","title":"Memory Heirarchy"},{"location":"operating_system/memory#hierarchy-design","text":"","title":"Hierarchy Design"},{"location":"operating_system/memory#registers","text":"Small high-speed memory units located in CPU that stores most frequently used data and instructions Have fastest access time and smallest storage capacity (16 to 64 bits)","title":"Registers"},{"location":"operating_system/memory#cache","text":"Small fast memory unit located close to CPU That stores recently accessed data from the main memory Minimizes access time for CPU by storing temporary data Or acting as a middleware between CPU & original location Typically integrated directly into CPU chip Or placed on a separate chip with a bus interconnect with CPU","title":"Cache"},{"location":"operating_system/memory#main-memory","text":"Primary memory of a computer system, has larger capacity than cache memory but is slower RAM Read write memory that is volatile and stores data & instructions currently in use by CPU Writing data is faster Static RAM Stores binary info in flip flops and requires constant power supply Faster access time and used to implememt cache memory but expensive than DRAM Complex internal circuitry and less capacity than DRAM Dynamic RAM Stores binary info as a charge in capacitor Requires refreshing circuitry to maintain the charge after a few milliseconds Contains more memory cells per unit area compared to SRAM ROM Read only memory that is non-volatile and stores important info used to operate the system Writing data is slower Masked ROM: Hard wired devices with a pre-programmed collection of data, were the first ROMs Programmable ROM: Modifiable once by the user, initially blank and can't be erased once written Erasable PROM: Extension of PROM that can be erased using UV rays Electrically Erasable PROM: Can erase (using electric field) and reprogramme upto 10,000 times","title":"Main Memory"},{"location":"operating_system/memory#secondary-storage","text":"Non volatile memory that has a large storage capacity and stores data not currently in use by CPU Has the slowest access time and typically least expensive type of memory Example: Hard disk drive (HDD), Solid state drive (SSD) Virtual Memory: Using secondary memory as if it was a part of the main memory if there's a shortage Magnetic storage devices use magnetic fields to store and retrieve data Solid state storage devices use semiconductor based memory chips to store data","title":"Secondary Storage"},{"location":"operating_system/memory#magnetic-disk","text":"Circular plates fabricated with metal or plastic or magnetized material Works at high speed inside computer and frequently used","title":"Magnetic Disk"},{"location":"operating_system/memory#magnetic-tape","text":"Magnetic recording device covered with plastic film, generally used for backup of data Access time is slower and requires some time for accessing the strip","title":"Magnetic Tape"},{"location":"operating_system/memory_management","text":"Memory Management Memory management is the functionality which manages primary memory Moves processes between main memory and disk during execution Keeps track of each memory location whether it's allocated or free Allocates memory dynamically to the programs when requested And de-allocates for reuse when no longer needed Memory Management Unit (MMU) handles these tasks Requirements Relocation: Relocate the process when swapped back if the previous location is occupied by another process Protection: One process should not write to the address of another process (accidental or incidental) Sharing: Allow controlled access to shared memory, share copy of process where required Organization of logical & physical memory Programs always execute in main memory, so larger the main memory, larger the multiprogramming Memory Allocation and Partitioning Placement Algorithms OS decides which free block to allocate when a process is loaded into main memory First fit: First available block which is large enough Best fit: First smallest sufficient partition Consumes a lot of process time to search May not always be the best algorithm It depends on how the memory can be distributed among all processes Worst fit: Largest sufficient partition Next fit: Similar to first fit, but will be searched from the last allocation point Allocation Methods Single Continguous: Except the reserved memory for OS, all memory is available to a process Partitioned: Memory is divided into different blocks or partitions and allocated based on requirements Paged: Memory is divided into fixed size units called page frames and used as virtual memory Segmented: Memory is divided into different segments Segment is a logical grouping of the process data or code Allocated memory doesn\u2019t have to be contiguous Most OS use segmentation with paging A process is divided into segments and each segment has pages Fragmentation When many of the free blocks are too small to satisfy any request External: Memory not contiguous, requires memory shuffling Internal: Allocated memory larger than required Defragmentation Contiguous Partitioning Processes can only be allocated contiguous or adjacent blocks of memory Fixed or Static Partitioning Main memory is divided into fixed number of partitions but the sizes may vary with no overlaps Each partition is assigned to a specific process or user, OS occupies the first partition Typically allocated at boot time and remains dedicated to a process till it terminates or releases Advantages Simple and easy to implement Minimum memory can be ensured for each process Prevents processes from interfering into each other's memory space Disadvantages Internal fragmentation (memory in partition remains unused) External fragmentation (since partitions are contiguous, some parts of memory may remain unused) Process size limitation (cannot exceed than the allocated partition) Limits the number of processes running concurrently (each process requires a dedicated partition) Used in embedded systems, real-time systems, limited memory systems Variable or Dynamic Partitioning Partitions are not made before execution but during run-time Partition is created depending on the process requirements avoiding internal fragmentation Number of partitions is not fixed and depends upon the incoming processes and the main memory size First partition is reserved for OS Keeping track of partitions: Bitmap, Linked List Advantages: No interal fragmentation, no limitation on multiprogramming, no limitation on process size Disadvantages: External fragmentation, complex memory allocation Non-Contiguous Partitioning Processes can be allocated a series of non-contiguous blocks of memory that can be located anywhere Pointers are used to link the blocks and track the blocks allocated to a process Use of pointers introduces an overhead in allocation & de-allocation Need to maintain page table for each process Paging Logical memory or process address space is divided into blocks of same size called pages Main memory is divided into small fixed sized blocks of physical memory called frames No external fragmentation since frame size is generally equal to page size Retrieving processes from secondary storage into main memory in form of pages is also called paging Internal fragmentation can happen in the last page of the process Logical address Page number: Bits that represent the page in logical address space Page offset: Bits that represent a particular word in a page p|d (logical) -> f|d (physical) Physical address Frame number Frame offset Translation Lookaside Buffer (TLB) is special fast lookup hardware cache It is used to track recently used page table entries Segmentation A process is divided into segments (main program, functions, procedures, variables, etc) Segments may not be of same sizes which can lead to external fragmentation It gives user's view of process which paging does not Segment table maps logical and physical addresses Address Spaces Logical or Virtual Address Virtual address generated by CPU during program execution relative to the program's address space Provides a layer of abstraction that allows processes to access memory without knowing physical addresses Memory management unit (MMU) translates logical addresses into physical addresses using page table Page table maps each logical page number to a physical frame number Process/logical address space Set of logical addresses that a process references in its code OS maps logical addresses to physical addresses at the time of memory allocation to the program Uses Allows efficient memory management using paging and segmentation Can extend physical memory by disk Memory protection Less I/O needed to load or swap program in memory Physical Address Actual address in main memory where data is stored Physical addresses are not exposed to processes or users Physical address space does not change Example Physical address = 12 bits, physical address space = 2^12 = 4 * 1024 = 4K words Logical address = 13 bits, physical address space = 2^13 = 8 * 1024 = 8K words Address Binding Process of mapping one address space to another address space Done by Memory management unit (MMU) (address translation unit in particular) Contiguous Memory Allocation In contiguous memory allocation, it is not a difficult task If the base address of the process is known, next addresses can be found out MMU is a combination of two registers: Base register & limit register Base Register (Relocation Register) Contains starting physical address of the process Limit Register Mentions the limit relative to the base address on the region occupied by the process Logical address generated by CPU is first checked by limit register If the value of the logical address is less than the limit register The base address stored in the relocation register is added to the logical address to get the physical address If the value of the logical address is greater than the limit register CPU traps to the OS and OS terminates the program by giving fatal error Non-contiguous Memory Allocation Processes can be allocated anywhere in the available space The address translation is difficult, some techniques are Paging & Segmentation Different data structures and hardware support like TLB are required Types Compile Time If it is known at the compile time where the process will reside in memory Then an absolute address is generated Physical address is embedded to the executable of the program during compilation Loading executable as a process in memory is very fast If the generated address space is preoccupied by other processes, then the program crashes The program needs to be recompiled to change the address space Load Time If it is not known at the compile time where the process will reside Then a relocatable address is generated The loader translates the relocatable address to an absolute address To generate an absolute address The base address of the process in main memory is added to all logical addresses by the loader If the base address of the process changes, the process needs to be reloaded Execution Time The stage where instructions are in memory and are being processed by CPU Additional memory may be allocated and de-allocated Used if a process can be moved from one memory to another during execution Page Table Data structure used by OS to keep track of the mapping between logical and physical addresses Contents of Page Table Entry (PTE) Frame Number (or Address Translation Bit): Frame number in which the page is present (physical address) Present/Absent Bit (or Valid/Invalid Bit): If the page is not present, it is called Page Fault Protection Bit: Specifies protection like read, write, etc. Reference Bit: Whether the page was referred in the last cycle or not Caching Enabled/Disabled: Caching is disabled when the latest info is required Modified Bit (or Dirty Bit): If a page is modified, it has to be written or saved somewhere on page replacement The size and format of PTE can vary depending on the architecture of the system and the OS Allocating Kernel Memory Buddy System Divides memory into blocks of fixed size, each block has size in the power of two Follows best fit strategy On getting a request, it finds the smallest available block with sufficient size If the block is larger than required, it is split into two smaller blocks of equal size (buddies) This is repeated till the requested size is achieved Split strategies: Binary, fibonacci, weighted, tertiary Advantages Easy to implement and can handle wide range of memory sizes Coalescing (how quickly adjacent buddies can be combined to form a larger segment) Address calculation is easy Disadvantages: Internal fragmentation, can be inefficient in allocating small amounts of memory Slab System Divides memory into slabs of fixed size consisting of a set of objects of the same type Slab Made up of one or more physically contiguous pages Container of data associated with objects of specific kind of the containing cache Possible states depending on the available objects: full, empty, partial Cache Small amount of very fast memory, consists of one or more slabs Single cache for each unique kernel data structure (e.g. file objects, semaphores, process descriptors) On getting a request, it attempts to assign free object from a partial slab and then from an empty slab If these slabs are not available, a new slab is allocated from contiguous physical pages and assigned to a cache When the object is released and marked free, it returns to its cache Advantages: Efficient in allocating small amounts of memory since objects are created in advance Prevents fragmentation Disadvantages: Complex to implement, may require more memory overhead Garbage Collector Prevents memory leaks and fragmentation Dynamic approach to automatic memory management and heap allocation That processes and identifies memory no longer referenced Dynamic memory management process that finds dead memory blocks and reallocates them 3 primary approaches Mark and sweep: Reclaiming available memory Reference counting Allocated object contains reference count of referencing number When memory count is 0, object is garbage and destroyed Freed memory returns to heap memory Copy collection: Two partitions. When one is full, relocate and compact to second Buffer Overflow Memory Leak When memory which is no longer needed is not released When an object is stored in memory but cannot be accessed by running code","title":"Memory Management"},{"location":"operating_system/memory_management#memory-management","text":"Memory management is the functionality which manages primary memory Moves processes between main memory and disk during execution Keeps track of each memory location whether it's allocated or free Allocates memory dynamically to the programs when requested And de-allocates for reuse when no longer needed Memory Management Unit (MMU) handles these tasks Requirements Relocation: Relocate the process when swapped back if the previous location is occupied by another process Protection: One process should not write to the address of another process (accidental or incidental) Sharing: Allow controlled access to shared memory, share copy of process where required Organization of logical & physical memory Programs always execute in main memory, so larger the main memory, larger the multiprogramming","title":"Memory Management"},{"location":"operating_system/memory_management#memory-allocation-and-partitioning","text":"","title":"Memory Allocation and Partitioning"},{"location":"operating_system/memory_management#placement-algorithms","text":"OS decides which free block to allocate when a process is loaded into main memory First fit: First available block which is large enough Best fit: First smallest sufficient partition Consumes a lot of process time to search May not always be the best algorithm It depends on how the memory can be distributed among all processes Worst fit: Largest sufficient partition Next fit: Similar to first fit, but will be searched from the last allocation point","title":"Placement Algorithms"},{"location":"operating_system/memory_management#allocation-methods","text":"Single Continguous: Except the reserved memory for OS, all memory is available to a process Partitioned: Memory is divided into different blocks or partitions and allocated based on requirements Paged: Memory is divided into fixed size units called page frames and used as virtual memory Segmented: Memory is divided into different segments Segment is a logical grouping of the process data or code Allocated memory doesn\u2019t have to be contiguous Most OS use segmentation with paging A process is divided into segments and each segment has pages","title":"Allocation Methods"},{"location":"operating_system/memory_management#fragmentation","text":"When many of the free blocks are too small to satisfy any request External: Memory not contiguous, requires memory shuffling Internal: Allocated memory larger than required Defragmentation","title":"Fragmentation"},{"location":"operating_system/memory_management#contiguous-partitioning","text":"Processes can only be allocated contiguous or adjacent blocks of memory","title":"Contiguous Partitioning"},{"location":"operating_system/memory_management#fixed-or-static-partitioning","text":"Main memory is divided into fixed number of partitions but the sizes may vary with no overlaps Each partition is assigned to a specific process or user, OS occupies the first partition Typically allocated at boot time and remains dedicated to a process till it terminates or releases Advantages Simple and easy to implement Minimum memory can be ensured for each process Prevents processes from interfering into each other's memory space Disadvantages Internal fragmentation (memory in partition remains unused) External fragmentation (since partitions are contiguous, some parts of memory may remain unused) Process size limitation (cannot exceed than the allocated partition) Limits the number of processes running concurrently (each process requires a dedicated partition) Used in embedded systems, real-time systems, limited memory systems","title":"Fixed or Static Partitioning"},{"location":"operating_system/memory_management#variable-or-dynamic-partitioning","text":"Partitions are not made before execution but during run-time Partition is created depending on the process requirements avoiding internal fragmentation Number of partitions is not fixed and depends upon the incoming processes and the main memory size First partition is reserved for OS Keeping track of partitions: Bitmap, Linked List Advantages: No interal fragmentation, no limitation on multiprogramming, no limitation on process size Disadvantages: External fragmentation, complex memory allocation","title":"Variable or Dynamic Partitioning"},{"location":"operating_system/memory_management#non-contiguous-partitioning","text":"Processes can be allocated a series of non-contiguous blocks of memory that can be located anywhere Pointers are used to link the blocks and track the blocks allocated to a process Use of pointers introduces an overhead in allocation & de-allocation Need to maintain page table for each process","title":"Non-Contiguous Partitioning"},{"location":"operating_system/memory_management#paging","text":"Logical memory or process address space is divided into blocks of same size called pages Main memory is divided into small fixed sized blocks of physical memory called frames No external fragmentation since frame size is generally equal to page size Retrieving processes from secondary storage into main memory in form of pages is also called paging Internal fragmentation can happen in the last page of the process Logical address Page number: Bits that represent the page in logical address space Page offset: Bits that represent a particular word in a page p|d (logical) -> f|d (physical) Physical address Frame number Frame offset Translation Lookaside Buffer (TLB) is special fast lookup hardware cache It is used to track recently used page table entries","title":"Paging"},{"location":"operating_system/memory_management#segmentation","text":"A process is divided into segments (main program, functions, procedures, variables, etc) Segments may not be of same sizes which can lead to external fragmentation It gives user's view of process which paging does not Segment table maps logical and physical addresses","title":"Segmentation"},{"location":"operating_system/memory_management#address-spaces","text":"","title":"Address Spaces"},{"location":"operating_system/memory_management#logical-or-virtual-address","text":"Virtual address generated by CPU during program execution relative to the program's address space Provides a layer of abstraction that allows processes to access memory without knowing physical addresses Memory management unit (MMU) translates logical addresses into physical addresses using page table Page table maps each logical page number to a physical frame number Process/logical address space Set of logical addresses that a process references in its code OS maps logical addresses to physical addresses at the time of memory allocation to the program Uses Allows efficient memory management using paging and segmentation Can extend physical memory by disk Memory protection Less I/O needed to load or swap program in memory","title":"Logical or Virtual Address"},{"location":"operating_system/memory_management#physical-address","text":"Actual address in main memory where data is stored Physical addresses are not exposed to processes or users Physical address space does not change Example Physical address = 12 bits, physical address space = 2^12 = 4 * 1024 = 4K words Logical address = 13 bits, physical address space = 2^13 = 8 * 1024 = 8K words","title":"Physical Address"},{"location":"operating_system/memory_management#address-binding","text":"Process of mapping one address space to another address space Done by Memory management unit (MMU) (address translation unit in particular)","title":"Address Binding"},{"location":"operating_system/memory_management#contiguous-memory-allocation","text":"In contiguous memory allocation, it is not a difficult task If the base address of the process is known, next addresses can be found out MMU is a combination of two registers: Base register & limit register Base Register (Relocation Register) Contains starting physical address of the process Limit Register Mentions the limit relative to the base address on the region occupied by the process Logical address generated by CPU is first checked by limit register If the value of the logical address is less than the limit register The base address stored in the relocation register is added to the logical address to get the physical address If the value of the logical address is greater than the limit register CPU traps to the OS and OS terminates the program by giving fatal error","title":"Contiguous Memory Allocation"},{"location":"operating_system/memory_management#non-contiguous-memory-allocation","text":"Processes can be allocated anywhere in the available space The address translation is difficult, some techniques are Paging & Segmentation Different data structures and hardware support like TLB are required","title":"Non-contiguous Memory Allocation"},{"location":"operating_system/memory_management#types","text":"Compile Time If it is known at the compile time where the process will reside in memory Then an absolute address is generated Physical address is embedded to the executable of the program during compilation Loading executable as a process in memory is very fast If the generated address space is preoccupied by other processes, then the program crashes The program needs to be recompiled to change the address space Load Time If it is not known at the compile time where the process will reside Then a relocatable address is generated The loader translates the relocatable address to an absolute address To generate an absolute address The base address of the process in main memory is added to all logical addresses by the loader If the base address of the process changes, the process needs to be reloaded Execution Time The stage where instructions are in memory and are being processed by CPU Additional memory may be allocated and de-allocated Used if a process can be moved from one memory to another during execution","title":"Types"},{"location":"operating_system/memory_management#page-table","text":"Data structure used by OS to keep track of the mapping between logical and physical addresses Contents of Page Table Entry (PTE) Frame Number (or Address Translation Bit): Frame number in which the page is present (physical address) Present/Absent Bit (or Valid/Invalid Bit): If the page is not present, it is called Page Fault Protection Bit: Specifies protection like read, write, etc. Reference Bit: Whether the page was referred in the last cycle or not Caching Enabled/Disabled: Caching is disabled when the latest info is required Modified Bit (or Dirty Bit): If a page is modified, it has to be written or saved somewhere on page replacement The size and format of PTE can vary depending on the architecture of the system and the OS","title":"Page Table"},{"location":"operating_system/memory_management#allocating-kernel-memory","text":"","title":"Allocating Kernel Memory"},{"location":"operating_system/memory_management#buddy-system","text":"Divides memory into blocks of fixed size, each block has size in the power of two Follows best fit strategy On getting a request, it finds the smallest available block with sufficient size If the block is larger than required, it is split into two smaller blocks of equal size (buddies) This is repeated till the requested size is achieved Split strategies: Binary, fibonacci, weighted, tertiary Advantages Easy to implement and can handle wide range of memory sizes Coalescing (how quickly adjacent buddies can be combined to form a larger segment) Address calculation is easy Disadvantages: Internal fragmentation, can be inefficient in allocating small amounts of memory","title":"Buddy System"},{"location":"operating_system/memory_management#slab-system","text":"Divides memory into slabs of fixed size consisting of a set of objects of the same type Slab Made up of one or more physically contiguous pages Container of data associated with objects of specific kind of the containing cache Possible states depending on the available objects: full, empty, partial Cache Small amount of very fast memory, consists of one or more slabs Single cache for each unique kernel data structure (e.g. file objects, semaphores, process descriptors) On getting a request, it attempts to assign free object from a partial slab and then from an empty slab If these slabs are not available, a new slab is allocated from contiguous physical pages and assigned to a cache When the object is released and marked free, it returns to its cache Advantages: Efficient in allocating small amounts of memory since objects are created in advance Prevents fragmentation Disadvantages: Complex to implement, may require more memory overhead","title":"Slab System"},{"location":"operating_system/memory_management#garbage-collector","text":"Prevents memory leaks and fragmentation Dynamic approach to automatic memory management and heap allocation That processes and identifies memory no longer referenced Dynamic memory management process that finds dead memory blocks and reallocates them 3 primary approaches Mark and sweep: Reclaiming available memory Reference counting Allocated object contains reference count of referencing number When memory count is 0, object is garbage and destroyed Freed memory returns to heap memory Copy collection: Two partitions. When one is full, relocate and compact to second Buffer Overflow","title":"Garbage Collector"},{"location":"operating_system/memory_management#memory-leak","text":"When memory which is no longer needed is not released When an object is stored in memory but cannot be accessed by running code","title":"Memory Leak"},{"location":"operating_system/virtual_memory","text":"Virtual Memory Storage allocation scheme where secondary memory can be addressed as if it were part of the main memory The basis is non-contiguous memory allocation and the software component is called Virtual Memory Manager (VMM) The part of secondary memory used for virtual memory is called swap space or swap file A process can be swapped in and out of the main memory to make room for other components It occupies different places in main memory at different times during the execution Allows more processes to be maintained in the same amount of main memory A process can be broken into pieces and only the required pieces can be kept in the main memory It is permitted by the combination of dynamic run-time address translation and a page or segment table Also allows a large process to be broken down, even if it's larger than the main memory Logical address space thus can be larger than physical address space The size is limited by the addressing scheme of the system and the secondary memory available Challenges Overhead due to the movement between the main memory and the secondary memory Increased risk of data loss or corruption (if hard disk fails or power outage during transfer) Increased complexity of the memory management system Demand Paging The process of loading a page into memory on demand (when a page fault or memory access fault occurs) Process When the CPU tries to access a page not in memory, it generates an interrupt indicating a memory access fault OS puts the interrupted process in blocking state and it must bring the required page in the memory OS searches for the required page in the logical address space The require page is brought from logical address space to physical address space Page replacement algorithms are used to decide replacing the page in physical address space The page table is updated accordingly A signal is sent to CPU to continue the process execution and place the process back into the ready state The time taken to perform these steps is called page fault service time Page replacement algorithm Minimize page misses, processor time, cost of primary storage Reference string FIFO, LRU, LFU, MFU, Optimal page algorithm, Page buffering algorithm Belady's Anamoly Generally, page faults decrease if frames are increased But sometimes the opposite occurs and is termed as belady's anamoly Commonly occurs in FIFO Swapping The process of removing all the pages of a process from memory Or marking them for removal by the normal page replacement process Suspending a process ensures that it is not runnable while it is swapped out At some time later, the system swaps back the process from the secondary to the main memory Thrashing If the OS throws out a page just before it is to be used, it will have to get that page back immediately Too much of this activity leads to thrashing where the system spends most of its time swapping pages This decreases CPU utilization and increases the time taken for execution Causes Increasing multi-programming after a certain degree which decreases the number of frames per process Lack of frames: If a process is not allocated a sufficient amount of frames Improper page replacement policy Recovery Instruct the long-term scheduler not to bring the processes into memory after the threshold If the system is already thrashing, instruct the mid-term scheduler to suspend some of the processes Frame Allocation Static Allocation: The number of frame allocations to a process is fixed Dynamic Allocation: The number of frame allocations to a process changes Paging Policies Fetch Policy: Decides when a page should be loaded into the memory Replacement Policy: Decides when a page in memory should be replaced Placement Policy: Decides where in memory should a page be loaded Memory Interleaving Technique that divides memory into a number of modules such that successive words are placed in different modules Most significant bit provides the address of the module Least signiciant bit provides the address of the data in the module Example Consider these addresses with data in parenthesis 0000 (1), 0001 (2), 0010 (3), 0011 (4), ... Module 00: 00 (1), 01 (2), 10 (3), 11 (4) Module 01: 00 (5), 01 (6), 10 (7), 11 (8) Module 10: 00 (9), 01 (10), 10 (11), 11 (12) Module 11: 00 (13), 01 (14), 10 (15), 11 (16) To get the data at 0111, it will look in the module 01 with address 11 and fetch 8 as the data Usage Whenever a cache miss occurs, the data is to be fetched from the main memory But the main memory is slower than cache, so memory interleaving increases the access time Inverted Page Table Most OS implement a separate page table for each process A considerable amount of memory is occupied by page tables only Multilevel paging schemes further increase the space required for storing page tables Inverted Page Table is a data structure used to map physical memory pages to virtual memory pages It is stored in secondary memory instead of main memory Unlike Page Table, which is per process, IPT is system wide that contains an entry for each physical memory page Segmentation A process is divided into chunks (not necessarily of the same sizes) called segments Need not be placed in contiguous memory, so no internal fragmentation The size of a segment is decided by its purpose in the program Why required In paging, a process is divided into pages without considering the relative parts of the code This may lead multiple pages to be loaded in memory that might have been included in a single page Segmentation was introduced so that related code can be combined in a single block There is no simple relationship between logical addresses and physical addresses in segmentation Types Virtual Memory Segmentation: Not done all at once, may or may not take place at the run-time Simple Segmentation: Done all together at run-time Segment Table Base Address: Starting physical address for the segments Segment Limit (or Segment Offset): Length of a segment Advantages Takes less space than page table Similar to the user's perception of physical memory Segment size is specified by the user, while in paging the page size in specified by hardware Segmentation operating system Disadvatages Can lead to external fragmentation due to swapping of processes Access time increases due to segment table More complex implementation than paging Managing multiple segments per process can be challenging and might increase segmentation faults","title":"Virtual Memory"},{"location":"operating_system/virtual_memory#virtual-memory","text":"Storage allocation scheme where secondary memory can be addressed as if it were part of the main memory The basis is non-contiguous memory allocation and the software component is called Virtual Memory Manager (VMM) The part of secondary memory used for virtual memory is called swap space or swap file A process can be swapped in and out of the main memory to make room for other components It occupies different places in main memory at different times during the execution Allows more processes to be maintained in the same amount of main memory A process can be broken into pieces and only the required pieces can be kept in the main memory It is permitted by the combination of dynamic run-time address translation and a page or segment table Also allows a large process to be broken down, even if it's larger than the main memory Logical address space thus can be larger than physical address space The size is limited by the addressing scheme of the system and the secondary memory available Challenges Overhead due to the movement between the main memory and the secondary memory Increased risk of data loss or corruption (if hard disk fails or power outage during transfer) Increased complexity of the memory management system","title":"Virtual Memory"},{"location":"operating_system/virtual_memory#demand-paging","text":"The process of loading a page into memory on demand (when a page fault or memory access fault occurs) Process When the CPU tries to access a page not in memory, it generates an interrupt indicating a memory access fault OS puts the interrupted process in blocking state and it must bring the required page in the memory OS searches for the required page in the logical address space The require page is brought from logical address space to physical address space Page replacement algorithms are used to decide replacing the page in physical address space The page table is updated accordingly A signal is sent to CPU to continue the process execution and place the process back into the ready state The time taken to perform these steps is called page fault service time Page replacement algorithm Minimize page misses, processor time, cost of primary storage Reference string FIFO, LRU, LFU, MFU, Optimal page algorithm, Page buffering algorithm Belady's Anamoly Generally, page faults decrease if frames are increased But sometimes the opposite occurs and is termed as belady's anamoly Commonly occurs in FIFO","title":"Demand Paging"},{"location":"operating_system/virtual_memory#swapping","text":"The process of removing all the pages of a process from memory Or marking them for removal by the normal page replacement process Suspending a process ensures that it is not runnable while it is swapped out At some time later, the system swaps back the process from the secondary to the main memory","title":"Swapping"},{"location":"operating_system/virtual_memory#thrashing","text":"If the OS throws out a page just before it is to be used, it will have to get that page back immediately Too much of this activity leads to thrashing where the system spends most of its time swapping pages This decreases CPU utilization and increases the time taken for execution Causes Increasing multi-programming after a certain degree which decreases the number of frames per process Lack of frames: If a process is not allocated a sufficient amount of frames Improper page replacement policy Recovery Instruct the long-term scheduler not to bring the processes into memory after the threshold If the system is already thrashing, instruct the mid-term scheduler to suspend some of the processes","title":"Thrashing"},{"location":"operating_system/virtual_memory#frame-allocation","text":"Static Allocation: The number of frame allocations to a process is fixed Dynamic Allocation: The number of frame allocations to a process changes","title":"Frame Allocation"},{"location":"operating_system/virtual_memory#paging-policies","text":"Fetch Policy: Decides when a page should be loaded into the memory Replacement Policy: Decides when a page in memory should be replaced Placement Policy: Decides where in memory should a page be loaded","title":"Paging Policies"},{"location":"operating_system/virtual_memory#memory-interleaving","text":"Technique that divides memory into a number of modules such that successive words are placed in different modules Most significant bit provides the address of the module Least signiciant bit provides the address of the data in the module Example Consider these addresses with data in parenthesis 0000 (1), 0001 (2), 0010 (3), 0011 (4), ... Module 00: 00 (1), 01 (2), 10 (3), 11 (4) Module 01: 00 (5), 01 (6), 10 (7), 11 (8) Module 10: 00 (9), 01 (10), 10 (11), 11 (12) Module 11: 00 (13), 01 (14), 10 (15), 11 (16) To get the data at 0111, it will look in the module 01 with address 11 and fetch 8 as the data Usage Whenever a cache miss occurs, the data is to be fetched from the main memory But the main memory is slower than cache, so memory interleaving increases the access time","title":"Memory Interleaving"},{"location":"operating_system/virtual_memory#inverted-page-table","text":"Most OS implement a separate page table for each process A considerable amount of memory is occupied by page tables only Multilevel paging schemes further increase the space required for storing page tables Inverted Page Table is a data structure used to map physical memory pages to virtual memory pages It is stored in secondary memory instead of main memory Unlike Page Table, which is per process, IPT is system wide that contains an entry for each physical memory page","title":"Inverted Page Table"},{"location":"operating_system/virtual_memory#segmentation","text":"A process is divided into chunks (not necessarily of the same sizes) called segments Need not be placed in contiguous memory, so no internal fragmentation The size of a segment is decided by its purpose in the program Why required In paging, a process is divided into pages without considering the relative parts of the code This may lead multiple pages to be loaded in memory that might have been included in a single page Segmentation was introduced so that related code can be combined in a single block There is no simple relationship between logical addresses and physical addresses in segmentation Types Virtual Memory Segmentation: Not done all at once, may or may not take place at the run-time Simple Segmentation: Done all together at run-time Segment Table Base Address: Starting physical address for the segments Segment Limit (or Segment Offset): Length of a segment Advantages Takes less space than page table Similar to the user's perception of physical memory Segment size is specified by the user, while in paging the page size in specified by hardware Segmentation operating system Disadvatages Can lead to external fragmentation due to swapping of processes Access time increases due to segment table More complex implementation than paging Managing multiple segments per process can be challenging and might increase segmentation faults","title":"Segmentation"},{"location":"operating_system/storage_management","text":"Storage Management File System Method used by OS to store, organize and manage data on a storage device using files and directories Types FAT (File Allocation Table): Older file system NTFS (New Technology File System): Modern file system that supports permissions, compression, encryption Ext (Extended File System): Commonly used in linux and unix HFS (Hierarchical File System): Used by mac OS APFS (Apple File System): New file system for mac OS File: Collection of related information used to store and manage data in the computer system Directory: Collection of files Contains information about files: attributes, location, ownership Directory is itself a file accessible by file management routines Helps in grouping files and locating files quickly File Allocation Methods Continuous Allocation A single continuous set of block is allocated at the time of file creation Pre-allocation strategy using variable size portions File allocation table needs a single entry for each file, with starting block and length Linked or Non-contiguous Allocation Individual blocks contain pointer to the next block, any free block can be added to the chain Although pre-allocation is possible, it is more common to allocate as needed If the pointer of any block is lost, the file will be truncated Supports only sequential access of files File allocation table needs a single entry for each file, with starting block and length Indexed Allocation File allocation table contains a separate one-level index for each file The index has one entry for each block allocated to the file The allocation can be on basis of fixed-size or variable-size blocks Supports both sequential and direct access to the file Disk Free Space Management Space not allocated to any file also needs to be managed To know what blocks are available on a disk, a disk allocation table is required Bit Tables A vector containing one bit is used for each block on the disk: 0 for free blocks, 1 for occupied blocks Works well with any file allocation method, and easy to find contiguous free blocks Free Block List Each block is assigned a number sequentially List of the numbers of all free blocks is maintained in a reserved block of the disk Unix File System Files are organized in multi-level hierarchy structure called directory tree At the top of the file system is the root directory (represented by '/') All other files are descendants of root Each file and directory has an owner, a group, and permissions Supports symbolic links: pointers to other files or directories Without the need of physically moving them around Structure /: root /bin (binaries): fundamental utilities like ls, cp /boot: files required for successful booting /dev (devices): contains file representations of peripheral & pseudo devices /etc: system wide configuration files & system databases /home: home directories for users /lib: system libraries, critical files like kernel modules or device drivers /media: default mount point for removable devices like USB drives /mnt (mount): file system mount points, used if the system uses multiple hard disks or disk partitions Also used for file remote/network file systems, CD/DVD drives /proc: procfs virtual file system showing info about processes as files /root: home directory for the super user 'root' Not kept in /home in case specific maintenance needs to be performed During which other file systems are not available /tmp: temporary files, many systems clear it upon startup /usr: originally held user home directories which is now done by /home Now holds executables, libraries, shared resources that are not system critical /usr/bin: stores binary programs distributed with OS not residing in /bin & /sbin /usr/include: stores development headers used throughout the system, mostly used by #include in C/C++ /usr/lib: required libraries and data files for programs stored in /usr /var (variable): files that may change often especially in size /var/log: system log files /var/mail: stores incoming mails /var/spool: contains print jobs, mail spools and other queued tasks /var/tmp: temporary files which should be preserved between system reboots Types of Unix Files Ordinary files: Files containing data, text, program instructions Special files: Represents a physical device used for I/O like printer, tape drive Character special file: Data is transferred one character at a time (raw device access) Block special file: Data is transferred in large fixed-size blocks (block device access) Directories: Store both special & ordinary files Pipes: UNIX allows linking commands using a pipe The pipe acts as a temporary file which holds data from one command until read by another Sockets: Special file that allows for advanced inter-process communication It is a stream of data, similar to network stream & network sockets But all transactions are local to the file system Symbolic link: Used to reference some other file in the file system File Access Methods Sequential Access Information in the file is processed in order, one record after the other Most common and simplest access method Read: It moves the pointer ahead by one Write: It allocates memory and moves the pointer to the end of the file Advantages Less prone to data corruption as the data is written sequentially and not randomly More efficient method for reading large files, as it only reads the required data Reliable method for backup and restore operations Disadvantages Does not allow quick access to a specific record in the file Not suitable for applications that require frequent updates or modifications to the file Space between records cannot be used by other records Index Sequential Access Constructs an index for the file, which contains the pointers to various blocks Direct Access (or Relative Access) A fixed length logical record that allows to read and write record rapidly in no particular order The file is viewed as a numbered sequence of block or record Relative Record Access Records are accessed relative to the current position of the file pointer Requires fixed length records and may not be flexible enough for some applications Difficult to insert or delete records in the middle of a file Without disrupting the relative positions of other records Content Addressable Access Hash function is used to calculate a unique key for each record or block based on its content Any record or block can be accessed by specifying its key Ideal for searching large databases or file systems Allows easy insertion and deletion of records or blocks There is an overhead of calculating hashes and possibility of collision Disk or I/O Scheduling Only one I/O request can be served at a time by the disk controller Two or more requests may be far from each other which can result in greater disk arm movement Hard drives are one of the slowest parts of the system and needs to be accessed in an efficient manner Key Terms Seek time: Time take to locate the disk arm to a specified track where the data is to be read or written Rotational Latency: Time taken by the desired sector to rotate into a position So that read/write heads can be accessed Transfer time: Time taken to transfer data, depends on rotating speed and size of data Disk access time = Seek time + Rotational latency + Transfer time Disk Response time: Average time spent by a request to wait for I/O Spooling SPOOL: Simultaneous Peripheral Operations On-Line Similar to a buffering mechanism in which data is temporarily held To be used and executed by a device, program or system Data is sent to and stored in memory or other volatile storage until the program requests for execution Devices like printers, keyboard, mouse are slow relative to the rest of the system creating a bottleneck Spooling resolves this by accumulating data, instructions & processes from multiple sources in a request queue Which is then processed in a FIFO manner Batch processing systems also use spooling to maintain a queue of ready-to-run jobs Which can be started as soon as the system has resources Allows multiple processes to write documents to a print queue without waiting and resume their work Difference from Buffering Main memory has an area called buffer to store or hold data temporarily That is being transmitted between two devices or between a device & an application Helps in matching the speed of data stream between the sender and the receiver RAID: 0 1 \u2013 Clone 2 \u2013 Error correcting code and bits 3 \u2013 Byte level stripking with parity disk 4 \u2013 Block level striping with parity disk 5 \u2013 Block level striping with distributed parity 6 \u2013 extends 5 with one more parity block 10 \u2013 combine raids 1 and 0","title":"Storage Management"},{"location":"operating_system/storage_management#storage-management","text":"","title":"Storage Management"},{"location":"operating_system/storage_management#file-system","text":"Method used by OS to store, organize and manage data on a storage device using files and directories Types FAT (File Allocation Table): Older file system NTFS (New Technology File System): Modern file system that supports permissions, compression, encryption Ext (Extended File System): Commonly used in linux and unix HFS (Hierarchical File System): Used by mac OS APFS (Apple File System): New file system for mac OS File: Collection of related information used to store and manage data in the computer system Directory: Collection of files Contains information about files: attributes, location, ownership Directory is itself a file accessible by file management routines Helps in grouping files and locating files quickly","title":"File System"},{"location":"operating_system/storage_management#file-allocation-methods","text":"Continuous Allocation A single continuous set of block is allocated at the time of file creation Pre-allocation strategy using variable size portions File allocation table needs a single entry for each file, with starting block and length Linked or Non-contiguous Allocation Individual blocks contain pointer to the next block, any free block can be added to the chain Although pre-allocation is possible, it is more common to allocate as needed If the pointer of any block is lost, the file will be truncated Supports only sequential access of files File allocation table needs a single entry for each file, with starting block and length Indexed Allocation File allocation table contains a separate one-level index for each file The index has one entry for each block allocated to the file The allocation can be on basis of fixed-size or variable-size blocks Supports both sequential and direct access to the file","title":"File Allocation Methods"},{"location":"operating_system/storage_management#disk-free-space-management","text":"Space not allocated to any file also needs to be managed To know what blocks are available on a disk, a disk allocation table is required Bit Tables A vector containing one bit is used for each block on the disk: 0 for free blocks, 1 for occupied blocks Works well with any file allocation method, and easy to find contiguous free blocks Free Block List Each block is assigned a number sequentially List of the numbers of all free blocks is maintained in a reserved block of the disk","title":"Disk Free Space Management"},{"location":"operating_system/storage_management#unix-file-system","text":"Files are organized in multi-level hierarchy structure called directory tree At the top of the file system is the root directory (represented by '/') All other files are descendants of root Each file and directory has an owner, a group, and permissions Supports symbolic links: pointers to other files or directories Without the need of physically moving them around","title":"Unix File System"},{"location":"operating_system/storage_management#structure","text":"/: root /bin (binaries): fundamental utilities like ls, cp /boot: files required for successful booting /dev (devices): contains file representations of peripheral & pseudo devices /etc: system wide configuration files & system databases /home: home directories for users /lib: system libraries, critical files like kernel modules or device drivers /media: default mount point for removable devices like USB drives /mnt (mount): file system mount points, used if the system uses multiple hard disks or disk partitions Also used for file remote/network file systems, CD/DVD drives /proc: procfs virtual file system showing info about processes as files /root: home directory for the super user 'root' Not kept in /home in case specific maintenance needs to be performed During which other file systems are not available /tmp: temporary files, many systems clear it upon startup /usr: originally held user home directories which is now done by /home Now holds executables, libraries, shared resources that are not system critical /usr/bin: stores binary programs distributed with OS not residing in /bin & /sbin /usr/include: stores development headers used throughout the system, mostly used by #include in C/C++ /usr/lib: required libraries and data files for programs stored in /usr /var (variable): files that may change often especially in size /var/log: system log files /var/mail: stores incoming mails /var/spool: contains print jobs, mail spools and other queued tasks /var/tmp: temporary files which should be preserved between system reboots","title":"Structure"},{"location":"operating_system/storage_management#types-of-unix-files","text":"Ordinary files: Files containing data, text, program instructions Special files: Represents a physical device used for I/O like printer, tape drive Character special file: Data is transferred one character at a time (raw device access) Block special file: Data is transferred in large fixed-size blocks (block device access) Directories: Store both special & ordinary files Pipes: UNIX allows linking commands using a pipe The pipe acts as a temporary file which holds data from one command until read by another Sockets: Special file that allows for advanced inter-process communication It is a stream of data, similar to network stream & network sockets But all transactions are local to the file system Symbolic link: Used to reference some other file in the file system","title":"Types of Unix Files"},{"location":"operating_system/storage_management#file-access-methods","text":"Sequential Access Information in the file is processed in order, one record after the other Most common and simplest access method Read: It moves the pointer ahead by one Write: It allocates memory and moves the pointer to the end of the file Advantages Less prone to data corruption as the data is written sequentially and not randomly More efficient method for reading large files, as it only reads the required data Reliable method for backup and restore operations Disadvantages Does not allow quick access to a specific record in the file Not suitable for applications that require frequent updates or modifications to the file Space between records cannot be used by other records Index Sequential Access Constructs an index for the file, which contains the pointers to various blocks Direct Access (or Relative Access) A fixed length logical record that allows to read and write record rapidly in no particular order The file is viewed as a numbered sequence of block or record Relative Record Access Records are accessed relative to the current position of the file pointer Requires fixed length records and may not be flexible enough for some applications Difficult to insert or delete records in the middle of a file Without disrupting the relative positions of other records Content Addressable Access Hash function is used to calculate a unique key for each record or block based on its content Any record or block can be accessed by specifying its key Ideal for searching large databases or file systems Allows easy insertion and deletion of records or blocks There is an overhead of calculating hashes and possibility of collision","title":"File Access Methods"},{"location":"operating_system/storage_management#disk-or-io-scheduling","text":"Only one I/O request can be served at a time by the disk controller Two or more requests may be far from each other which can result in greater disk arm movement Hard drives are one of the slowest parts of the system and needs to be accessed in an efficient manner Key Terms Seek time: Time take to locate the disk arm to a specified track where the data is to be read or written Rotational Latency: Time taken by the desired sector to rotate into a position So that read/write heads can be accessed Transfer time: Time taken to transfer data, depends on rotating speed and size of data Disk access time = Seek time + Rotational latency + Transfer time Disk Response time: Average time spent by a request to wait for I/O","title":"Disk or I/O Scheduling"},{"location":"operating_system/storage_management#spooling","text":"SPOOL: Simultaneous Peripheral Operations On-Line Similar to a buffering mechanism in which data is temporarily held To be used and executed by a device, program or system Data is sent to and stored in memory or other volatile storage until the program requests for execution Devices like printers, keyboard, mouse are slow relative to the rest of the system creating a bottleneck Spooling resolves this by accumulating data, instructions & processes from multiple sources in a request queue Which is then processed in a FIFO manner Batch processing systems also use spooling to maintain a queue of ready-to-run jobs Which can be started as soon as the system has resources Allows multiple processes to write documents to a print queue without waiting and resume their work","title":"Spooling"},{"location":"operating_system/storage_management#difference-from-buffering","text":"Main memory has an area called buffer to store or hold data temporarily That is being transmitted between two devices or between a device & an application Helps in matching the speed of data stream between the sender and the receiver","title":"Difference from Buffering"},{"location":"operating_system/storage_management#raid","text":"0 1 \u2013 Clone 2 \u2013 Error correcting code and bits 3 \u2013 Byte level stripking with parity disk 4 \u2013 Block level striping with parity disk 5 \u2013 Block level striping with distributed parity 6 \u2013 extends 5 with one more parity block 10 \u2013 combine raids 1 and 0","title":"RAID:"}]}